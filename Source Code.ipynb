{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJrZqqZm9iSQ",
        "outputId": "9171f318-5166-493a-e5ef-460f8108cd46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Zmtkte3ISG7",
        "outputId": "3ffa90df-6be3-4c80-d737-40f4e358e06e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyedflib\n",
            "  Downloading pyEDFlib-0.1.32-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from pyedflib) (1.22.4)\n",
            "Installing collected packages: pyedflib\n",
            "Successfully installed pyedflib-0.1.32\n"
          ]
        }
      ],
      "source": [
        "pip install pyedflib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9VWvG4nLvLs",
        "outputId": "8b7a4c62-086e-4fb2-acb6-e68d5ae753ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mne\n",
            "  Downloading mne-1.4.0-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.10/dist-packages (from mne) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from mne) (1.10.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mne) (3.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne) (4.65.0)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne) (1.6.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne) (23.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne) (3.1.2)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (2.27.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne) (2.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mne) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mne) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mne) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mne) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mne) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mne) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mne) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mne) (1.16.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4)\n",
            "Installing collected packages: mne\n",
            "Successfully installed mne-1.4.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.22.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.10.1)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.22.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyhht\n",
            "  Downloading pyhht-0.1.0-py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from pyhht) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pyhht) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pyhht) (1.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pyhht) (1.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyhht) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyhht) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyhht) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyhht) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyhht) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyhht) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyhht) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyhht) (2.8.2)\n",
            "Installing collected packages: pyhht\n",
            "Successfully installed pyhht-0.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install mne\n",
        "!pip install numpy\n",
        "!pip install scipy\n",
        "!pip install pyhht"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mrJpduW28twS"
      },
      "outputs": [],
      "source": [
        "import pyedflib\n",
        "import numpy as np\n",
        "from scipy import signal\n",
        "from scipy.signal import butter, lfilter\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime, timedelta\n",
        "import os\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import  Dense, Conv3D, Dropout, Flatten, BatchNormalization \n",
        "from keras.callbacks import EarlyStopping\n",
        "from random import shuffle\n",
        "import math\n",
        "import numpy as np\n",
        "import statistics\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Conv3D, MaxPooling3D, LSTM, Dense, Flatten, Input, Embedding, Multiply, Dropout, Reshape\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5O1JGgONPIvo"
      },
      "outputs": [],
      "source": [
        "sampleRate = 256\n",
        "pathDataSet = '/content/drive/MyDrive/chb-mit-scalp-eeg-database-1.0.0'# path of the dataset\n",
        "FirstPartPathOutput='/content/drive/MyDrive/spectrograms' #path where the spectogram will be saved\n",
        "patients = [\"23\"]\n",
        "_30_MINUTES_OF_DATA = 256*60*30\n",
        "_MINUTES_OF_DATA_BETWEEN_PRE_AND_SEIZURE = 3 \n",
        "_MINUTES_OF_PREICTAL = 30\n",
        "_SIZE_WINDOW_IN_SECONDS = 30\n",
        "_SIZE_WINDOW_SPECTOGRAM = _SIZE_WINDOW_IN_SECONDS*256\n",
        "nSpectogram=0\n",
        "signalsBlock=None\n",
        "SecondPartPathOutput=''\n",
        "legendOfOutput=''\n",
        "isPreictal=''\n",
        "\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2BtcG0bjRmP7"
      },
      "outputs": [],
      "source": [
        "def loadParametersFromFile(filePath):\n",
        "    global pathDataSet\n",
        "    global FirstPartPathOutput\n",
        "    if(os.path.isfile(filePath)):\n",
        "        with open(filePath, \"r\") as f:\n",
        "                line=f.readline()\n",
        "                if(line.split(\":\")[0]==\"pathDataSet\"):\n",
        "                    pathDataSet=line.split(\":\")[1].strip()\n",
        "                line=f.readline()\n",
        "                if(line.split(\":\")[0]==\"FirstPartPathOutput\"):\n",
        "                    FirstPartPathOutput=line.split(\":\")[1].strip()\n",
        "                \n",
        "def emd(signal,indexPatient, fileOfData):\n",
        "    imfs = []\n",
        "    chbmit_dataset = []\n",
        "    imf_dataset = []\n",
        "    file_path=pathDataSet+'/chb'+patients[indexPatient]+'/'+fileOfData\n",
        "    raw = mne.io.read_raw_edf(file_path, preload=False)\n",
        "    data = raw.get_data()\n",
        "    chbmit_dataset.append(data)\n",
        "    chbmit_dataset = np.array(chbmit_dataset)\n",
        "    signal = chbmit_dataset[0,1,:]\n",
        "    while True:\n",
        "        # Decompose signal into IMF and residue\n",
        "        imf, residue = pywt.swt(signal, 'db1')[0]\n",
        "        # Check if IMF is monotonic\n",
        "        if is_monotonic(imf):\n",
        "            imfs.append(imf)\n",
        "            break\n",
        "        imfs.append(imf)\n",
        "        signal = residue\n",
        "    return imfs\n",
        "\n",
        "def is_monotonic(signal):\n",
        "    return (np.all(np.diff(signal) >= 0) or np.all(np.diff(signal) <= 0))\n",
        "\n",
        "\n",
        "def butter_bandstop_filter(data, lowcut, highcut, fs, order):\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "\n",
        "    i, u = butter(order, [low, high], btype='bandstop')\n",
        "    y = lfilter(i, u, data)\n",
        "    return y\n",
        "\n",
        "def butter_highpass_filter(data, cutoff, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyq\n",
        "    b, a = butter(order, normal_cutoff, btype='high', analog=False)\n",
        "    y = lfilter(b, a, data)\n",
        "    return y\n",
        "\n",
        "def loadSummaryPatient(index):\n",
        "    f = open(pathDataSet+'/chb'+patients[index]+'/chb'+patients[index]+'-summary.txt', 'r')\n",
        "    return f\n",
        "\n",
        "\n",
        "def loadDataOfPatient(indexPatient, fileOfData):\n",
        "    f = pyedflib.EdfReader(pathDataSet+'/chb'+patients[indexPatient]+'/'+fileOfData)  \n",
        "    n = f.signals_in_file\n",
        "    sigbufs = np.zeros((n, f.getNSamples()[0]))\n",
        "    for i in np.arange(n):\n",
        "        sigbufs[i, :] = f.readSignal(i)\n",
        "    sigbufs=cleanData(sigbufs, indexPatient)\n",
        "    return sigbufs\n",
        "\n",
        "def cleanData(Data, indexPatient):\n",
        "    if(patients[indexPatient] in [\"19\"]):\n",
        "        Data=np.delete(Data, 22, axis=0)\n",
        "        Data=np.delete(Data, 17, axis=0)\n",
        "        Data=np.delete(Data, 12, axis=0)\n",
        "        Data=np.delete(Data, 9, axis=0)\n",
        "        Data=np.delete(Data, 4, axis=0)\n",
        "    return Data\n",
        "\n",
        "\n",
        "def getTime(dateInString):\n",
        "    time=0\n",
        "    try:\n",
        "        time = datetime.strptime(dateInString, '%H:%M:%S')\n",
        "    except ValueError:\n",
        "        dateInString=\" \"+dateInString\n",
        "        if(' 24' in dateInString):\n",
        "            dateInString = dateInString.replace(' 24', '23')\n",
        "            time = datetime.strptime(dateInString, '%H:%M:%S')\n",
        "            time += timedelta(hours=1)\n",
        "        elif(' 25' in dateInString):\n",
        "            dateInString = dateInString.replace(' 25', '23')\n",
        "            time = datetime.strptime(dateInString, '%H:%M:%S')\n",
        "            time += timedelta(hours=2)\n",
        "        else:\n",
        "            dateInString = dateInString.replace(' 26', '23')\n",
        "            time = datetime.strptime(dateInString, '%H:%M:%S')\n",
        "            time += timedelta(hours=3)\n",
        "    return time\n",
        "\n",
        "def saveSignalsOnDisk(signalsBlock, nSpectogram):\n",
        "    global SecondPartPathOutput\n",
        "    global FirstPartPathOutput\n",
        "    global legendOfOutput\n",
        "    global isPreictal\n",
        "\n",
        "    if not os.path.exists(FirstPartPathOutput):\n",
        "        os.makedirs(FirstPartPathOutput)\n",
        "    if not os.path.exists(FirstPartPathOutput+SecondPartPathOutput):\n",
        "        os.makedirs(FirstPartPathOutput+SecondPartPathOutput) \n",
        "    np.save(FirstPartPathOutput+SecondPartPathOutput+'/spec_'+isPreictal+'_'+str(nSpectogram-signalsBlock.shape[0])+'_'+str(nSpectogram-1), signalsBlock)\n",
        "    legendOfOutput=legendOfOutput+str(nSpectogram-signalsBlock.shape[0])+' '+str(nSpectogram-1) +' '+SecondPartPathOutput+'/spec_'+isPreictal+'_'+str(nSpectogram-signalsBlock.shape[0])+'_'+str(nSpectogram-1) +'.npy\\n'\n",
        "\n",
        "\n",
        "\n",
        "def createSpectrogram(data, S=0):\n",
        "    global nSpectogram\n",
        "    global signalsBlock\n",
        "    global inB\n",
        "    signals=np.zeros((22,59,114))\n",
        "    \n",
        "    t=0\n",
        "    movement=int(S*256)\n",
        "    if(S==0):\n",
        "        movement=_SIZE_WINDOW_SPECTOGRAM        \n",
        "    while data.shape[1]-(t*movement+_SIZE_WINDOW_SPECTOGRAM) > 0:\n",
        "        \n",
        "        for i in range(0, 22):\n",
        "            start = t*movement\n",
        "            stop = start+_SIZE_WINDOW_SPECTOGRAM\n",
        "            signals[i,:]=createSpec(data[i,start:stop])\n",
        "        if(signalsBlock is None):\n",
        "            signalsBlock=np.array([signals])\n",
        "        else:\n",
        "            signalsBlock=np.append(signalsBlock, [signals], axis=0)\n",
        "        nSpectogram=nSpectogram+1\n",
        "        if(signalsBlock.shape[0]==50):\n",
        "            saveSignalsOnDisk(signalsBlock, nSpectogram)\n",
        "            signalsBlock=None\n",
        "             \n",
        "        t = t+1\n",
        "    return (data.shape[1]-t*_SIZE_WINDOW_SPECTOGRAM)*-1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MnpDqL2OUJqd"
      },
      "outputs": [],
      "source": [
        "def createSpec(data):\n",
        "    fs=256\n",
        "    lowcut=117\n",
        "    highcut=123\n",
        "\n",
        "    y=butter_bandstop_filter(data, lowcut, highcut, fs, order=6)\n",
        "    lowcut=57\n",
        "    highcut=63\n",
        "    y=butter_bandstop_filter(y, lowcut, highcut, fs, order=6)\n",
        "    \n",
        "    cutoff=1\n",
        "    y=butter_highpass_filter(y, cutoff, fs, order=6)\n",
        "    \n",
        "    Pxx=signal.spectrogram(y, nfft=256, fs=256, return_onesided=True, noverlap=128)[2]    \n",
        "    Pxx = np.delete(Pxx, np.s_[117:123+1], axis=0)\n",
        "    Pxx = np.delete(Pxx, np.s_[57:63+1], axis=0)\n",
        "    Pxx = np.delete(Pxx, 0, axis=0)\n",
        "    \n",
        "    result=(10*np.log10(np.transpose(Pxx))-(10*np.log10(np.transpose(Pxx))).min())/(10*np.log10(np.transpose(Pxx))).ptp()\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "QmBWqkWJUZbv"
      },
      "outputs": [],
      "source": [
        "class PreIntData:\n",
        "    start=0\n",
        "    end=0\n",
        "    def __init__(self, s, e):\n",
        "        self.start=s\n",
        "        self.end=e\n",
        "       \n",
        "class FileData:\n",
        "    start=0\n",
        "    end=0\n",
        "    nameFile=\"\"\n",
        "    def __init__(self, s, e, nF):\n",
        "        self.start=s\n",
        "        self.end=e\n",
        "        self.nameFile=nF\n",
        "\n",
        "\n",
        "\n",
        "def createArrayIntervalData(fSummary):\n",
        "    preictalInteval=[]\n",
        "    interictalInterval=[]\n",
        "    interictalInterval.append(PreIntData(datetime.min, datetime.max))\n",
        "    files=[]\n",
        "    firstTime=True\n",
        "    oldTime=datetime.min\n",
        "    startTime=0\n",
        "    line=fSummary.readline()\n",
        "    endS=datetime.min\n",
        "    while(line):\n",
        "        data=line.split(':')\n",
        "        if(data[0]==\"File Name\"):\n",
        "            nF=data[1].strip()\n",
        "            s=getTime((fSummary.readline().split(\": \"))[1].strip())\n",
        "            if(firstTime):\n",
        "                interictalInterval[0].start=s\n",
        "                firstTime=False\n",
        "                startTime=s\n",
        "            while s<oldTime:\n",
        "                s=s+ timedelta(hours=24)\n",
        "            oldTime=s\n",
        "            endTimeFile=getTime((fSummary.readline().split(\": \"))[1].strip())\n",
        "            while endTimeFile<oldTime:\n",
        "                endTimeFile=endTimeFile+ timedelta(hours=24)\n",
        "            oldTime=endTimeFile\n",
        "            files.append(FileData(s, endTimeFile,nF))\n",
        "            for j in range(0, int((fSummary.readline()).split(':')[1])):\n",
        "                secSt=int(fSummary.readline().split(': ')[1].split(' ')[0])\n",
        "                secEn=int(fSummary.readline().split(': ')[1].split(' ')[0])\n",
        "                ss=s+timedelta(seconds=secSt)- timedelta(minutes=_MINUTES_OF_DATA_BETWEEN_PRE_AND_SEIZURE+_MINUTES_OF_PREICTAL)\n",
        "                if((len(preictalInteval)==0 or ss > endS) and ss-startTime>timedelta(minutes=20)):\n",
        "                    ee=ss+ timedelta(minutes=_MINUTES_OF_PREICTAL) \n",
        "                    preictalInteval.append(PreIntData(ss,ee))\n",
        "                endS=s+timedelta(seconds=secEn)\n",
        "                ss=s+timedelta(seconds=secSt)- timedelta(hours=4) \n",
        "                ee=s+timedelta(seconds=secEn)+ timedelta(hours=4) \n",
        "                if(interictalInterval[len(interictalInterval)-1].start<ss and interictalInterval[len(interictalInterval)-1].end>ee):\n",
        "                    interictalInterval[len(interictalInterval)-1].end=ss\n",
        "                    interictalInterval.append(PreIntData(ee, datetime.max))\n",
        "                else:\n",
        "                    if(interictalInterval[len(interictalInterval)-1].start<ee):\n",
        "                        interictalInterval[len(interictalInterval)-1].start=ee\n",
        "        line=fSummary.readline()\n",
        "    fSummary.close()\n",
        "    interictalInterval[len(interictalInterval)-1].end=endTimeFile\n",
        "    return preictalInteval, interictalInterval, files\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfm90JV6RqBJ",
        "outputId": "59411fa9-5f1a-49c5-d7c9-1a9f0169ab36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "START \n",
            "\n",
            "Parameters loaded\n",
            "Working on patient 23\n",
            "Summary patient loaded\n",
            "START creation interictal spectrogram\n",
            "Spectrogram interictal: 1702\n",
            "Hours interictal: 14.252777777777776\n",
            "END creation interictal spectrogram\n",
            "START creation preictal spectrogram\n",
            "Spectrogram preictal: 1690\n",
            "SEIZURE: 5\n",
            "END creation preictal spectrogram\n",
            "Legend saved on disk\n",
            "\n",
            "\n",
            "END\n"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    global SecondPartPathOutput\n",
        "    global FirstPartPathOutput\n",
        "    global legendOfOutput\n",
        "    global nSpectogram\n",
        "    global signalsBlock\n",
        "    global isPreictal\n",
        "    print(\"START \\n\")\n",
        "    loadParametersFromFile(\"PARAMETERS_DATA_EDITING.txt\")\n",
        "    print(\"Parameters loaded\")\n",
        "    \n",
        "    for indexPatient in range(0, len(patients)):\n",
        "        print(\"Working on patient \"+patients[indexPatient])\n",
        "        legendOfOutput=\"\"\n",
        "        allLegend=\"\"\n",
        "        nSpectogram=0\n",
        "        \n",
        "        SecondPartPathOutput='/paz'+patients[indexPatient]\n",
        "        f = loadSummaryPatient(indexPatient)\n",
        "        preictalInfo, interictalInfo, filesInfo=createArrayIntervalData(f)\n",
        "        if(patients[indexPatient]==\"19\"):\n",
        "            preictalInfo.pop(0) \n",
        "        print(\"Summary patient loaded\")\n",
        "        \n",
        "       \n",
        "        print(\"START creation interictal spectrogram\")\n",
        "        totInst=0\n",
        "        #c=0\n",
        "        #d=0   \n",
        "        interictalData = np.array([]).reshape(22,0)       \n",
        "        indexInterictalSegment=0      \n",
        "        isPreictal=''\n",
        "        for fInfo in filesInfo:\n",
        "            fileS=fInfo.start\n",
        "            fileE=fInfo.end\n",
        "            intSegStart=interictalInfo[indexInterictalSegment].start\n",
        "            intSegEnd=interictalInfo[indexInterictalSegment].end\n",
        "            while(fileS>intSegEnd and indexInterictalSegment<len(interictalInfo)):\n",
        "                indexInterictalSegment=indexInterictalSegment+1\n",
        "                intSegStart=interictalInfo[indexInterictalSegment].start\n",
        "                intSegEnd=interictalInfo[indexInterictalSegment].end\n",
        "            start=0\n",
        "            end=0\n",
        "            if(not fileE<intSegStart or fileS>intSegEnd):\n",
        "                if(fileS>=intSegStart):\n",
        "                    start=0\n",
        "                else:\n",
        "                    start=(intSegStart-fileS).seconds\n",
        "                if(fileE<=intSegEnd):\n",
        "                    end=None\n",
        "                else:\n",
        "                    end=(intSegEnd-fileS).seconds\n",
        "                tmpData=loadDataOfPatient(indexPatient, fInfo.nameFile)\n",
        "                if(not end==None):\n",
        "                    end=end*256\n",
        "                if(tmpData.shape[0]<22):\n",
        "                    print(patients[indexPatient] +\"  IT HAS LESS NUMBER OF CHANNELS\")\n",
        "                else:\n",
        "                    interictalData=np.concatenate((interictalData, tmpData[0:22,start*256:end]), axis=1)\n",
        "                    notUsed= createSpectrogram(interictalData)\n",
        "                    totInst+=interictalData.shape[1]/256-notUsed/256       \n",
        "                    interictalData = np.delete(interictalData, np.s_[0:interictalData.shape[1]-notUsed], axis=1)\n",
        "                    \n",
        "        S=(_SIZE_WINDOW_IN_SECONDS*(len(preictalInfo)*_MINUTES_OF_PREICTAL*60-_SIZE_WINDOW_IN_SECONDS*len(preictalInfo)))/totInst \n",
        "        if(not (signalsBlock is None)):  \n",
        "            saveSignalsOnDisk(signalsBlock, nSpectogram)\n",
        "        signalsBlock=None\n",
        "            \n",
        "        print(\"Spectrogram interictal: \"+ str(nSpectogram))\n",
        "        print(\"Hours interictal: \" +str(totInst/60/60))\n",
        "        legendOfOutput=str(nSpectogram)+\"\\n\"+legendOfOutput\n",
        "        legendOfOutput=\"INTERICTAL\"+\"\\n\"+legendOfOutput\n",
        "        legendOfOutput=\"SEIZURE: \" +str(len(preictalInfo))+\"\\n\"+legendOfOutput\n",
        "        legendOfOutput=patients[indexPatient]+\"\\n\"+legendOfOutput\n",
        "        allLegend=legendOfOutput\n",
        "        legendOfOutput=''\n",
        "        nSpectogram=0\n",
        "        print(\"END creation interictal spectrogram\")\n",
        "        \n",
        "        print(\"START creation preictal spectrogram\")\n",
        "        isPreictal='P'\n",
        "        contSeizure=-1\n",
        "        for pInfo in preictalInfo:\n",
        "            contSeizure=contSeizure+1\n",
        "            legendOfOutput=legendOfOutput+\"SEIZURE \"+str(contSeizure)+\"\\n\"\n",
        "            preictalData = np.array([]).reshape(22,0)\n",
        "            j=0\n",
        "            for j in range(0,len(filesInfo)):\n",
        "                if(pInfo.start>=filesInfo[j].start and pInfo.start<filesInfo[j].end):\n",
        "                    break\n",
        "            start=(pInfo.start-filesInfo[j].start).seconds\n",
        "            if(start<0):\n",
        "                start=0 \n",
        "            end=None\n",
        "            tmpData=[]\n",
        "            if(pInfo.end<=filesInfo[j].end):\n",
        "                end=(pInfo.end-filesInfo[j].start).seconds\n",
        "                tmpData=loadDataOfPatient(indexPatient, filesInfo[j].nameFile)\n",
        "                preictalData=np.concatenate((preictalData, tmpData[0:22,start*256:end*256]), axis=1)\n",
        "            else:\n",
        "                tmpData=loadDataOfPatient(indexPatient, filesInfo[j].nameFile)\n",
        "                preictalData=np.concatenate((preictalData, tmpData[0:22,start*256:]), axis=1)\n",
        "                end=(pInfo.end-filesInfo[j+1].start).seconds\n",
        "                tmpData=loadDataOfPatient(indexPatient, filesInfo[j+1].nameFile)\n",
        "                preictalData=np.concatenate((preictalData, tmpData[0:22,0:end*256]), axis=1)\n",
        "            notUsed= createSpectrogram(preictalData, S=S)\n",
        "            if(not (signalsBlock is None)): \n",
        "                saveSignalsOnDisk(signalsBlock, nSpectogram)\n",
        "            signalsBlock=None\n",
        "        \n",
        "        allLegend=allLegend+\"\\n\"+\"PREICTAL\"+\"\\n\"+str(nSpectogram)+\"\\n\"+legendOfOutput\n",
        "        print(\"Spectrogram preictal: \"+ str(nSpectogram))\n",
        "        print(\"SEIZURE: \" +str(len(preictalInfo)))\n",
        "        print(\"END creation preictal spectrogram\")\n",
        "         \n",
        "        text_file = open(FirstPartPathOutput+SecondPartPathOutput+\"/legendAllData.txt\", \"w\")\n",
        "        text_file.write(allLegend)\n",
        "        text_file.close()\n",
        "        print(\"Legend saved on disk\")\n",
        "        print('\\n')\n",
        "    print(\"END\")\n",
        "            \n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "TJ5Hmws4TeQi",
        "outputId": "86c74ef7-48a7-4370-98b1-396b2dc656c0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f06e8308b80>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAEvCAYAAADlz6PhAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACAmklEQVR4nO29eZAc13XmezJr36ur9wa6sYMAwUUUSIIgqR0eitaTJQthW3q0TcuKcUgDakQxZmxTtuRtNNCMI7TYQ9ExDg3peSOathyW7JFG4sigJGoBKBDiDhALsTV6qV5rr8qqysz3B+gGzncuugESLADU+UUgArcq782b997Mul3nq+9Yvu/7pCiKoiiK0iHsS90BRVEURVF+vtDNh6IoiqIoHUU3H4qiKIqidBTdfCiKoiiK0lF086EoiqIoSkfRzYeiKIqiKB1FNx+KoiiKonQU3XwoiqIoitJRdPOhKIqiKEpH0c2HoiiKoigd5XXbfDzwwAO0cuVKikajtGXLFvrpT3/6ep1KURRFUZQrCOv1yO3yd3/3d/Sbv/mb9Fd/9Ve0ZcsW+uIXv0hf+9rX6ODBg9TX17doXc/zaHx8nFKpFFmWdbG7piiKoijK64Dv+1Qul2loaIhse4nvNvzXgZtvvtnfsWPHQtl1XX9oaMjfuXPnknVHR0d9ItJ/+k//6T/9p//03xX4b3R0dMnP+iBdZJrNJu3bt4/uv//+hdds26Zt27bR7t27xfGO45DjOAtl/5UvYob/8nfJjkWIiMity24OLJtj5UYrxMqFibSoEyoEWDl6VRH6Is8TjrRZuTKTEMeQ7bNiPNvgb9ueqNJs8r40S1FWtkKyTiDk8hfGY6zo9fPzEhFZAd633q4yK0+eyok6wyMzrDw6wY8ZHuRjT0Q0OcfH2wrw/rcn5bh5cX49/UPz4pi2x8epVInwA3z57Vg4yucsHeXjMvuM/PYttKHEz9vmu3Znjo81ERFFeP8TGX6eakHWCcWarOy2+PWl0nIOi3N87AKwJl1YS0RE5PFxsXHtEFFggq85u8HrOAMtUScyERKvnY0f9MVrdou3a/Huk2/4A8mL8XaafbwviUNhUae6hh8TLPL72Y3Ke8oP8/Nk9stnQOkqPnZ+DMbSNXxD6+I1wzFpObZ+jZ/bivGBCoZh4IjIG4/zcgTG33CewCS/h9rd/BirZlhP2EaDT5otT0OtJB9vHGsiosRxmCO4vUlOGfnQPbxm2zmPb8zP4xBcy7hO7aZsJFjn5VaKt9FOGu4PaMfmjwhxvUTysRcqyb54cKuaxh8JVKEvsNSdLkP/zzrGcxp0/L/8GaVSqSXPddE3HzMzM+S6LvX397PX+/v76aWXXhLH79y5k/7kT/5EvG7HImTHTz8cfUM3gwm+SgNNPtJ2jD9YiYjsBp/FQBw2CQH5YA1E+F1lahc3H4E43AyGzUcgyK/Jbi29+bDDsBKi0Bf+HDrdDmw+ggm+sk3Xg2OLx+D7RER2Az7IYPPhYV+JiOAhHjC067t8zmwP2jFsPgJR+BCCDzLb0JdA3GFlvw3nrRv6D5sPMe+OYQ3G+RPMb+GaNNzccG4bNld+4Dw2H7h2SI5DAJ7Idky2G4guvvnwDJuPgA0fxNCsafNBURhL6EsgIjcfeIwNf0z4saU3H4GwfNbYsddh82EYW/xbEDcfdkRuPsQzAMbNdB47ivc3P8YyfdphGyAXtA1V7NjSm49ABMb7VWw+8JoDpnA9nvo81I64lnGd4romIoLHHrm4jnF+iMiGdjBacT6bj4Bhw2XBrSo2pgYC7cU3H8b+y0fLeUkmLvrm40K5//776b777lsol0olGh4epl/e8AxFkqdHb010StRL2PzDouDyT978ioyo04JZrMA2e64pP72bHh+iUqYojnlpdICVY2H48AvI2amM8W8K0sv4X971l7KiDk47fnNTPWXYbWb5ZiNg8VZSfRVR5cRYNysPDBRYeWxG9q0vx/s/caSXlQc3yDn04A7Kv9wjjqEU/ElVhE1mD18HRETpGN9U5p/lG+H0dbOijg99wTlsFORGIhTjx1Tgm45ARM57Gz4QA3n4IMhWRR0LNrc2zKFXkbexH+FPwchB+S1MfSX8iTXDxzYyKTca+Bduo5efJ/ecfOg4XbycPco/RKfebPggxmbghXq/fAgGC/hNB3x4xOV8pA7wTUxpnWmDwl8LwuYv9KJ8buCDvpWG/lqy/6i+81v8U8idleeJrOT3b/NEktdxDGMLH6pWEK7Z8Gknxq7G+9bKGMYtyutYddluZSUfy8gMfDs9LddTaR1vN1TifQnzR9Hp/vFhIQseG07OsJ5qFpThAMNneaMbxhaOCc/LXU+4wMvVET6WmUNyDCrLoSuGzZQNe1X8BtL0LUwrA3+slmEM6oZvWM7jGxUTF33z0dPTQ4FAgPL5PHs9n8/TwMCAOD4SiVAkIv/iVRRFURTljclF/6ltOBymzZs3065duxZe8zyPdu3aRVu3br3Yp1MURVEU5QrjdQm73HfffXT33XfTjTfeSDfffDN98YtfpGq1Sh/+8Idfj9MpiqIoinIF8bpsPn7t136Npqen6TOf+QxNTk7Sm970JvrOd74jRKiKoiiKovz88boJTu+55x665557XnX9dLBO0eBpxUwqUBfvH2lw/cgpULU5rry0gwX+E8t6ix+TjcmfOeZLXMQZDkrFeQSEhzOnsvwAFHQREcGvUKo1rntJbZQ/O8WfDzsNEF92S/ElyoPmqly01mhIUSEKTPNTXLzb08N/rktE1GyDUh+Ervg+EVFvAsRyK+Q1V+swLt28TqUu9UIoqm1n+Zy1XSl8q8H4x+HXL6ZfH/kn+E9gIzD87bVy3YZAhOeBvL/+Uym6Tby5wI85wucjaFCbt1P8mutDct2Gpvnco2itmZMNB6v8oNzzfIUV18u+pI/w+Zhfz9dCOyHH1oXXEi/zvjZ6ZJ02iB4D0NfYQfkLmfIa+EVJU0ai7QpfL20QAPtXy3n25vm58Bcypni3XYdfQsEvZry4vGZ8BljwKyfL8CsnNwFPBbQyMPxiiUD8iqLVUEFeUQuExvExed9VR/j4O0P8WdpKGcTUIRTzwi/rgrIvKB4Ng667vswwtrD+08/zOXUNP4CzoBlc2+F508+CoAzD72QNv6oBrXh8Us5ZbZDXi87wY6JSd08BeIaVV/AyimOJiKyzxODu+fzM+RU0t4uiKIqiKB1FNx+KoiiKonQU3XwoiqIoitJRLrnJ2LlwvNCCP+zDY7eJ91tgu31imgcY23lpyJM6yvdapWt54GyunRV17ASPQVYbsl2Mq0Yn+bA2hgw21TkeJ3bKPPZfcqUpVKKPByrRArxdkzHtWIrrWOIRfs29KWkyNl3mjjzRQzy4OW/QP7QboJ8BbcbMpLS7DwzxduqO7P+ynDR1O5tYSI5tLAivgUlUpSKDtR7EtIVbrG0whQLdjtMHOoWo7FvtFB9bPw0x+eUQzCWiJuhR+q/lHjozRXBQIiK/BOZlBi1Dqxt0IOgA/oLUA6FZkwtmWianxQbIWNowtmgSRSSNi2rLwGU0KTUsVhUeZzBllXUGD3DQSJiMo1DfgG6xft7gzJsBLQlYvVOf1GJ4aP8O5zVZ2zuwBqkLrNINDsCoLYlO83JtrVyDmaf5vWm3+HkroA0gIrLA1KqJRmtEFJ7lz/EW6hsMEgKh5cnzcmWNwQmW+Hn8AG/YZEBnl/icVZfz+YlNmXQuvJ3s87yN8ir57IzM8nbwHrIMmq4wPBZrQ3KgcOrLq3k5NinrNMGbs42Oywbn0szLZ67JbRr0jedAv/lQFEVRFKWj6OZDURRFUZSOopsPRVEURVE6ymWr+Ritd1E4cDrOOFeXOosq6AP6slxjMPeijINXb+Y6C/zFtdeW8SoP05WbYsLwO/k2ZllMylhzq8nrBCGpl5sw/CYedBVd/TyDkinteyTH45+5GM+OdGSSJ4AjIkqAx8X6Ow6zMibbIyIaK/JgYfUA1+D0Xjsj6jTbS2fPLEBG13SU9w19S4iI+tPchyQcB++AKTlOAfBI6YrztVKakEn7Qiu4BicHWZLjBj3K5ADf71sv8natHsxeRRQDnc7EJB/bgMHLAX1kUJ9CRGSBFsZ3eN/Ka2S7mJ3VC4PuKGnwQ8HsnxCMDknbGHIjoEuY4XUqK2WdICY76wH9A2pCSPqUzN4s9QIiYZ3HNR5Wn/TXIUjoZg/wtdEuS/2GBToWe4o/45xlUouBugRMHmYCk53VwGuDDPqg0lo+r8mTkPQuIucdNXbl1Ybna4bPUewIH9tmVq7byDy/xkYPPyY2JufZ6ebnboPWKjgl5yNc5OdppcCbacRwf8D4l9bw84bKcmwxOSN6hWCiOSKiAKz1UFnOe89+3r+Z6/ia9AwJqjFxJGqv4sdknepZzzTXOf/vM/SbD0VRFEVROopuPhRFURRF6Si6+VAURVEUpaPo5kNRFEVRlI5y2QpOd/9oE9nR02LDgRsmxftFECvm57iJVXtEiv1SCS76Ks/xxGChmEEYiiK1kBRABdJcCOY2uWgq+qIURdZX8HOF6yDki0gBUeowVwgVGllWTg9zASoRUaHArzEJ4sWerDQZmyvyOpkwH7enJoZFHR9EhP4IF2zOzkkBcF8P72/bk3vh2lPcoarnrSdZOZeQAs3RmSwrtwpgKoZmTkTU28VVjycnc6xsG0TD4ZDJzOgMxbo0M0vDGpzp42vDn5FrpdGEdQqiNVMCODRnwmRcRET2PCjOUJRq+NPEA/OsNoiPAw25bqPTKBCE0xiGsZ3gfUm8AKZWYJhERBQCgWCgDoLNVVIYWlrNj7EMYsvEKUiedzUf78C4wbQuyY9xG5C4cEDed+2XwIgPpiO7WyoEZzdDokJIrkcGAWCwBGJYMB0LVg1zOMtfc7L8/bAhsVxxE79n4sdl/2tJ3i7Oe2xa9qXRzY8JF6BvObnWgyDIdONLCzaxHVyn8VNSMB+ExxGKR2uDsm9o8lYfgEoGozgPftTg1+QxhTWL/1giXDKYvsFrzQwKi0UVClXP1LGbhl9knAP95kNRFEVRlI6imw9FURRFUTqKbj4URVEURekol63mw1pRJeuVZD+n8l3i/QQkTLNtHifzMGEUSYOqWoTHanMZbhpFRDTt8v2ZSEBGRDa49nhZHuusx6TGAJPRNdfygGJgVMaRm1leDkKCpdKU1FUEErxdF+KH82WpMcBxeLnIg/SVaa5BICJKgDlWf47rOYK2HIMSxMEHU9Jt6tAQv6aje7neJLRW1mlBUrVAis9HOiV1Im2Xx0ctSCTnG9ZTMMDncHqKx+yTWa57ISIqjIFZWRT0AwV5S/Zs5AZt9SaPnTen5byHZnk7rV6pWQnM8Wvu+xm/5qnNhoRvIukVaJUMTxQP8gV6oD/JvWTQWiV5pakb+frp2Sv7hkmwSmsh/lyUmoN2mrcbNCS5K17HdVLhPG/HN/wJhyZQfj9/9jjHpGldcB3XgTiz3AxvFrQyREQUAb0PmJthcjoiknogNKRDUzgiKl3FnyORPKyvtLy/Y6f4OLWTBqO7Gu9vqALaDJlrckkCBs83NAzDYaovl8IjnMPoDCSA4x9Bp4Gha+TgfUPeNdSS2E3eCBrsEck158bk2DqwXlb/A39Wntomk3327QHjyi5uHmmQn1By4swabLcM+rNzoN98KIqiKIrSUXTzoSiKoihKR9HNh6IoiqIoHeWy1Xy4rk3+K3qLWEIG8erwG/7Yz8Av4RpZx2lDgqg6eIXUpLYkkuGBPacpf+jcKkNgMsQDe+G07EuzwusEwX/DlKALA30RiAW2emTcz8/z/hZjPI6ciMm+TU3xON+a4SlWtquGpHc+H/+1G7hO4bkTy0Sd61aMsfJ0XWpJrDYkLoOEUAGDFgP1Jw2Ir7sJGax1YbjDER6I9U0JBTFBWpTXae7n40hElN5UYOV6g8fFW215PeU6n0MP/FBM66tdgTlyZbutbt7fuY28L+hZQETkg49Hs4sPnMnnw4KYds+zfDBnrpGBfYynx6b4NRdRz0FEiXFeRv8EU1JIF3IMOgbPFAueE80+fkGoryEi8vogCRyuU0NOxWCQj6UDeiDTHOKa8/N8LE1aANTcRPO8M+hBRCTv+VYKkqEZ+mbDELSkzIX8CLbDz9Pok8/B8NzivhjBusEXA+Q+ImHaSTmHtWGYZ9Cj1PvkeZrgsxKfAM1gUNZBjQp6g2CyNyKpE2nLRyd5sMbG38o1HpZBnjFzIz8GNR6hilxPte4zJ3IxEesi6DcfiqIoiqJ0FN18KIqiKIrSUXTzoSiKoihKR9HNh6IoiqIoHeWyFZxeNTRFocRp8ZRncDZZmZhj5cRGrtqZaEgDlWyImz6Ve7iRV7klxaRNcE0qZaX5lwMiqdkCN31qoiCViEIJriKKgMDR7QK1FhG1YiD66oK9Y1vuJTFJVADMviKG5GjRJB/Lo+PcrcZLyzrpbm5MNgPi0fXL86LOs0eXs3Jvn0yM17+aC1cHE/yYI3PSealS5CrCDW/myehKjpzDsXFIJAcmcF5d3ipNEItSiZetESlsTYLRXQmSG4rkbiSFra2TvI6bk4q0EAg/vajBJK2EQkO+5rLPyHVbWb544ihTUrJQjddpdIHhU7dsE82lYlMgdO2Wajkvwq/HBcGmb0goGJrj8+onDCo8SDYXHeXzHJI54qgyCC/gsPQYRMJ4/8K8W0bDMP5aG8zkwpPSWA3HbvBbvM6JLlknYBBxsq4aPkna4F+IZmanX1w6KZwAhgkFmSaxvhvm50mc4o3Ulsk6UTBSq4zwvrlh2Vccp0YvPwaTHxIR1eEYF5LGtdKLjz0RGcXUKKr1YAxaBtO3OORwxQSCIenDSa2zkgO6znn09RX0mw9FURRFUTqKbj4URVEURekouvlQFEVRFKWjXLaaj1tzL1M0ebp7W+IvL3n8YWeAlZeH5+Ux9T5WDoKby0RV6kSKNa4fiIRkfL0J5mXRGI+dtyoydt4qgHEUnCe5pijqtGN8r+g4PDYbjcq+OWl+jAsGVeW61D80aotncwqg+RERlUFngdqGWku2iRqP2TmZIG24n88janBwDIiIunKQoMvldSZnpflXKM7nDA2f7LjU4NTGeH+DvVxT1KrLvuF6SuV4EBX1KkRE0TAkKgSNRyhmSMzWC8mpTsrxb4DGA3UutQFDTBu9s6BZTO5GRFQDM6Yg5NtDEzIiIhv0AdUR3rfolHx0oUGYleOd9Q1JIVtZXieUkPNsp3hfnBi/6EZNGisFJ/n97SYg8WVM3kNtuOYAGIiZklq6E1xYAbkOqTko10Zwhq/Lk/+G99+kzfDhEtGgLmhIiIhGce24wWCrwq/JBb1GeEaObQikYRaMS33YkCQOzlNZxQcqPCfPg8nyUsd4G02DaRqu/9Qx/j5qKIiI2gkwfQNzvMaAXCvRCd5fT+YHJT/M+99K8fFPnpB15jfxcvdzvI3qoFyDyx47o79suw4dkM0a0W8+FEVRFEXpKLr5UBRFURSlo+jmQ1EURVGUjnLBm48nnniC3vve99LQ0BBZlkXf+MY32Pu+79NnPvMZGhwcpFgsRtu2baPDhw9frP4qiqIoinKFc8GC02q1Stdffz399m//Nn3gAx8Q7//X//pf6S/+4i/ob/7mb2jVqlX06U9/mu644w7av38/RaNS3HguPpB6nlKp03ujUXSrIaLeAFet7W5z9Y+NqQGJKBYA4R44GXXHZBrPFhiIhVHRRTLLqNPiw5rqlS5ElZMgbh3gAs22K/eF9QkucAz38f5m4qDkI6ImiBWFqNOQFdZ37EWPcSNybHO9XAVWqHLhZDwihW9oeOZVpEBz1OKZhgd7uBA3EJB9wfnIl/jaiESlqLB9gM+Ht57Pmek8lOHXhCLVSFbOR6XAxyWW4vPeB+NIRDQ9x/sfTfL+NwryvrLAGAsFg0REBEK96BF+P9SXGTK8tvhaiE3yNkzGRT5Ma/IIiNhMa72fl20wL2osk+spfoyfqB7g15M+JAehvB6yJB+QoufGIAgYcSmYfJXgNSHiNIlHLXgcg4FYICzXYAAyrbYgy7DJfAofjXhIdEr2zenBSvy8mG2aiCg6AwZuBpM0HBerCaZj/QbxaIO3i4LNUEHOM2bYxb+7URx7+jUQ56+C+3tWjpMFz8rqEH/fNAaZQ5AtF9a+MSM1iKDjE4YMu7UgHANmf92GDNQumNaBOaHB75Ps2cKZ/3vy2XouLnjzceedd9Kdd95pfM/3ffriF79If/iHf0jve9/7iIjof/7P/0n9/f30jW98gz74wQ+KOo7jkOOceQCXSvLhqyiKoijKG4eLqvk4duwYTU5O0rZt2xZey2QytGXLFtq9e7exzs6dOymTySz8Gx4evphdUhRFURTlMuOibj4mJ08bw/f38++N+vv7F95D7r//fioWiwv/RkdHL2aXFEVRFEW5zLjkJmORSIQiEZnQzaYzO6PbonKPdO/E21j5TQmePOzF2jJR57l5/trGLN8QjZVknXU5ntis4EgTKDStSqe4FiNgyzhf/6Zx8drZzFalziU8zPUOhRken5426De6M9zEKpYAjUHakBULqLd4LH1qRpqxzc1wXQIaiE2PZUUdNAeykjKO393F+2dDHHx1z6yoM9/gc1RzeOzflKjQ31Bm5UaFr0nfYOTV38vnA/s2Mcn1KkRE5PB4dCTHY9rxz0sDNP83eLs2JgfMyIC12+bncYJST4NaHjRIQp0FkYz5ttIQby/JOvE8P2b2GjjGkvcHJqjzQGvStV+eZ+YtfG1bFUgKeb2MR1twb7avkgnf0nv5vejC46r9Zr52iIgcgucExvoNzwRMYGeBmV/YoJuqL+PzHJri8+zl5PV4QT4uHiQya9qGv0mXyPeW6JcZxypWwnAkJ5jmc9IGPQe15Tyj/gTXZMCwblEXgmsf1/HpOvw86cN8rGtDsg54IFJ8kp+nslLqduavW1yzYjfl9QQhcWTZ0G4sD8ZqEFTIHJH9rywHbRXPt0nxKVkn/55VC/93mw2ivxGHGLmo33wMDJx2Gc3neQbTfD6/8J6iKIqiKD/fXNTNx6pVq2hgYIB27dq18FqpVKInn3yStm7dejFPpSiKoijKFcoFh10qlQodOXJkoXzs2DF65plnKJfL0cjICN177730n/7Tf6J169Yt/NR2aGiI3v/+91/MfiuKoiiKcoVywZuPp556it7xjncslO+77z4iIrr77rvp4Ycfpt/93d+larVKv/M7v0OFQoFuv/12+s53vnNBHh9ERGHLorB1Ov60pyF/Q35LkiebG23x4NRcU8Yb0Vfi+Xn+I+z5efkb/0MQUFzfPS2OyaR5vBMTzQ2lZZK7KiRaG5+TsX4EvSbi4CPhviDbmFoDMeEw1xh0RaS3CSbYw2R09rRMUjawaYqVg6hLyEpdQhv8UOIJeUxXlF/j4TGeHPDWtUdFnaMz3axcn4P4uyFx1ophru3Jw7yHQ9JvIBnm8eoAGChM5eU4ZTdxjUoNEuNN3Cr1T8EwX1+1Kb62e4YLok6pyu+3WLf0HGlAYrxmD9xnpjg/eE0MPcbfnrhNakvKI5Dkjg+1MXbuRvhr2UP8/UaPwaPApKNgjRpMCsCbxTfogUrr+dwHqvx+MD1Eg0V+3wVWc+2S6TxI6Gd8ftqbDZoVeCZkruHrq1iWGjVvCDO+wRfgOakfcNGDJ8SPqZ+UWdZCA/zZ0irLtd2u89HDpJWuJb+cDxfAz2WIz4/lyzpeiK+N8Dx4M/UZshuCn1Eryec0Oi3nsDrM6zR6+Pt+Qn6WxQ8vnsjTpEfBJIq55+U1z97INULde/lY1wYMehqYe8tFXZhh3Z71kttYel3/Kxe8+Xj7299Ovn/um9yyLPrTP/1T+tM//dMLbVpRFEVRlJ8DNLeLoiiKoigdRTcfiqIoiqJ0FN18KIqiKIrSUSx/MQHHJaBUKlEmk6GHf3Y9xVOnBT4HGkPiuLLLBXW7p1axcrEuBa5oAjWY5kZYEyVpnlUB4V67bDBrQgMhMMaxE1LMZI/zdgMruSCt2TCcB4RWyRHe/8aBrKyziosVc2kuAqs15XmWEsOZ3o9HFk8oNFeUAuDeLm7OhPNDJMW7vQk+TkVHzvNcmZ/LGedlu0caL7lVEAmPcOHedEGKkVtVLhTr6efzMTsr64TBrMwxiPAQO8zFZRYKZsflGERW8bHFpISnG+LFEIjwfIMiDI2XUJBmSkoWBP+p+uDSZmY2+GlhMrRGryGhYBLEfJi0zJAcMJDn4x+el32preD3b3iWCw+bg9L8KwTz3G6CuVxc1mkUYS3A2IbS8h5Dwzy3yNekFZfPHh/N/cD4LliScxhYy++7xjQXsgYrMpmbDwLg1HHZbuEGuCa45kBZtotrTohJC4akfSBg7nmWl6duElUIdauYFC5UlOdJneDl6jKYn5jh4xZeQqM+kdSP5D3jhS/8YzxYk2sdTdIS45D0rk+e5+y+uE6Djvz5p6hYLFI6LT9PWb0L6KuiKIqiKMprRjcfiqIoiqJ0FN18KIqiKIrSUS55Yrlz4ZJF7itB6UxAGiStj06wcs8yHuP2DEYzqBNxIMCVMxhuVbI8Dtv0ZAxyrs4TT7VcG8qyTvwa3t+po9wYa+NOmd134kFu5NMAvUZ0Y0HUKc+B1gI0H+V5mcAOk8LFQ6BTMFxPAPQaY+Pc9C2akjqLwURJvIYcnOamYvUIv+ZiTZoorYJkcwcwPm0wDIv28Nhzfo7HK3uyMgFfETQFDTBNE9oMIrJQZwGx/8BBqY1xermWIfUSH//KiDxPow6xf0OCrkADDYSgHYP0B2PNkTkw3JL5xSj7Mh9vpxsMuKS3HNWX82v2wQzMqAVoQF96+XOjVZDaGNSSiDEgEoZaFqx/qy77Ekzzi0JtRmNGrluco+yKAiuj/omIqP0CGAL2G8yyEDRbk75XgkaJPwdDYKLW6lq6kcK18phQnt/PLTDPcrsM1wPzHBvj4+J0S41EGHQsk28FczmDQR1eo13h42aSxqH5HepRBn8sx2D8Nn4e1DMZpHDiNZN+Y2APH7vpN/Gx7t4vx3bqzbwvbVimqAkhIrLlo/280G8+FEVRFEXpKLr5UBRFURSlo+jmQ1EURVGUjnLZaj42hvOUDJ/eGwUMGa62xfOsfCzEE5s9Xt0o6tRdHvPqCnH9Q96SyZHSYR43jgXk7/Mdlw8j+lUcOdYv6lTgN+N9q7lO4dDHV4g67VmuSxga5AnrxkFnQUSU6+W6ikyEx6Kt70LmIyKq/Sq/nmiQxwYjARm3nKlwrcL1a7hm5dkD8nrCQ7ydgzN94phsgo8/eoyYXGpQg5NdxsegWJA6lxboM4Ih3jeM2RMROeDzYR/kcfHsrZBBjYgqNa47yKT49c32GHQJLX7u5tv49fgGTxh/DjQfBm+TFniboC9GYF62a8HUB0GOVe83JImL8fOEuNzJGEf2Y/xE0ZP8ehoDMl6Nsf96dGkPlVYaLihm0C6ALwZqcAJpg2cHrA0fvDTslKyDa67u8DZcQ2K8cBU8IUBjYEoC6cI1+1CnnZKaicgp3g76vRg1OGh/lJVz1urhrwXn4Flq0Jc1e3md+vDSOpc23EMh8AJpDhk8VCCBYCzPy7UBg9Yqyl9D/43KkEEfBHoNJ87HNjZu8FCBpYC+OEREM9fy+9eFvk1fL288C4cSzoM6MSKum0IN1WLoNx+KoiiKonQU3XwoiqIoitJRdPOhKIqiKEpH0c2HoiiKoigd5bIVnPYEPHolrxxtSkozqueaXPhS8KRpD9Id4g5Isy0ukmy4UmDXFeaiVJN52crkHCsXW1w0aIWkCsevgTgODMOWbx4XdRDXg740Zd/Q4GymxsWWoV+Xosg4KMVcUDc1DSKwVIwLWattLlAbWinPM1rOsnLp5aw4puf6MX6ekMGRCshGuAoSRcNJg7hsxuFr4eV5bvqGolsiIguMr1Jv4aJnk0i1P8vVlnNVEL8axIuhqEFNdvZ5mgbTt25+jbG4FJy2I/yamg5fk25Krie7Bsnn0DXNBOjyWin+QjMr7w+rBsZLw/x6rIp8dNVHYJzOJ9dWmJ873SWNBhvPZ1k5AEZr7awc2wCI+yjKxzoRMwiA4b7yPDCsMhgc+jcXebswHZFeg0C+xZ81KNqul6Xo2YnAHAXRnU2uFasOCeyiUswbmOCiYHeIj4vJusye5c+WIJh/NZfJa27nIMkgPJNN91gbtPiNYTjGldfszfDrCcAYzF9rEPNO83n1QaRaW2YYBZizzCG5Nsor+bncJC9HpgzrCV7yMEmq4VHUTp7pjIdJVhdBv/lQFEVRFKWj6OZDURRFUZSOopsPRVEURVE6ymWr+UhYIUpap/dGzzgyPtrwedyy4PHYecOT+o3AEg4olZY0JTpe5MZdA8myOOZQvpeV0Qirv4/HZYmI5su8v/4TXaxc3yaDazFI8FaH2G0oK/UQ8TCvMzXDE1FlszIT2Pw0N1uLZ7lmot02xAoh1DfV5ucJRwwGQy3eztrrT4ljxku8nUwP70vZkSZKfXE+R4UmH+t00LCeQO+TgHHLRmVyw/kEJKyz+frqicmxPTbP11N1hvdtYJjrh4iImjDetb0QjB4ymCyBxqAyLRPWEcRzrTiPLYcKhnmGcmU1r5M8JuvU+8D4CrrrG+LEQTCtikG75WvkHFqgo0LBQOKU7Fv7Jr5WhI6KiNqr+H3VBNMxy5GPUR/0GvEMXz+mJHGouWk1eDl5QD6fnCwfO0zMVjU88oJZrp9pV2Dt90jdiwNGdu0S3HeGJIqIj6Z2RNTO8P7akOAteEzqT1or+Nx7/ZCIbU6OExr1kQWJ8dJSu4Rzhskavbq8ngCcp90H+jKDLg/7YsX5DeIbEheG5vm5i+ulLsR2+LnSB3id8hpDHeg/ShzDRTlOZyeb9JvnoQH713rnfaSiKIqiKMpFQDcfiqIoiqJ0FN18KIqiKIrSUS5bzUfTb5PzSsDpu9Vrxftb4i+z8nCQx8pLYRkrLLo87j0Q4VqMuZiMi69O8oRv4/W0OGYAvBuSYR6TPDrDPSNMtLbyNjDOT0Q0U0jyF0BbYmEmJ5L+Ifi7+kCuIuqEx3mdcA8/Jh6RepSZKT4uoRg/JhWXepQwJKg7fEomlguBduGlaZ6kLxuXWox9x0ZYOQCeBM/Xlos6yRyPc4fB1yNfkEkHW3U+TrUqH9tCXHrPoDYmluP9Ry0QEZEzw9tJvZknFGxMyr6h5iD9otRAVUf4uNhFSH5m+E1/gtuuUG2Q12nL204kGHNRLlAz+CVAsrPKat7X+GEZ1w/BUq4Mg9ZEykTIPcLvKceQVA2T3OWe5GM5f72sE4SkZO4ov+hmj8HzAup0H+Lv1wZEFWpn4NxQRB0PEZE/wSfJ7uMDU52Sz0GROC7J2w3Oy48SF5LPmTREmMisBToFNyafaZGjvP+Y6M/KSB+fyEv8HnJ6oG+T8v5oTvPXgnA/WIZEfy2YD6sMifIcudYb6EsC2qWgYdwwSVzU4NmBY1cfhLGUVYigK6njvNwwfJQFzl4+hnvsXOg3H4qiKIqidBTdfCiKoiiK0lF086EoiqIoSkfRzYeiKIqiKB3lshWcHmsHKflKsqIPpJ4V7x9uceXLnM+FY1GDWq7scTGQB4ZCmZAUL844vF3bIOqcxeRgQCwiBVBoMoTGZMGAFLGlfsTPU3gTv0aTQdXkBDcvy27gYsVKXQr3Vt46yspzdX7e2WO8TSKi1RsnWBnNmkxmYBOHuMA0OCjNjVp5LhTrWT/N223I/neDiLZQBjOwmDTlQuM0B5OstaQ6KwjGabkMNxWbnpVC0GCYi+OaZT4uXfsMwrcNIL4s8PmI90ozM8fh7ZQ2GBLjgZDSg2Rt0Ul5zSg4i/JcelQdMZhNwUtd+3m5sFEK94JV/lrqBd5IeaU8T6MXBaa8jcpKeU+FC/D3lyFxZAvGqbgezp2UzxoXTBDbkEzPastrdqO8f7M3gXjRkJiNirBe4ryO3zAIEbv4Wgif4ALOdlyOrfBnRGM407SDWVbbN5ixQWK/QJEf40UNLmmQZzRYgjkrSdVzYz0XvAcm+XMjWJfz4UF3PUj4hvNFRBSe430JgADT6ZYDlTzI59CFR5pJdOvDUgjJRwC1k/I1VmfO8N0DDuVqXk6elFWyR858vrXbTTokDzGi33woiqIoitJRdPOhKIqiKEpHuaDNx86dO+mmm26iVCpFfX199P73v58OHjzIjmk0GrRjxw7q7u6mZDJJ27dvp3w+f1E7rSiKoijKlYvl+2h7dG7e/e530wc/+EG66aabqN1u06c+9Sl64YUXaP/+/ZRInDam+djHPkbf+ta36OGHH6ZMJkP33HMP2bZNP/7xj8/rHKVSiTKZDP1/T19L8dTpeOXxZo847ifza1i5K8z1AicqPIEXEZHjLi5xOf5yv3gN4+n1itQYBEKgJZkyOC1hu2N83+dv5YZnzZekmVmrn8eWUbtgG3QiOLu5NB+nwl5p7NW9ZZKVUVeBCZaIiDYM8Q3mZIXrHUzakkiI999kkoZJ7kIJrp9pFeRYpwe4YVsd+oumY0QyqRfit+U+PZXlY1ma4eZMoaTU+rQqvC+pHr6+yuNSJxIqQRKsHr4OLEPCLj8NxxjyPfmY5ApMk0ymUBgHDxd4HUwaR0QUm+bz2ujmdZoZOe94nlCZ13G65RwOf5cHwkd/gfffixnMwEompyVOZJ6fu7oW5tVbOpmWBcnBrG7pxuSVeewfNTm+QSdC8FL6Ob6+StfKNYhJ4GzQjXgGY7LUS/yY6nLQloQNHyNJSJBm+qSB+ypQAFMug8wFjdRiU3wQMJEhkUyY1oTkdPa0fKYFYOhwrdcG5XrC8wRrvByQXotCr1FexdtNH5bzXlnJy8GKPEboTbp8eN+gOwJ9iQ1jEOfSPiIi8kJn2nGdBu3/q09RsVikdFp+hrE+L/ou8J3vfIeVH374Yerr66N9+/bRW9/6VioWi/SVr3yFHnnkEXrnO99JREQPPfQQbdy4kfbs2UO33HLLhZxOURRFUZQ3IK9J81Esnv5rPZc7/S3Dvn37qNVq0bZt2xaO2bBhA42MjNDu3buNbTiOQ6VSif1TFEVRFOWNy6vefHieR/feey/ddtttdM011xAR0eTkJIXDYcpms+zY/v5+mpycNLRyWkeSyWQW/g0PD7/aLimKoiiKcgXwqn0+duzYQS+88AL96Ec/ek0duP/+++m+++5bKJdKJRoeHqaGHyLbOx0nfUtc/nL41vhhVj7a5NqFUkom9aq4XB8w5mRZuTsqfyzd9nisdjohky7NV7jvQh1itZbht/YN+L231YRjVknPiwT4SlRnwF8kIGOdAUj4NLeMx/naq2QQMmSDvwC836pJL4rj89z7ozLG433Rfjm2/SmuzTgy2SuOWb2CG0mcnOJaHtR3EBG1wLPDde1Fy0REHox/5mkeA65uNXiQ7OXXbIGXQDgsA9aZAf7NHupcnDm5VlpZPh9B9E9oyevBhFaUkV4UdoWfC2PAdlPGhO0W728Ih8Vgy+BkeTuROd6GFzQk6EpD7BmH0vBn0/xVkAisCm2U5OOuleDH+APyfnDr/FmC7WBcn0gmGPMjkMjsuNQqYbI5a45fj5+Q68muwVqHx15oRt6rbUieZ2GzBg1LedPiOpdAUa5bv8XPnZiQk1bv532JTYM3y2opIrIhEWEU7I1qQ6IKeWBE4sM946YNPjjgOdIC3wyDRI2iM/B8hUd0pCAruWG47+A+rBr+Ho/lQQPVZWgX1gJ6tbgRg38ITL0F8xyqyjpdB848g9tug/aLI8y8qs3HPffcQ9/85jfpiSeeoOXLz2QIHRgYoGazSYVCgX37kc/naWDAkJKRiCKRCEUiUoyoKIqiKMobkwsKu/i+T/fccw99/etfp8cff5xWrVrF3t+8eTOFQiHatWvXwmsHDx6kkydP0tatWy9OjxVFURRFuaK5oG8+duzYQY888gj90z/9E6VSqQUdRyaToVgsRplMhj7ykY/QfffdR7lcjtLpNH384x+nrVu36i9dFEVRFEUhogvcfDz44INERPT2t7+dvf7QQw/Rb/3WbxER0Re+8AWybZu2b99OjuPQHXfcQV/+8pcvSmcVRVEURbnyuSCTsU7wryZjjz6zccFkbENoRhyHieVecgaXbHu+zcWis02uIJprygRxh+e5CNIzjFbLBTMjSKpWmzBk+ElxAWBggute/OVS+ObN8GO6VnOl1dy0NHUJxblQLJUAUWRQitgmJ7OsnMjwOnFDorzpyQw/L5iBxaJS8BgM8HP3JyvimLEibxeHvzwpTbkGVsyycj6fZeVERiYQrIK5l5Xm/U+k5HxgMrogjKXJMAxNrfxh3m4obHDpAlwwA2tPS3F1AEysXINJWuJ5LnqsDvP+x8cM4lcQgnYdgIRvI4ZILkwamjehKI+IKARLoYlL2+C3FR+HBHwj0Ea3wbEKkrWFx6XZVBPM/TBYbRnM/dC0ypBTTRBo8ItKjIL4coUh4RssFzR586TelNpJ3l+7AeLLLnmvCjE7rEEyiJ5xraNJF5E0tWqDADhUNLQLt68w+zKsDQ8Ev7EJFJOaBJsgzAXxZTRv6BsIsMtr+fqKzBpM7aD7EZ77k+JTcn01crwv5ZWyWWH4B5fYSst2c8/ya0KRqm/ofivBTcYOPHh+JmOa20VRFEVRlI6imw9FURRFUTqKbj4URVEURekor9pk7PUmQD4FXglS/UPpBvH+/81vZOVGm19KfpZrBYiIYnEeB68UeKw8lpLJnuKP8bh9YZMhCRYYOFk13hfLkMDHiy4eW2sbkoVhfHp+lvctauh/Ks41BdNTPA43MFAQddJdPHDpgobFNZgQBaBvrToPNpsMt8on+BzVl8l4u9Pg7QROcZ1CcETqN/JTvN0NK3g2pFNFuTbsLj52fp6fp2zQTMTTfGwrRXR4kmul3QfxdEjuFonKOCxqiFrzvG8msyN3DrxzklJL0szyitFpHtCtrpPanugpPkfFNWAgBvFqIqJGDxg82bxO31NSYzD+Nr7+0RgrPrp0QrhmL7/mxFEpgKhtAsO2mGEwYbmH8rwd16TP6jUkdDu7yXm51ltdvC+lCGjJDEZYZIORWgGSxJmMySAhpVvldXJ75TgV14ExXB+/vqDBzCwIyQA9g51T6hi+wuvMbzIkgczyso9mWYYpxOSMmOCt0WdIygk6l/QBuD+WyRM53YtrVpoGnUUMtCOBJm+juEY+ezBpnPGisQ5oioJVeQ+hrihUgjqGxHjOWb6PruH9c6HffCiKoiiK0lF086EoiqIoSkfRzYeiKIqiKB1FNx+KoiiKonSUy1Zw+pIzRNHQ6e71BGXm0g8MPc3KaCBGhsyGLXBIOVjp5+UZnhmXiGh2CxfDxbJSUeNDKsAGGPAEc1JQ54HIy17DXZXCmF6QZDZW6xQXODZkUlhqVEDYBgLHZluKjkrz3PUpMMv7Wu2W1xNNgsDO4u0mo1IMa41ARldHLkcPhLdePz+PbRC/RsHgrNaS4j4kEuHX5A9zUZ5nEtmCuZR/Hpk+XRAVEmQ8rmEqSiIKQBZbAsMkahkyiobhGENmZcxa24TsudGTctzaYMY0sJvXKaxd+jwokJ27WooVvRBk8gXhnpOVAjvfsvAFVmz0SrGfBYJNk0EVOfzcbRQNoriXSGQRtkFw7RqExZZB1LxYG0REPj4ToFnbICr02vwiY+P8Hpu/1mDGhppOWE+Zg7JK8SpYK3tkuxO38HYwe3GoIscEH42Rk7xcG5BrY+Qx/vw59kt8bQfq8jxunA9mvX9pUWdijLfTyPE6cUNmXzTuKvOUaRSQmnphwofZdImIHDg3Gt1175fzUVgNnYHu1vvkGCROnfm/21x6jM7RtKIoiqIoyuuLbj4URVEURekouvlQFEVRFKWjXLaaj7fGD1IycXpvtNZg1nSizV97qcn1G8/Vh0WdrmCVlY8WeHK6mwdPiDq7KhtYeXXPrDimCpqCQpjH7YOGxFMzZV7HKfG4cbqH95WIqFbjx7RTELMz6BIGhrjrUzLM9RDFBjesIiIKxXi8GnL4UVe3TADXBJO3kRw/L44REVFfircTyhhizSDDOZrvYeV2U8a0E1F+jQ4k/lueKYo6QZvP0fMHeFay+Al5q0Rvn+Z9AZO3dlSaQtkgeLAg56B/DLRLRGStAp3LFNdIZK6Ra3JmghupBVJSp+OANsmHvnkGbQ/qWk69m5dD8/LvmcwhXi6u4+X6gLw/kMQp3m51SD4TaqDTCRb4vLspg5EUaIoMtyqFoJ0wGC+1UgYzuW7ekFsH48G2vFfDkHSsvZYH+01JBy2Yszq2a9CRRCGpWn01X1+RpNRnOUUwtgP9ydy7ZN88uOaZa6W2pw1J7ELzvI6TNpikYSI8lEkZ5vD4eyDRHybKa8r5CBXA/AtMuvy4nPfkGD956Spebho0E7FTfFwsuOTGsDSsa2b4OKFRGZFMOtiCpH3z6+WzEz4iqbqc18kcFlXIO6sr/gV8naHffCiKoiiK0lF086EoiqIoSkfRzYeiKIqiKB3lstV8xO02xe3Te6NxgxSgF8JVez0ek5xvca8KIqJJhydVW5udYeUjJWmU0ZsrsbLjyiHDxGvFIj93IiW9QdaumeR1QHvhtOR5RvrmWLnVzQdh3JBMLwRahkiABwIzUdk3TD6HWpJ4WGoBehM8WHj4FBdrXLdyTNQ5NM3HOxmTsebVWa5n6M5ynUg6LOt0R3lfnp8aZOX+uNSs9Eah3eu4UMG+XgaSn55czsrre7kGJBmSffvJvqtYOb6Mn7dhSJTnFrjW56qbubHBoVGudyIiiud4csBwUN5E1RMQx1/Dx605K/VAAfCvcC2+9j2DPqu0Cnw+IBZt5WRMG/1dymugjkEzEe3lY9fK8vvDL0ndUe/yAiub7ju8ojporyxbrg2MpqdTvG+NptQ/xEb4OPQl+dowzTP6lGR7eZ3CGNzLROT08LVgh3g5m5RrcLrJxyUS5esguosnuSQiaryL+zPVXTlnkS7+/HFAwBGZlvPRzPH++nFetoJyPuwgzOIMn8Ng3eCT0c3bbYJPTCQv+5a/CdpBv52m/Hu/vmrxJIR2SZ7HbsF5DP40zT5+o8WP8zVn0lphIrxwcelEf2drYTxNLKcoiqIoyuWKbj4URVEURekouvlQFEVRFKWj6OZDURRFUZSOctkKTl9u5Sj+SsKs400pBH2uwsV+/3KQm4H1dstkdLPP8Xa6r+MCwdnn5XncAS4aLMSl2LIFYiwUmHbFpYDr1FyWlVNxXqdlSPjmQUalU0e4qDPYLc8zeoKbcq1Yya85F5VmZhFIzObMc+EhGnIREVXAROzNq7kocqomBWk9KX5u7CsRUVeUX9OGrilWPlXNijrTDe7cVZnmxl37G1Lsd+MI7282zM9baMqEb7cuO8bKsw4/z0xDGob1r+Ui50iAi9qqYSmKjOS4cGyixEWEmEiPiCgF4t18XoqRKcvPHT4M/e01GEehaBAEdLYjlW+YjK5/D39/ao0UqQbBFK1d5nOGZlRERKEQ76/9M1hzN0pzuToIP9uG+y4H6zQR4eNdrkthLpp/FWb5mkSRJ5EUXI8V+ZyFRmUCu8R1XIReOphj5YFr+P1CRFSocEG8M8nLzYwcg1icX3N1jt8P9i9wYT6RfO5hAk4iosY0bwcTvLUTBscwXC6wBn2DGJlgPaHAtNEv17o4D4hHW6ulujJyEJJ9RiBxnsHMbPnj/EQnfxHMzWqyTu/TvC8z18vvEcIz/B5p9PE6aGZGRORGeF9cWNpC6Poa0G8+FEVRFEXpKLr5UBRFURSlo+jmQ1EURVGUjmL5vi8DrpeQUqlEmUyG/svet1AseTpm9cP5deK4/dPScOdsTPFFjMNWCjzWaYdkfNEFsyMRByQigji4leTxw3BU6kTQyGdqhsfxIy/LOLK/ietYXIxPn5S6BEym5YMBz7IVMilZExKxzRV4vDqRkLHOOMTB4yF5zcjRY3wOV640xKdr/Jq2Dh1n5QMFuQ7Q9M2FtVAyxOjROMqt8XkfWM5j60REAVhPxfrS2pgQmH1VG1zj0XSkHiUI+gC8YwOGbGi1eYjJR2SA15+HZFtRiAk7hr9N4CU/CoZVBkMkC7oXKvFGmllDwjdIOGYV+Lh4CXk9IUjs15rj8xHpkZqolgMJ3zDhGBH5cH8HYD5Shvthfp7fM74D96olz2PDWHqwBgMlqcWgQX7NmTTXp8yNS61PsMjbbefgXjUkqAwk+TGZFDexq9QMzyu4xJjhOVg5DgkQQYvR6pV1cJx8TJ5XMeiBIElcK8PXXHhOju3AHn7usd8AHVJV3qsWfobA/dC7V95TlWG45jQfOMNHmUAkyjMQmePndrpkHReSlWKyw1ZS1gmVzzYZa9DRP/sDKhaLlE5Lg7uz0W8+FEVRFEXpKLr5UBRFURSlo+jmQ1EURVGUjnLZ+nw8X15OYf90TPqpPevF+26Sx6aiOR53bZTlb+LFb+uL6B0g92LuMog9Y6IgIoq+zM/VWMc1Hyb9CSawCoAWw+mVMW0L49OTPM4aLhs8FrAdOGQ8nxV1EmmIYUN8unxSxvJKkLjpputeZmWTzwfqKMbnZHx68/JRVkaNx6npLlFn07IJ3m6F9zcdkzF61GcUmtzzYnJCnicKGoNGka+D/qGCqDM9y8chm+Ux+vopOU5ejp8nnQYPkilZB3VIfl3GtDE5G8boc8/J+2F2M19PoTy/h0w+AOjVEORyAWpmRRWhv4pO8L7UhmSd4Emus2gPQGKwmvRQQT2HHTbcd3k+r/4QXz9zmIiRiGIZfowX5edpTkgPGA+0C0HQeFgj0pOnVeXXVA6A9gITqpHUeOAzTehTiCgKeg3UeLQnZCJPH5Le1Qy+NwRj2Srx9RRJy+SM6MXio8bDYA3STvC+oO7INuR2m7gVtDGQZM2kE0HvDNRvzF5v0FmAvskGTU7A4A3iw62ZPSCPqfeDlgT0GrFpWafCbyFqpflgZl6S1xysn2nXXTxHHkO/+VAURVEUpaPo5kNRFEVRlI6imw9FURRFUTrKBW0+HnzwQbruuusonU5TOp2mrVu30re//e2F9xuNBu3YsYO6u7spmUzS9u3bKZ/PX/ROK4qiKIpy5XJBgtPly5fT5z73OVq3bh35vk9/8zd/Q+973/vo6aefpk2bNtEnP/lJ+ta3vkVf+9rXKJPJ0D333EMf+MAH6Mc//vEFd2yslqGgdVroFVstkxZVQfTooTEOJsAiInuai6SsFVzA5VjSpCvWxcV9aFRGRGQ3QJAGAqhAXKpwCuO8/xb0P5CTQiu3BQmU4lwM1HblXhJNb7q6KqwcDcmESmjSJd4fMtSBc9faXAhnGjcU4maS0gTqSIEnm1ueKrByNSNFhMUmn+dSlZcHsjLpYA3MvlDwONgjk5JNzHCB7BAIaE3eQF6TC7ZCYBAWLspazSDvWyMK428YWzx7dFCKFdGcrApi19lbDeqxBoj94AkSlMNENiT+yhzlqrzaMnnNLghkq+t5XxKH5LzX+/n1JI5DG9cajO/gvrOmpFDd6+H1/BKsbUMis7rF1xz217+B34dEREEwoHNzcL8fBjUgEdEA71v4GX5Ma8V5JEyDOQ11S0E2Pl+9E1w8Gl4lr6cxy5+nblquJ7/OF5DdAIPAY/Ka0QiL4F41JR3EhIdujA9C2CiUhGdyhY9Ts1uKkwMV3v8wGnv1GbK5wfLBpHdu1GDsVeTtNmROVDHPKFJtdMt2EycWN9UsXi37nzp8ZlxcQ2LJc3FBm4/3vve9rPzZz36WHnzwQdqzZw8tX76cvvKVr9AjjzxC73znO4mI6KGHHqKNGzfSnj176JZbbjG26TgOOc6ZD9pSSW40FEVRFEV54/CqNR+u69Kjjz5K1WqVtm7dSvv27aNWq0Xbtm1bOGbDhg00MjJCu3fvPmc7O3fupEwms/BveHj41XZJURRFUZQrgAvefDz//POUTCYpEonQRz/6Ufr6179OV199NU1OTlI4HKZsNsuO7+/vp8nJyXO2d//991OxWFz4Nzo6es5jFUVRFEW58rlgk7GrrrqKnnnmGSoWi/QP//APdPfdd9MPfvCDV92BSCRCkYiMs06W0xRwT7/uOIYYXi+PSzbLEAM2aD7694KR1Doev8qsnhd1Zk5leX9zUpdQW8PjqqF5SMaTlf1P9PMYfGs/14C0XDkmSLCP96UVknUSSa4dcVpgCmUI0RXLPFaLic2EvoaImiV+7kNeHyu3m9KcpqeHay9mZqVZFhoeBZbzObyxT25Wj1dyrJyK8zHIRuQcEniInZzgbSRCMijcDfoZDzQsU7PSfGp4OU/kN/2TQVZO3zwt6tSbfM6cA1xrYqUMrkrngZhHDAEb5hmNlTCWXl0lNQaJY3z9z1zH2wiWDToqSHrnhSDZliHHmgX3fAXuS6oZniOQMC06JbUktQjUi0NiM8NT1AI9TW0ZxMrrMilZKM2PaZ3iugpvSK5BC4y8qqvhek7J8zRWgZ4MjL1a8/I5Eujl90wbdDBe4zw+SoqyL4lx0ESADsGNy7WN84xaBlwrREQtGNvYOO8v6oWIiGww98IEiaYko+EiXg8Y7JXl3/s26kLAGDI2JscWzcuaYdmZ9BFMpgfnbcj724P7qjGAieZk/8PFs03Gzj9P7QVvPsLhMK1du5aIiDZv3kx79+6lL33pS/Rrv/Zr1Gw2qVAosG8/8vk8DQwMXOhpFEVRFEV5g/KafT48zyPHcWjz5s0UCoVo165dC+8dPHiQTp48SVu3bn2tp1EURVEU5Q3CBX3zcf/999Odd95JIyMjVC6X6ZFHHqHvf//79Nhjj1Emk6GPfOQjdN9991Eul6N0Ok0f//jHaevWref8pYuiKIqiKD9/XNDmY2pqin7zN3+TJiYmKJPJ0HXXXUePPfYY/cIv/AIREX3hC18g27Zp+/bt5DgO3XHHHfTlL3/5VXXMtnyyX/EvwKRGRESVUR5PD+DvuLtlnfKv84xW9aM8CBZeKzUfQfhtuts2BJvhd+ZuFL5QmoJkT0QUX8c1H9M5HltLHpVTU9nI+xJCLUZSXjPG9eszkACqT/o/oG9EBLxAsnGpmRiFRHmoE+ntkt4a8z/m4bjo9fJn1oND/LWQzdt1XDlOyRCPaR+tdbPySS8r6oTBY2HDCBdJFx05h9MTfP2ke/hYRmMyRl+s83YamLiwLuPtDugDIuv5WLarUqcQh6R36MNCZFgLEDe2MGGXAdReoN6JSMbkbZBi1Aeld0Dvk7ydwsbFz2sE/U8CBl+Dp7m+qXKd9LgIneJzgon+TFFuH+67yCR4RBj8EDxIUBnYxDVF/d+QydsmfoEPZgCeAY0Bg6gLfD1wPnzDWmkUYP3DRXtNqeewHEiUV5V9Qe1CGxKGhgpyolvdvMMWXE/YkCA0OAa6ihw/rxcxJHwDvQk+kx136UUYqPFrxgR3RCTWaRI0UtUReX+g1goT2hERVYZ5uzj+QbnUqQnzgQn4ug4srumwWq+T5uMrX/nKou9Ho1F64IEH6IEHHriQZhVFURRF+TlCc7soiqIoitJRdPOhKIqiKEpH0c2HoiiKoigd5YJ9PjpFLNykYOS0QGamKJMLhcBgqzkPgqiW3FdVIcGY380FgeWKTCzn5Xmd4FBNHIPnyh7gwp7522SSuPkiNxAKZLhQrLJeCneiad6OBwngUglDQigwvqqDOLZ+Qhp75dbxBGlocnXioPRtuebaE4ued6oq53DkHbzOwROy3QiIyzDp3ZPjK0Sddpsf44GADgW0RNIQzOvi/W+05K3SM8DFsMXnubDVHZbzgUJcFEHW5+UaDMO8NypcmBiclILTKooGHXk/YDJDTMTWShmSAYLGrp2ExIUvSFHh3LX8mDgYS6FpFBEReuyhcVT2sOzb7DWQ/AwS2vlxqcqrDfB27Gk5lt4q/qxJ7OHCz+ZbpVAa56jRx8fAj8q+NEQCO97G/HqDkHKG35temK/T6HIpKPcO8XtRJEiz5dhaYX5McAImyKAzTIzy+SivMog6u/g1R8bBUK/HILaEpIORGZhnw5/U5XX8nk8f5OPUShkSkaJp3QYQkLflifwi3CB4yQbRc+4Z3k5pNYg+i4bzwGm8oGxXJKiL82MCTYMYGbBb8PnRK+tE586sbd8gfD1n2+d/qKIoiqIoymtHNx+KoiiKonQU3XwoiqIoitJRLlvNR9sLkP+KiUuzIuOw4SSPv9kJiJcajHKiz/N4enU9GIgZEh/5CR7Eck9Jo59wY3GNR3BcGkdhDNtNQNYiQwzVATMpK8jrNA0J+DD5WWo/JOy6rSjqFEr8Gm1IktW9UpqxlZv8GjNhrnfIRKX+IV/mepPVwzKp2oFjQ6ycyPL4+0iX7MuBo7xOHOpMjkMWOZLraW5/DyubTHyCV3NtjL+CnyeAJldE1IQ5TD/Hy+UbpD6oBfMahWSB9nqDW9AhSGpnyD3XzoD+B5JrmYyXAjXQGR3j5ZohjVMQZAf1AX4ekynUPOhE7AY/ZuLtckICFX5Mzz5ent0mTd/cFOhPDNoYG/RLxet5O1ae67eIiHyc+xTXHNhFea/6oB0LoJnZNXKe2zOgEYrCM8GQ8M0DQ0OrDYnaYobFUoHkc72QwG5UPqMduM3ik1IvUE7wa25CIjYyJInzfUgyCJfYTMv+B0tcJIEmY35E1gnnQRcC+hN7TH5etNOLm6QFS3J9VUZ4OQm5MgubDPMBwxI/ZTBjA8OwAHxOBeSjhtr48QbnCZfkfFSWnbkm13D/nAv95kNRFEVRlI6imw9FURRFUTqKbj4URVEURekol63m46bekxROno6p2QMyzpQJ8vi6Cz/uDlgyTta4Hn5D7vHLP1CQAev5Bo+pzsxIXwwXEhtRk5dNfg8W/pbegWRP8zKeCLYM5Af4NSd6pAfJ9KksK4duhAB805AIDGLc6JOBmhAionKQaz7cDK8zkpLajESQx87HyhlxjFXj/WsnIfZfAm0DEcUyfLxrBT6HuT7py4AeL+mruJ4jFpZJ+1qQWKpd5+sp1S09FlplHhsvXQOJ5UQNIh8SvLkRrh+oz8ikd5HVXOvjVKTuyKosnhjLN3gSIJURjCvLY5KneLm6DDQGhm6g90cA5BqewRuEYN1W4DxeXT7uUOPhpw3JGQugZwCvHNM4Zfbzc5U284HBxGBERNTPj2mX+HntjCFIDxoPAv2GR3JwLfA/CYAfhNc2eF6AXqAdA98Pg/2RkwVdm1ymMonaStBMTMs5w8RyXhB0O4ZlGyovvp6aOXnNPj6jp/g9ZNKBocYDPUdMOgsb/DaK6/mchgryO4JmP4xBaOkkd2GQ9zW6DZouWAv4MVodlOMUmT/Tjts8/8Ry+s2HoiiKoigdRTcfiqIoiqJ0FN18KIqiKIrSUXTzoSiKoihKR7lsBadrYtMUjZ3u3ptjx8T7LXCWedFZxspTLSlEDIFC6GCln5UjQZlwrFLnIqNQVB5D8NpgFxc0njjeK6qEQTxmT3LBY3tIKpMCIHSLRrk4zkNFKhEFSnycBlbOsHLFMZgDQRI1FwSnrVPSVAm0lxSAMXh6gs8PEVEAzMsqBSlktTJcGdas8f4G90kBsH9jmZ8nZpgzIPI0v6bmLbzOUFqKVA9N9LEyGpWVp2QyvWQvF6FWT/J1ahnUl8EBruazQQhnJ6VI0pnl68mKG8YA7qHILCTkq8i/TUb++CesfPS/bGVlFKwREbVguaCQzzNo5bCd+AQvF3oMxks2P8bphXEyCWxBH+c3DSZjWT6v/jR/JmCiPCKi4iY+J6lnudqystqQMA3LYKzWdmTSQQvUlX6Yl8Nj8hHfTvBj0Bir63k5TlW4fWNH+X3Yll0TiczCcwbhZAbmCEzsWjk5TskjXIxfHebHROZk/90oCKNB8GvqG4JJ1kymaZioEEWppnGiGC5CXkRzMCIiq8772+iX4xTN83EINGCtGC65CSLhcImfGw0DiYi6D5wRSrfbBsX5OdBvPhRFURRF6Si6+VAURVEUpaPo5kNRFEVRlI5i+Zil5xJTKpUok8nQt59bSYlXkj79oLJRHJcBV5uTTjcrP1/gycWIiF4a5SZicUjQtSwjk6xNQvIzp7m0TCad4HEv1FAQEZWmuR4gBHoB1FkQyVg/mlr19EtdwjwYgnWl+bilDQnfRqd5Rqj2LLgDGcLtFuhNcmu5SdfsrNQ/BMNgVBSSccv6DO9/oAq6hB6ZLAwN3MIv80BrY7ms09XHdSKlMj9vOCJ1FYNZPt4zFS5uqDcMiQpP8mOyV8+ystOW8erKCW6+NrCbvz/xVtOE8GJ4RraLsf/4JMSRc/LRgMnmwkVexzaZKIHcBJN6ockSkUEXAh5pBg9BkawRcbMm3Qu0WzeY7mG7kNCRWvJeDXXx+8ob4+vJ1NfoFD93fQ0MpqFvQdCxuHEwQIsaNBMvcb0G6i58uWxp9d/xtX5sO9cqxccNSeNWQ3LAlkEP1AV6DRgDp0f2P36KP/eyR/h5Jt4j728q84sKz6IZmJwPu7243qEl5WZiXoOgXcodkNczv473xQMZntHsDwz1XEMSyNgUP6YFj2A0WiMicrrwmYBjIM/jnGXQ5joNOvT5T1GxWKR0Wuouz0a/+VAURVEUpaPo5kNRFEVRlI6imw9FURRFUTqKbj4URVEURekol63J2IHmEMWc0917uSZNupDjlRwrHz3ZJ46JpUEEBiLJ4zO8DSKi1jQXK/pBg7AHjHxm1nFxUyrNM/ASSZOYdg3Ok5DiuGQPVzzVTkHGXVo6w2u5xpV7uZhMR9mq8v6nl3OxWdMgoF2eK7DyVJmrm7q7eZZVIqIGtFMpSAeeYBEyx/ZxlVQsIVVTaF5W7eUKLhSXEhFVwUzOm+d1oiNynHCNDS/j4tHSpFSkhUb4HM5A1uH+ES7UJSKq5rjwcHIr72v6kJyP8loubDNlFA2X+BrsfpGLak+93fB4AM1gYozfD05m8ayXpkZQCEdE1Pssn8P8zSBsNYjlwpD9s9HL20BjLCIiFwyemt1SEGiBSZ3fhr/ZDM+ENpi8+WDkZYWkYjbyEogtrwLxqCvnQ4gRU3wO7Tl5zfVBGJc8v57qMtm3o7/Gny2RWT6HmeNSkF1ZyfvbTsp2o+P8GKeXj1PfbimynX0TCEwHYQyKBqF3nLfb5L9PMGaORYMwp3tpoTSKal0wfZu+Xp4HRcKY8dgk1A2KjxR5jAsi7TaavhVlnTicuw3PjfikQShdOPNau2VQgp8D/eZDURRFUZSOopsPRVEURVE6im4+FEVRFEXpKJet5uPleh9FAqdjd5uS4+J9F2Jca+LTrPyuvoOijgOJtE7VuZlWviFj9KUsD3rVWzKeWOvlr0Wf4aZQ4S1S7+AnZWz5bOIZqRNBDYHw5GrLGF4jz02tUsu4fmOsyPtKRJTt5f2tvQCmYwkZ96uluJahJwnahopMRlfJ82B/MC0D+ZgQCjEm04MwsQXtooEYEZELJkSxCd5IY8DgvATjPQ+6HdQKEBG1ihCIBcOqqWmp27GneJ1wlZ+3vEauJdQCmLRKiVFenrqBX2NEyk/IAnOjeg9/v/c5GfsvruDtJsb5NTsZ+TfQ1I2Lm5dZrpx3NC9DDYjpTy2RCM9gNuWD4V8AjLuyj0tBTWEDtAH6AC8q+1/cBPMIuiPULRAREZoeymYF0WnQeEBitti41FnYMK3VEV7Hbsv7wwNdS2TakPANdAiodyivkBcUgmRnaDjX6JXjFJzh/WvnQMcTlIsDNRKo8WilDLodSM7YAH1N8pgcAw/uZ9QqpY+KKlQbwMSLct1Wh3kZNR7BukG/Mc/PXevn/Y0U5dh64TPt+qr5UBRFURTlckU3H4qiKIqidJTXtPn43Oc+R5Zl0b333rvwWqPRoB07dlB3dzclk0navn075fP519pPRVEURVHeILzqxHJ79+6lX/3VX6V0Ok3veMc76Itf/CIREX3sYx+jb33rW/Twww9TJpOhe+65h2zbph//+Mfn1e6/Jpb7h2fWUyJ1Ot60MlSQ52+MsHJvgGsZxttcp0BE9MPCelZOhbgHxndelgns3rPmRVZ+cnqlOGamxPUMTUgo1p2Tmo9wkMcc602It4ekXqAbPDnaHt87Fh0Ze06HebD8yDj3TPEL0gegf+0MP4/L434zeYMuIcJjgf4s1ynEh6W3Rm9KjgsyNss1KfZBMIXYKNvtSvFxKj3Rz8or/s3xpc8LWhiTt8kAJJYr1vn4p6Myy9roFF+XXoOPLY4jEZGF0gWbx1Vd9J0gIhs1H76MnXuom8D8aWOgTyGpwUH9QDNr0JaM8fP40N2WlAMJ/41WFmLJptAyXCNqPizDk66Z5g15MUPDoPGIg19QrSj9adI5rnly4V5tOgbPjlGuRbKG+ToOhQ0aItB8ZFJcK+YZrrkIzyua5PPspuUaDKf5WvaP8TZaWVknkgcPjz7Z//goP6ZxNe+/b9B0YZK4YI7PR2terlv8MzuU5XUsw2maqM8CPZDpXiV47nlRWE8Gfxe7yMfAhyRxvuk8cM+HDXqaVg58YuCZEDsl12B9BMQ96CNj0BXGTp6ZD9dp0JE/fx0Ty1UqFbrrrrvor//6r6mr68zDtFgs0le+8hX6/Oc/T+985ztp8+bN9NBDD9FPfvIT2rNnz6s5laIoiqIobzBe1eZjx44d9J73vIe2bdvGXt+3bx+1Wi32+oYNG2hkZIR2796NzRARkeM4VCqV2D9FURRFUd64XPBPbR999FH62c9+Rnv37hXvTU5OUjgcpmw2y17v7++nyclJY3s7d+6kP/mTP7nQbiiKoiiKcoVyQd98jI6O0ic+8Qn66le/StGoIVnEq+D++++nYrG48G90dHTpSoqiKIqiXLFc0Dcf+/bto6mpKXrzm9+88JrruvTEE0/Qf/tv/40ee+wxajabVCgU2Lcf+XyeBgYGjG1GIhGKRKRA6GBziKKviLK6A1XxfneAixVRYDrelILTqsvFlaeqWVa+ekB+O1NocRFY1ZECzZU93I0pX+ZmYPNFqajr6eJCyQCImabnDKJOSGzUH+dtmESF01V+7mCYi5daGWkKNTnKE+yFM1xsljgsxwCFht4IF44lDeLLapO3Ew/JvrRnuJgvdf08K5cL0jCsAu5rwS28TskgzA2CiDMA5WBQir6mIXleKgaJC00iTxCYBmK8Xc8gAA5087Fs1fgxqZy8P2qHs6wcWinFvc0GCN1AFGkyk0OBaW0FFxGGZ6TwLVTm7dQGwXArIs/jgWdVaB4Em4NyrVg1fu7WeYhJQ3PQ317ZLooeUeQZTcm1Xa/zOcpl+BzlZ+W6pSwfyygY0LXbcmyjMW6g58AxTTQhIxLKW6+HtxEal89jGwSaBOZs7jI5bt5VvE5qr8wgWF0OcwT3hxU2CIAh6WarxheLZUjKaYFwslXh84PGikRE1kH+7PSv4nPYnDf8AW4ygjsbg4ldoIHmZdBGy/AdAQhXW1n5rEGBabAEiQtzBvEr3EN+ls+rFTYYuJ31AwtL3grn5II2H+9617vo+eefZ699+MMfpg0bNtDv/d7v0fDwMIVCIdq1axdt376diIgOHjxIJ0+epK1bt17IqRRFURRFeYNyQZuPVCpF11xzDXstkUhQd3f3wusf+chH6L777qNcLkfpdJo+/vGP09atW+mWW265eL1WFEVRFOWK5aLndvnCF75Atm3T9u3byXEcuuOOO+jLX/7yxT6NoiiKoihXKK/aZOz14l9Nxj72xC9TJHk6lvSW9CFx3GSLm0A9fJyHdW7pPy7qPDXNjckiYPSFGgQiolSEB7HmH1kuj/kgT3x3YryblYMRgzlQgccLAxUe1/P7ZfDMc2TMlx9gcMqBuJ9Vh5ieIQZJEGe1qnyPahnCml4Xjw1GEjyOnIrL6ymUeNy7XTEkb8P+Q6wzKLLrEbmTYPrUw8+NuhcTGM81mvis4O1aGEs3zFe8i+s36lUeX/drhr8H4JpxDPC8RETBk7z/zZzBvAwNg6AYLMlYszAZm4Gka4aYL0itqJnhbaAJGRFRdRmMZRji1zVZBxOM4XkoKxMXhk7x8W92GdYG6HLEfWYwXgqm+P3gzsE8GxL9WZC4zE/AeZtyPjBZWxPM2EzniY3zNYb6Gme5HCfUTOAzLfV9qWEpvQ0MzwzJAD0wy8JnjclMzoe1YDlLm8mJ51waEsvV5b1q4bxD33yDYZjV4H0JlXnZNeibUsf4MeVVkJBvVs57C9Z2O24YKNDz+dD/UMFwzdA9XBvheUPy0rMS4XmNBp28/w9fP5MxRVEURVGUV4tuPhRFURRF6Si6+VAURVEUpaNcdMHpxeL21CGKv5JY7oflq8T7tyRfZuW1WZ4MbS/oO4iINmSnWPl7L/F2R4ZmRR0bsm3Nv70hjmlVId4JXg1erykLFgeTbXlVqX+wa4vHNj3DbPqg37AdHrMLlWXcD+P6HsSNXUN8MTjNrzn8Ao9xzw1LrxMbft9OhuRUAfhtOsZQMc5PRGRBXNVtg/4Bf0dP8jfwcYhtmuLI7Rl+zRbGtNNS6+P/DBLlgT+Ki3F+Ikrt5+epDcKctmQctpXhx8TGTH4PvIjzjmuFiCgAr6VOghdFzBATzvHXYlO87HCJ1Ol2j/Oy0wU3iEHelD3C+1JaCd4gJelf4cFL0bwcp3YM7hGUyhhkIn4B2oGxDVXk333iGQBaEtugLfGXkIEFK/KAZhcfpzB4qMSOSu2bGwefjBS/vtIqee7oz/hzUWhwSHpctFMwTkV5zSGw5IgUYN26hvOAjGX6Bn6NprXuRvnYZY7w9+t9pmcnL9uogTI8rxqw/u2mYXED2Zd4ubzS0JfK4p8XOPZERBY8suJ5Xqm6TPYlXDxzHrdx/t9n6DcfiqIoiqJ0FN18KIqiKIrSUXTzoSiKoihKR9HNh6IoiqIoHeWyFZzGbYcS9mkRzUQjI96fjvLkbdeneTbciC3FfrMOFz3eftVhVt5zYqWoc90ybiCGpjhERLEwmLmsKLJytSwTEIW7uHC1SahUMiTbioK5FAgcfUNSo94nuHB1+nY+LibREQoPA5BEyjKIVL1l/HrK3ZAgqmoQRIGIzWTk1U7yYxorQDlmEFtakIgJxWRCGEpEq/+RJ406/BvcqMwynAcNnLwoH9u4QbjXguvxQ2CYZEhGV1kBifJAeIxCRSKi7Av8xUavPMYB4WHiFK+DBkNERMlTvE69h9fpOiwTjLlh3lDuJa7Cm9sohaAOiFQTYyDMNeT0skBoiOMSqhrEi5BL0pVdIYI5cfr5fKA52OkXeTEMwkk0XiMiis7wY5qLezQREVGoDIJNEPzivUtE5MNTvz4Ez4S6wcxsBtWwSwuAW/wRbZwzNI/DJIMmUytsBwXNRqO7KDwT4DFiEq5j30prICFiQD6jcQ7bkEsPhdRE8t4MwHoy/ZCg1o/ryWBaB9cUnYXPC8NzA7T5VO8F0bO8vSk2debcbvP8PUv1mw9FURRFUTqKbj4URVEURekouvlQFEVRFKWjXLaaj6KboJZ7WgNwZ/fz4v2/nbiZlTdlJli5agiq9ka5O83RMnd3WT8wLeocmOpn5dXD8pijhwZYOTHA9QMhQ2I5BxLLoQbEOyZNuaJzPP5W2ciDm3ZQBi6nbwdTsSQPdrajBiOsEh+7FmhNMPEcEVHsJdBI3MB1L40yBICJyO/ifWlJaQ/ZoKvo+iEft8rbarLdk9zcCLUZvsEx7NDdvF2R5MuUoGuQr6fId3mQfn6zDJDaoH1BLYnpPJhgLDDL23Bycj7m3wT6IIMuIQCGQPV+OLchju8FeZ34JK8z/SYpFMGY9fw6WF8QFyeSuqPCRmzUUCfCxwXP68bk2NaGeUOBqvx7DOPcPiZZc5Y2DGvHlx7bymo+z2gqiAnViIjsJr9m1AuY3PFE8jw0EczKZ4IHzwTUNlRWGIwH4dY0tWvVINFlBDRF/PH7SiVeTJ7k4+R0GUz3wLwscYofUxsyjS3oNxKgzzKYy7mguUFdVSwv+9aGPJhootY0mFQKs8iKoV1Yc2gg1hhY2vQNNVA4p0REickzDbdbco7PhX7zoSiKoihKR9HNh6IoiqIoHUU3H4qiKIqidJTLV/Phxajpnu5e3iAGeEs3z/LTFayKY5Ay/Ih5ssh1CF2JuqhTK/CA3HxIxrS6lnN9w/wE/EDf4N2QPMKH3snxsjdsSGDXhB9hg+eI15A+GXaSB6xdrFOTSyDUzcfBP871J/6w1DI0wPug+1t8DJx3yevxqnDukIxtBo7zoGP1HXyegy9IwUBzIw9MejO8jewL8poL1/F5TR/h41ReJfvWqEHCtzdBzN7gh+J3c50L+sZExqRmopnFRqCYlGsS23H6ZIA6/SIvz18HCeuMHhEQ08akcXkZR3a60V8AfFcM+g1MloeeC6Z4exXi9m4KGjZYEMRP8jlqdsmD0KPDdvj6wRg9EVETHlmokTBpDLxuflEe3A9W3eCDAzoE1KOYvDVMepOzCWBSPJK6F9R4+BGDtgQSOIYnZbuY2C84j89FOdHRPB+HGmiVbMPawGuujkCivIysFJ7h54nMgleIwfMCdRUE82HyVfLA68eNgG9JbWkfGZMXCGpW0LfH5KHSvZ9fVGENr9SWUkSavv7MMa7jEv1feYwJ/eZDURRFUZSOopsPRVEURVE6im4+FEVRFEXpKLr5UBRFURSlo1y2gtNTzRxFmqeFLBuj4+L90VaOlWsemOAY1EBjreyi51yeKojXijkwtXoxJ46hVVwEGZkEsd9yyGJERMlxNNMBcVBDTk2zGwR0IGayIlI05VVAZYQiNoNBUrvB6wRAl+SWpSgyNgUisAE4YMKQsQsEaVZJtttGY6gJbiDWHJJiy8A4nzO/m6+F8mqD4RaIQ8tr+Dh5BmO11Q/zsTvxi7zsJgxKShD4hub5eU2JzVA45vSA6dicHDcUGgaLUqzoZCF523F+TJsPNRERhcrQNxh+X56G+p7iZniNHujvtBQrthJggAYJrkzGZJYP7cDtgCJWIjlOsQmDyBauKVLgZScr+9K/F5K1NflacLqlCaI3y8cF1w8aSxFJMWy4BMJWNI4jIhsEpXiPhUryPGjSFQQRpGtI1ui1Fxc8EknRJv5uIDIrFxSKeYMgjDYZYTXTiwtxrabBXM7F/vM2ojPyPG4UBNhj8FxZJecjUkD1KPSjLccW70NTEkK8Rny2GPznqLycr41gAxL9wXmJiOL5s03GWnRYHmJEv/lQFEVRFKWj6OZDURRFUZSOopsPRVEURVE6ymWr+Wh4IfJfCRJ+r7hBvP9UfpiVr+vlieUcV17aU6O8znBPgb9/YkTU6e3iQS5vfUkcg0ZkqevneZ0DWVFn8nbQO0B80aob9oVpHkdOPceDeO5t3OyMiCjwLA/8lTfwIKtt0Hy4EAtMjvK+FWMyBolJjFyD6ZAAzNcwqRSR9IXq/yHvb2VYznNtCMa2zI9xk4YkWCXQXmAyPVtez4lfBG0MJmXKyPOk9vNYf3WEHxMfl/OBCd9CJX6MKakUJjYzGWzlDvL1VBngY4BaEyKirsN8/UTmuJ4jMCODwu0+HpC2wBGpmZTXnD3EA/ftKBeghOVtSPU+jP1D0jXeVSKSpmiogyGSuhbUwphi5/mb+blDJX7NJr2ADboDO7+0qVV0FmLyFb6eGt1SM5Ec5XWqQ2BqZThP/Ci8ANccqslBqAzBOq2aEpnxMmoXTBoinI/ESTAMMxhhoXFXdA7aNKx11Jas+CdeafydPDEpEdHyv32ZlctbVvA2DWsdvC8pMcWfX42sHATLA/Mygx4I10uoBno/w7ptg2YFzfxwfRERVQfPrG23ef5bCv3mQ1EURVGUjqKbD0VRFEVROopuPhRFURRF6SiXreaj6QUXsuU0DVlz1uV40PRnk8tZORiQnhexKA+CzVR4cNAtyN/ezwd5gDcQkDGvUJy3WylxDQgNGYLNkFTND0JyJIMWI3qIazzK10K7eRnsDN8MWa9meYDRzckAbwD8Qpwu6Me0jEFicq3ym0ALYEga50NSNd+QGA99SWr9fNxqw3KeMbmW0NPEpTcIoQ9GEPpr8AHwerh/i4v9N3gfODnwCoC4fm1AjpMX46+5Sd6GF5b3R3wM/B4GZYC3uJLXw1h5dE7WwURTXSAQCtnScCBQ4mvBXcHvD4x5ExGFJrl+qXU73KsGzwhMsmbB0vaCBi8K0Du46CtDRJE5OAb9E6IGLQN4T9QH+RxGZuR6wvyToTJvt5EzaXssOIavQbwXiKQ+A+8Pz3AbthLgswJrJVKUfQtCnk5TAkEkXAI9yjJDu+DjgVqGyjJ5AejN0ujh5fRRQ2K8DD/35Fu4x5PJa6axiX8OzV8FvhmGJISo35jdxOukj8mBQ20G+osQEfXu5drD2TdleV8cec1uGHxjyvD87THpT8z/Xwr95kNRFEVRlI6imw9FURRFUTqKbj4URVEURekoF7T5+OM//mOyLIv927DhjAdHo9GgHTt2UHd3NyWTSdq+fTvl8/mL3mlFURRFUa5cLlhwumnTJvqXf/mXMw0EzzTxyU9+kr71rW/R1772NcpkMnTPPffQBz7wAfrxj3/8mjr55KkV4jULHFLiEa4u8wwGKpUKV4oN9HBRWy0rs3o1IcmabxAeBop8GC04xCTCQRMoFIZ5CUOSuBBUqoP4x7CVbE2B+BXMs+ywPE/wMBfZ1ocNrkNAe46PQfg4H+vmSnATIiK/Cf2Xmikihx9TWcP7mzokBVAeTuPWAiu6T2VFncZ63j8bTMXih6QYuToCHQbRcLAg+9YGsShes98jkxCmn4axTPH3GytlHafO+4sJyIiIApA0CgWZaOZERBSd4+tn9hp+nu4XZJ3iWr6eYjO84XZMPoaO/b9DvG9h3leT+VS4sLgwtG0QhkI+SqPZFJo1tVJ8DND07XyIzMu+VJfxcnklL6MwkYjINST/OxtTMrrZa3gZzddQ+EpEhLnN0KDKVCdSBMFstyFBGlwTCilNZnJoRNbo4uNvSn6G90x0mpdr/bJvmHAvgmNgeK5P3MIfPjFImtg0mNi5If5a7iB/xhXWyMUewFveZBiW4n2x2/yg8nK5btMn+LlR0Gy6785O4GhaB+figjcfwWCQBgYwZSlRsVikr3zlK/TII4/QO9/5TiIieuihh2jjxo20Z88euuWWW4ztOY5DjnNm9ZdKhtWmKIqiKMobhgvesh8+fJiGhoZo9erVdNddd9HJkyeJiGjfvn3UarVo27ZtC8du2LCBRkZGaPfu3edsb+fOnZTJZBb+DQ8Pn/NYRVEURVGufC5o87FlyxZ6+OGH6Tvf+Q49+OCDdOzYMXrLW95C5XKZJicnKRwOUzabZXX6+/tpcnLynG3ef//9VCwWF/6Njo6+qgtRFEVRFOXK4ILCLnfeeefC/6+77jrasmULrVixgv7+7/+eYrHYIjXPTSQSoUhEai2mnSSFgqcDslf3y81LPMiDXqUmP386DA43RPTDUZ6gzgKjmVBYBrn7ctzRJv9inzgmNFJlZafOdSK578nrm7t2cVMxk1cLxikbGP0yGXl5vN1AgU+5F5f7T4xpB6FOOyV1IhhzdPr5WNqzUjPhxyHRkcFYzY9CDBI0K5VVBhOiQT5n6X/mGaJq/49MwEfj3DHIz/BAf73PMLYw3uEsD563DFoGvwZJ1SCu3P9/5Tjlb+djiUnw+r4nHbfmr0YjMnEItSB2njy5tKmVDbHmANxm0THpouQHeMC9mQIjrFfxmzuTNgPjzT7odlInZDu+xSthMjEiovJq0EmBjsKUsE74IsL9UbxKBumDNd5uO83XfsigIUKDMxyDqCHpYGKMl0vroA1RgygNieWaad6uI3OsUSsJGiLDY6MOSSrRmKyZlXXCcPu24mCSZjCgQ61CdRm/Srw+IqJ2fPG1YTpPBBLWocbDZI6Hupbyct5Z1I0QSY1KYkIeM30DaK1mQatkSPRXGYJnyzN8QixffpaVh8/cwK5BY3QuXtNPbbPZLK1fv56OHDlCAwMD1Gw2qVAosGPy+bxRI6IoiqIoys8nr2nzUalU6OWXX6bBwUHavHkzhUIh2rVr18L7Bw8epJMnT9LWrVtfc0cVRVEURXljcEFhl//wH/4Dvfe976UVK1bQ+Pg4/dEf/REFAgH60Ic+RJlMhj7ykY/QfffdR7lcjtLpNH384x+nrVu3nvOXLoqiKIqi/PxxQZuPU6dO0Yc+9CGanZ2l3t5euv3222nPnj3U29tLRERf+MIXyLZt2r59OzmOQ3fccQd9+ctfflUduyo5SdHk6QBZBgPLRBS3eaC1CD94nzAEb9dfNc7KmQhvt9yQ8axMhPs/5AdkgNfzILYJnh1z18nYWuIU/9KpvAb0JoaEUKVbecA9AOE1r2XwIMnyOn6dmx/YdRmjSx/hrxWuXjpbkL+Cj2VwlGtw3Jhsw05wXYUfM8QLwQskEOPjZAgjC48OHH9vXuqTgt18XnFOXYPOBTUekZ9y3Uj7TXLdhrshhvoi10Pk3yE9O2LHuWCjBV4h5RVLJ98yIX+zz9sNSGsWavTA7/5hyZ26kyffIiKK5yH5XJWvBR8XMhGlTvA6wofB8J0tJkRLgna9LO2CzsvjIjbJT1aH5H8uGkCQHBc3AevfIKxoQVKv3if5Bc282ZDUsgiaLtDCOD2yTn05JuADn4nnDAkRQbuAPhPRE4bn1WpeToyLQ8ScRGd5GRNWEhHVexfX3LQN3ideyKRkOYPJgwS1GJgA0ZRQEL1aUMeTPSznA8dW9KMs66BuCvU1RETZo/z5WlzJBSeJSYOXFHj9TF/Hn5Umb5PIWQko3ebi43w2F7T5ePTRRxd9PxqN0gMPPEAPPPDAhTSrKIqiKMrPEZrbRVEURVGUjqKbD0VRFEVROopuPhRFURRF6SgXnNulUywLz1MsfLp7Py6uE+8vj86z8sFKPyvfnD0m6jxHXA209wBXRF21RiqismBWtmpgRhxz5NAgK4dAiBhdJU2t/JUgmoJEYG5JukIFglwgFAxy9U+TpINNu8GnOOiCMGm5FEW21nA1WXeIizxnpsCdioiCh7jKq7WOtxsxGLi1mrxvyZTsS2mSCzLdKr/GYGLppHfh5dwEDs9LRNQG869sL1e6OVFDnRaIvm7hGa28ohQwe2NctdZevXhCOyIi5yo+Ll6Fj4FIOEhEHhi42TV5TOo4fw0TqJnEl/XuxRO8BatLiy9LK3klU5K12iAkGIMkZc2UoXMwRWi0ljwuxyCR5+M0c71sNzqD9yqIkWOy/y4kwsMEgmgqSCRN0aZv5vd7wDCH2C4acNUHpUKw63k+/sX1kBCxIa9nDkSqYRC6WvhcISkyL64Xh4ixROHn0E/kM6ENhpbVYTRslOfBxIrROV4nNiefT4XV8Hw6xeuUVhvWCghmAw70zTWslQgfyyCYfxVXS3O56Cw/JlqQ8zy3AZ6V0G58QirKW2n+uVNaxfuWPm744cBZCevaraV/nLBQ77yPVBRFURRFuQjo5kNRFEVRlI6imw9FURRFUTrKZav5sMkj+5X0avvn+8X7E1GuO1iZ4Bl99hTA4YaIUmEe4+oZ5AHSRltqJg6U+bmrdanFiPVyR6f6HI9JtuqGbEJg7GNFIMlaTMYg21PQrsG4CwmneQBUWFg5Mp7oWKApAMMtastYJyaj8yAG7FTluPX3F1g5f6RHHBMd4GMbCPDzVGelo5AbRpEBv57sCn5eIqKix9tptiG5U0Saf80V+BoMdfH4dGhKzrsN0+q7vK/hmAxYu9CXvid4nambRBWRpM8yeP+UV0JivAKMm+FPE9RvYJK1tkH/UO/jx6SPcS1DdFau9eoQ18ugEVMzK8+DyebwepxugynUMC+HSnJtl9aDKRoYVgUqBv1GBM4FpoF2Q56n3c9FN+Fxfs8EDHXQCE4ktDOYFdYGeDsR0LTMGkwR4+OYZA1M4LjsjYiILDRfNMizUDPUjvN2W3H5EVUbhP5h0fCpFi6DXmMVfz85Jp+lFnhwpY+BKeWIfPagwRkmhWvF5FpxungZTetaaTkfkQL0bf+8OKY6wJ+ndTDqC1Tks8bywIAOPhOTJ6QGZ37jmYt2m+f/fYZ+86EoiqIoSkfRzYeiKIqiKB1FNx+KoiiKonQU3XwoiqIoitJRLlvBqfeK5JSIaLaUEO+3XK5UmqomxTFIwOaiotk5XqdoMMJC06e2waDKA+OY5GEu0qmOyOyBiZO8/xXIaouCQSIiP7J4ZsxQWgqIWnkuUrVBLIriOSIib4YL3fwCCN3WSPGlm+TXaBX5GIT7ZZrV2QIffz8o++LDS7USN+kKFKVgNrySi6IaYMrlegZTLjBjc0CoV580rC8UEcJa8VdKcZYD5nHBGd63VkGurwCIOutgxOQZxMnhWTBAS0lBXaCx+N8ebUPWTpQ8JiCbqRuWokhcp5VlvG/VATmHKE70DJptBDP5oijVJHh0wYxNXCBJ8y86Dx+lxDG4v0G06hrmwwJhdAAyorYycj6cLv7a4E9QCGpYT4ZsxWcTm5SD0Mzyso2mYsYxWTrDabCyeLbi6TfJiQ9xLz+xNozzDH5/KPyu9RvOU+H9H38rV5OaMrziuWv9/IKa0p9RrLnuF3gjY2+Tc9hK8Erj26RYvwUfm5gpevYGULoSUQvN+6A48yYpsm2mzxzkOoYb6BzoNx+KoiiKonQU3XwoiqIoitJRdPOhKIqiKEpHuWw1H6NON0VCp+Nwt43IJHHPz3JXm2pDmlghHsT6U09z/UDsF6ZEnampDD8mJQOm9TGuB6hs5JqI6AnZtxZICCwwSPJjUicS7eLnRvOv1jTXdxAREYTTLZBreCadBWgZ2tfwYLrVlDH6QHQJk7EiH2sTgYps18vyOfNBC4PGUkRETYfHb/0IH8tkVGpjagkeFMYkfqgBISLqHebGPtOjPIZqG5LeBUGjgmONpktERK0M70s1wA8KFWSlVobPhykpWRt0OtFp/jgw6SxCkDiuBv5/GEsnIsocBWM4iIPHZmXwvJjhx2DyNkxIRmQwQIPhbxtuD0yIZhp/GwwBUcrgGXRTbYjJRyb4YKKZFpHUEDQG+fygoRuR7H95GM3lDAZVkMgvBFqZuWtEFWqneV/C07COZQ5FMS6YjI6IqJmDBIh4PxskBImT/EVMhFdcK+sEoF3UjZjA+UDTMTRaIyJKjsExaX5ebIOIKMTzXpILRmRBg7kcan2CNXlMAB5zlWFYk9KXjCLzoE2CpHcmGU+4dOZFt7m0zudf0W8+FEVRFEXpKLr5UBRFURSlo+jmQ1EURVGUjnLZaj6GI7MUi5zu3o2Jo+L9m9LdrPylF9/Jyvdf+21Rp+zxoO/xNfy30TNN6eXQgsRfTksGwrMrC6zs+5Bsq0vu8WpVHiTNfZ9rImZvk8HzUIi/Vq3wOt0rZRCv3gSPC7gevyGXgA8xxxD4n7Qdg3fAET62FshcgqsgsElEYWjX75Zxy8axFCun1vBkgNW41JJ4Fd6/dH+FlfOzXMdzusOQAAquMd4r+z9f5D+kD2VRkyPnPbCK98WBJISmRGChGdRigCanV2pLoif4+jJ5dgRBY1MbWiLRHBHV+/gx8Ql+TKQgz1NZBjoEWNpN9BYgIhcSs2HCt/Px/UCMvgzn40sA97MXXlp/ghoVjJWbEv2hrgK1PO2k4QKgoUYPamUMepoNoJko49ga9CigmWh2877GRw3+R5AgrdEvBQ+xMX6NTdAyhMpybFvglVHcwK8xaEj05+QWX0+llYY5RF2Ot3TfqoYEe2djSojYRh0eaLosU0I+0Nhkj8ixndsE7cAhtkGfgfciesI0s/Kal33/zDOt3V7CRObs85/3kYqiKIqiKBcB3XwoiqIoitJRdPOhKIqiKEpH0c2HoiiKoigd5bIVnF4bHqPkKwYnKUOmoMeLV7PyL619npVPNmWinbK7uNFV3ZUqtkSYn9s26NOabRCGgagzHZcinHCQq+6Ka6FvnjxRG86TTPJ250sy6Y/X5n3JZrlwslGRBmgWJNJCE7VQ2SDoGuLjZIW5CCwTlcnoyhUutgwdlC5QwWu4GxCOSiAkhVbhcd5ONcXVWRFDXxwwJsN22/tlRii3i19jdILPT32FXLduAG45MECjlsEMDJKQYQI+TEhGRNTMgjB0zNAuLJc25m80rHUUSnpwOdVBWSk6w8s+1DEJTtGsLD4JCdMGDIZbqK0EIahJcBoAA6faMrme4qf42LXjYKA3LNdTcIrPSRCErTg/RER2fXFhrkkc66EwF0SQzQF5PTYkL0QTNZMBFyYMbIPxnSnpXajI64Tn5BpEYa4w4TIIc9E8y4JkmcIUjuTc40dKvV/OR3QaxPlgQIemdkREYa6HJw+EoSahcfYQL4dqfBDq3fJEZbhXWwl5zMAeSFD3VhDin5DPp9JKvm4Hvz3Oyid+ZUjUKa498yBxmzbRXnGIEf3mQ1EURVGUjqKbD0VRFEVROsplF3bxX8lFUK2c+RrMsuVXYk6Ff2XkwjGhgPxKyXH592Ye/H6/1ZBfn7ar/Ds+ty374kI4BL00XF/mEnGxLw3wiKgbvrIP8WPsIORTqcnv9DzsS5j3xavLJYBhF6rzrwG9htyzYn8tF3IEhOQYeJCPwDV8rezX+DW7beyLIVkCeJd42IYrPVQ8B38Ez/tvNQx5Z+pwjQ7MqWEOhY8HjrUh7GI14etfDLs4hjpQdg3HwNIgD/rmGnJKeCG8Zt6IZwhtuHBb+TDUruGraLg9RM4I01rBr9Y9OI9nOA/BsvTqcj3hvIpxq8vnBq5LHEuvYRgo7D/WMXxn73k4LrgGZd8suD9wDv226TxQDuN9KO8PnCPXFHMAxNowzLONcwZj6RqeTyLsskQbp8+9eNjFFBLCtY6teg1ZCetYLbiepuF5C5F8bIOIqN3izzkP5r3dNnzGNCHc7MHnnyMlBG7zTH/d1un3fUNOIcTyz+eoDnLq1CkaHh6+1N1QFEVRFOVVMDo6SsuXL1/0mMtu8+F5Ho2Pj1MqlaJyuUzDw8M0OjpK6bQU/CmvnlKppGP7OqFj+/qhY/v6oWP7+vHzMra+71O5XKahoSGy7cVVHZdd2MW27YUdk2Wd/sotnU6/oSfsUqJj+/qhY/v6oWP7+qFj+/rx8zC2mYwhfYUBFZwqiqIoitJRdPOhKIqiKEpHuaw3H5FIhP7oj/6IIpHI0gcrF4SO7euHju3rh47t64eO7euHjq3kshOcKoqiKIryxuay/uZDURRFUZQ3Hrr5UBRFURSlo+jmQ1EURVGUjqKbD0VRFEVROopuPhRFURRF6SiX7ebjgQceoJUrV1I0GqUtW7bQT3/600vdpSuOnTt30k033USpVIr6+vro/e9/Px08eJAd02g0aMeOHdTd3U3JZJK2b99O+Xz+EvX4yuRzn/scWZZF995778JrOq6vjbGxMfr1X/916u7uplgsRtdeey099dRTC+/7vk+f+cxnaHBwkGKxGG3bto0OHz58CXt8ZeC6Ln3605+mVatWUSwWozVr1tCf/dmfsURgOrbnxxNPPEHvfe97aWhoiCzLom984xvs/fMZx7m5ObrrrrsonU5TNpulj3zkI1SpVDp4FZcQ/zLk0Ucf9cPhsP8//sf/8F988UX/3/7bf+tns1k/n89f6q5dUdxxxx3+Qw895L/wwgv+M8884//iL/6iPzIy4lcqlYVjPvrRj/rDw8P+rl27/Keeesq/5ZZb/FtvvfUS9vrK4qc//am/cuVK/7rrrvM/8YlPLLyu4/rqmZub81esWOH/1m/9lv/kk0/6R48e9R977DH/yJEjC8d87nOf8zOZjP+Nb3zDf/bZZ/1f+qVf8letWuXX6/VL2PPLn89+9rN+d3e3/81vftM/duyY/7Wvfc1PJpP+l770pYVjdGzPj//zf/6P/wd/8Af+P/7jP/pE5H/9619n75/POL773e/2r7/+en/Pnj3+D3/4Q3/t2rX+hz70oQ5fyaXhstx83Hzzzf6OHTsWyq7r+kNDQ/7OnTsvYa+ufKampnwi8n/wgx/4vu/7hULBD4VC/te+9rWFYw4cOOATkb979+5L1c0rhnK57K9bt87/7ne/67/tbW9b2HzouL42fu/3fs+//fbbz/m+53n+wMCA/+d//ucLrxUKBT8Sifh/+7d/24kuXrG85z3v8X/7t3+bvfaBD3zAv+uuu3zf17F9teDm43zGcf/+/T4R+Xv37l045tvf/rZvWZY/NjbWsb5fKi67sEuz2aR9+/bRtm3bFl6zbZu2bdtGu3fvvoQ9u/IpFotERJTL5YiIaN++fdRqtdhYb9iwgUZGRnSsz4MdO3bQe97zHjZ+RDqur5V//ud/phtvvJF+5Vd+hfr6+uiGG26gv/7rv154/9ixYzQ5OcnGN5PJ0JYtW3R8l+DWW2+lXbt20aFDh4iI6Nlnn6Uf/ehHdOeddxKRju3F4nzGcffu3ZTNZunGG29cOGbbtm1k2zY9+eSTHe9zp7nsstrOzMyQ67rU39/PXu/v76eXXnrpEvXqysfzPLr33nvptttuo2uuuYaIiCYnJykcDlM2m2XH9vf30+Tk5CXo5ZXDo48+Sj/72c9o79694j0d19fG0aNH6cEHH6T77ruPPvWpT9HevXvp3//7f0/hcJjuvvvuhTE0PSN0fBfn93//96lUKtGGDRsoEAiQ67r02c9+lu666y4iIh3bi8T5jOPk5CT19fWx94PBIOVyuZ+Lsb7sNh/K68OOHTvohRdeoB/96EeXuitXPKOjo/SJT3yCvvvd71I0Gr3U3XnD4Xke3XjjjfSf//N/JiKiG264gV544QX6q7/6K7r77rsvce+ubP7+7/+evvrVr9IjjzxCmzZtomeeeYbuvfdeGhoa0rFVOsplF3bp6emhQCAgfhmQz+dpYGDgEvXqyuaee+6hb37zm/S9732Pli9fvvD6wMAANZtNKhQK7Hgd68XZt28fTU1N0Zvf/GYKBoMUDAbpBz/4Af3FX/wFBYNB6u/v13F9DQwODtLVV1/NXtu4cSOdPHmSiGhhDPUZceH8x//4H+n3f//36YMf/CBde+219Bu/8Rv0yU9+knbu3ElEOrYXi/MZx4GBAZqammLvt9ttmpub+7kY68tu8xEOh2nz5s20a9euhdc8z6Ndu3bR1q1bL2HPrjx836d77rmHvv71r9Pjjz9Oq1atYu9v3ryZQqEQG+uDBw/SyZMndawX4V3vehc9//zz9Mwzzyz8u/HGG+muu+5a+L+O66vntttuEz8JP3ToEK1YsYKIiFatWkUDAwNsfEulEj355JM6vktQq9XItvljPxAIkOd5RKRje7E4n3HcunUrFQoF2rdv38Ixjz/+OHmeR1u2bOl4nzvOpVa8mnj00Uf9SCTiP/zww/7+/fv93/md3/Gz2aw/OTl5qbt2RfGxj33Mz2Qy/ve//31/YmJi4V+tVls45qMf/ag/MjLiP/744/5TTz3lb9261d+6desl7PWVydm/dvF9HdfXwk9/+lM/GAz6n/3sZ/3Dhw/7X/3qV/14PO7/r//1vxaO+dznPudns1n/n/7pn/znnnvOf9/73qc/Bz0P7r77bn/ZsmULP7X9x3/8R7+np8f/3d/93YVjdGzPj3K57D/99NP+008/7ROR//nPf95/+umn/RMnTvi+f37j+O53v9u/4YYb/CeffNL/0Y9+5K9bt05/anup+cu//Et/ZGTED4fD/s033+zv2bPnUnfpioOIjP8eeuihhWPq9br/7/7dv/O7urr8eDzu//Iv/7I/MTFx6Tp9hYKbDx3X18b//t//27/mmmv8SCTib9iwwf/v//2/s/c9z/M//elP+/39/X4kEvHf9a53+QcPHrxEvb1yKJVK/ic+8Ql/ZGTEj0aj/urVq/0/+IM/8B3HWThGx/b8+N73vmd8vt59992+75/fOM7Ozvof+tCH/GQy6afTaf/DH/6wXy6XL8HVdB7L98+ytlMURVEURXmduew0H4qiKIqivLHRzYeiKIqiKB1FNx+KoiiKonQU3XwoiqIoitJRdPOhKIqiKEpH0c2HoiiKoigdRTcfiqIoiqJ0FN18KIqiKIrSUXTzoSiKoihKR9HNh6IoiqIoHUU3H4qiKIqidJT/H3Rev25vKebTAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "img=np.load('/content/drive/MyDrive/spectrograms/paz22/spec_P_1039_1088.npy')\n",
        "\n",
        "\n",
        "plt.imshow(img[0][0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5q1EAl1zNeO"
      },
      "outputs": [],
      "source": [
        "plt.imshow(img[0][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1qRe_TSmxXd",
        "outputId": "6697471a-1945-420d-db50-ff68c028b0a8"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "START\n",
            "Parameters loaded\n",
            "Patient 23\n",
            "Spectograms data loaded\n",
            "SEIZURE OUT: 1\n",
            "Training start\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n",
            "<ipython-input-9-b671816773dd>:213: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(generate_arrays_for_training(indexPat, filesPath, end=75), #end=75),#It take the first 75%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/280\n",
            "42/42 - 145s - loss: 0.8689 - accuracy: 0.4940 - val_loss: 0.6858 - val_accuracy: 0.5671 - 145s/epoch - 3s/step\n",
            "Epoch 2/280\n",
            "42/42 - 12s - loss: 0.8579 - accuracy: 0.5135 - val_loss: 0.6858 - val_accuracy: 0.5671 - 12s/epoch - 297ms/step\n",
            "Epoch 3/280\n",
            "42/42 - 15s - loss: 0.8604 - accuracy: 0.5010 - val_loss: 0.6884 - val_accuracy: 0.5671 - 15s/epoch - 368ms/step\n",
            "Epoch 4/280\n",
            "42/42 - 7s - loss: 0.8573 - accuracy: 0.5075 - val_loss: 0.6906 - val_accuracy: 0.5671 - 7s/epoch - 160ms/step\n",
            "Epoch 5/280\n",
            "42/42 - 8s - loss: 0.8539 - accuracy: 0.5130 - val_loss: 0.6900 - val_accuracy: 0.5671 - 8s/epoch - 200ms/step\n",
            "Epoch 6/280\n",
            "42/42 - 7s - loss: 0.8437 - accuracy: 0.5090 - val_loss: 0.6878 - val_accuracy: 0.5671 - 7s/epoch - 172ms/step\n",
            "Epoch 7/280\n",
            "42/42 - 8s - loss: 0.8706 - accuracy: 0.4920 - val_loss: 0.6837 - val_accuracy: 0.5671 - 8s/epoch - 180ms/step\n",
            "Epoch 8/280\n",
            "42/42 - 7s - loss: 0.8475 - accuracy: 0.5090 - val_loss: 0.6805 - val_accuracy: 0.5671 - 7s/epoch - 168ms/step\n",
            "Epoch 9/280\n",
            "42/42 - 7s - loss: 0.8433 - accuracy: 0.5055 - val_loss: 0.6781 - val_accuracy: 0.5714 - 7s/epoch - 160ms/step\n",
            "Epoch 10/280\n",
            "42/42 - 6s - loss: 0.8349 - accuracy: 0.5169 - val_loss: 0.6776 - val_accuracy: 0.5873 - 6s/epoch - 153ms/step\n",
            "Epoch 11/280\n",
            "42/42 - 8s - loss: 0.8198 - accuracy: 0.5184 - val_loss: 0.6815 - val_accuracy: 0.5859 - 8s/epoch - 185ms/step\n",
            "Epoch 12/280\n",
            "42/42 - 7s - loss: 0.8232 - accuracy: 0.5030 - val_loss: 0.6745 - val_accuracy: 0.6176 - 7s/epoch - 167ms/step\n",
            "Epoch 13/280\n",
            "42/42 - 7s - loss: 0.8437 - accuracy: 0.5075 - val_loss: 0.6767 - val_accuracy: 0.5974 - 7s/epoch - 157ms/step\n",
            "Epoch 14/280\n",
            "42/42 - 6s - loss: 0.8204 - accuracy: 0.5140 - val_loss: 0.6756 - val_accuracy: 0.5873 - 6s/epoch - 150ms/step\n",
            "Epoch 15/280\n",
            "42/42 - 7s - loss: 0.8116 - accuracy: 0.5189 - val_loss: 0.6711 - val_accuracy: 0.6118 - 7s/epoch - 165ms/step\n",
            "Epoch 16/280\n",
            "42/42 - 7s - loss: 0.8020 - accuracy: 0.5244 - val_loss: 0.6726 - val_accuracy: 0.5887 - 7s/epoch - 165ms/step\n",
            "Epoch 17/280\n",
            "42/42 - 8s - loss: 0.7924 - accuracy: 0.5424 - val_loss: 0.6684 - val_accuracy: 0.6104 - 8s/epoch - 183ms/step\n",
            "Epoch 18/280\n",
            "42/42 - 7s - loss: 0.7981 - accuracy: 0.5294 - val_loss: 0.6672 - val_accuracy: 0.6017 - 7s/epoch - 166ms/step\n",
            "Epoch 19/280\n",
            "42/42 - 8s - loss: 0.7631 - accuracy: 0.5578 - val_loss: 0.6610 - val_accuracy: 0.6263 - 8s/epoch - 179ms/step\n",
            "Epoch 20/280\n",
            "42/42 - 7s - loss: 0.7645 - accuracy: 0.5563 - val_loss: 0.6646 - val_accuracy: 0.6162 - 7s/epoch - 169ms/step\n",
            "Epoch 21/280\n",
            "42/42 - 7s - loss: 0.7947 - accuracy: 0.5329 - val_loss: 0.6518 - val_accuracy: 0.6392 - 7s/epoch - 172ms/step\n",
            "Epoch 22/280\n",
            "42/42 - 7s - loss: 0.7910 - accuracy: 0.5404 - val_loss: 0.6490 - val_accuracy: 0.6494 - 7s/epoch - 171ms/step\n",
            "Epoch 23/280\n",
            "42/42 - 6s - loss: 0.7748 - accuracy: 0.5449 - val_loss: 0.6496 - val_accuracy: 0.6450 - 6s/epoch - 146ms/step\n",
            "Epoch 24/280\n",
            "42/42 - 7s - loss: 0.7591 - accuracy: 0.5518 - val_loss: 0.6491 - val_accuracy: 0.6494 - 7s/epoch - 169ms/step\n",
            "Epoch 25/280\n",
            "42/42 - 6s - loss: 0.7760 - accuracy: 0.5479 - val_loss: 0.6458 - val_accuracy: 0.6494 - 6s/epoch - 152ms/step\n",
            "Epoch 26/280\n",
            "42/42 - 7s - loss: 0.7449 - accuracy: 0.5668 - val_loss: 0.6444 - val_accuracy: 0.6522 - 7s/epoch - 165ms/step\n",
            "Epoch 27/280\n",
            "42/42 - 7s - loss: 0.7860 - accuracy: 0.5469 - val_loss: 0.6411 - val_accuracy: 0.6450 - 7s/epoch - 156ms/step\n",
            "Epoch 28/280\n",
            "42/42 - 7s - loss: 0.7501 - accuracy: 0.5748 - val_loss: 0.6415 - val_accuracy: 0.6537 - 7s/epoch - 163ms/step\n",
            "Epoch 29/280\n",
            "42/42 - 8s - loss: 0.7369 - accuracy: 0.5753 - val_loss: 0.6384 - val_accuracy: 0.6522 - 8s/epoch - 180ms/step\n",
            "Epoch 30/280\n",
            "42/42 - 7s - loss: 0.7474 - accuracy: 0.5778 - val_loss: 0.6310 - val_accuracy: 0.6551 - 7s/epoch - 164ms/step\n",
            "Epoch 31/280\n",
            "42/42 - 6s - loss: 0.7303 - accuracy: 0.5852 - val_loss: 0.6328 - val_accuracy: 0.6494 - 6s/epoch - 154ms/step\n",
            "Epoch 32/280\n",
            "42/42 - 7s - loss: 0.7419 - accuracy: 0.5842 - val_loss: 0.6285 - val_accuracy: 0.6623 - 7s/epoch - 155ms/step\n",
            "Epoch 33/280\n",
            "42/42 - 8s - loss: 0.7226 - accuracy: 0.5912 - val_loss: 0.6291 - val_accuracy: 0.6595 - 8s/epoch - 180ms/step\n",
            "Epoch 34/280\n",
            "42/42 - 7s - loss: 0.7228 - accuracy: 0.5882 - val_loss: 0.6247 - val_accuracy: 0.6566 - 7s/epoch - 165ms/step\n",
            "Epoch 35/280\n",
            "42/42 - 7s - loss: 0.7091 - accuracy: 0.6052 - val_loss: 0.6231 - val_accuracy: 0.6623 - 7s/epoch - 176ms/step\n",
            "Epoch 36/280\n",
            "42/42 - 7s - loss: 0.7233 - accuracy: 0.5947 - val_loss: 0.6300 - val_accuracy: 0.6522 - 7s/epoch - 166ms/step\n",
            "Epoch 37/280\n",
            "42/42 - 8s - loss: 0.6846 - accuracy: 0.6261 - val_loss: 0.6227 - val_accuracy: 0.6638 - 8s/epoch - 179ms/step\n",
            "Epoch 38/280\n",
            "42/42 - 7s - loss: 0.7010 - accuracy: 0.6097 - val_loss: 0.6208 - val_accuracy: 0.6681 - 7s/epoch - 171ms/step\n",
            "Epoch 39/280\n",
            "42/42 - 7s - loss: 0.7250 - accuracy: 0.5922 - val_loss: 0.6184 - val_accuracy: 0.6724 - 7s/epoch - 167ms/step\n",
            "Epoch 40/280\n",
            "42/42 - 7s - loss: 0.7018 - accuracy: 0.6181 - val_loss: 0.6203 - val_accuracy: 0.6652 - 7s/epoch - 174ms/step\n",
            "Epoch 41/280\n",
            "42/42 - 7s - loss: 0.6808 - accuracy: 0.6281 - val_loss: 0.6229 - val_accuracy: 0.6652 - 7s/epoch - 166ms/step\n",
            "Epoch 42/280\n",
            "42/42 - 8s - loss: 0.6911 - accuracy: 0.6221 - val_loss: 0.6244 - val_accuracy: 0.6667 - 8s/epoch - 179ms/step\n",
            "Epoch 43/280\n",
            "42/42 - 6s - loss: 0.6787 - accuracy: 0.6336 - val_loss: 0.6184 - val_accuracy: 0.6724 - 6s/epoch - 146ms/step\n",
            "Epoch 44/280\n",
            "42/42 - 7s - loss: 0.6994 - accuracy: 0.6206 - val_loss: 0.6159 - val_accuracy: 0.6696 - 7s/epoch - 176ms/step\n",
            "Epoch 45/280\n",
            "42/42 - 7s - loss: 0.6765 - accuracy: 0.6446 - val_loss: 0.6226 - val_accuracy: 0.6652 - 7s/epoch - 164ms/step\n",
            "Epoch 46/280\n",
            "42/42 - 8s - loss: 0.6638 - accuracy: 0.6481 - val_loss: 0.6133 - val_accuracy: 0.6811 - 8s/epoch - 180ms/step\n",
            "Epoch 47/280\n",
            "42/42 - 6s - loss: 0.6711 - accuracy: 0.6486 - val_loss: 0.6170 - val_accuracy: 0.6753 - 6s/epoch - 147ms/step\n",
            "Epoch 48/280\n",
            "42/42 - 7s - loss: 0.6605 - accuracy: 0.6610 - val_loss: 0.6150 - val_accuracy: 0.6811 - 7s/epoch - 176ms/step\n",
            "Epoch 49/280\n",
            "42/42 - 7s - loss: 0.6562 - accuracy: 0.6481 - val_loss: 0.6155 - val_accuracy: 0.6840 - 7s/epoch - 165ms/step\n",
            "Epoch 50/280\n",
            "42/42 - 7s - loss: 0.6564 - accuracy: 0.6510 - val_loss: 0.6172 - val_accuracy: 0.6739 - 7s/epoch - 169ms/step\n",
            "Epoch 51/280\n",
            "42/42 - 6s - loss: 0.6520 - accuracy: 0.6630 - val_loss: 0.6197 - val_accuracy: 0.6681 - 6s/epoch - 146ms/step\n",
            "Epoch 52/280\n",
            "42/42 - 7s - loss: 0.6345 - accuracy: 0.6650 - val_loss: 0.6177 - val_accuracy: 0.6753 - 7s/epoch - 171ms/step\n",
            "Epoch 53/280\n",
            "42/42 - 6s - loss: 0.6185 - accuracy: 0.6839 - val_loss: 0.6226 - val_accuracy: 0.6782 - 6s/epoch - 144ms/step\n",
            "Epoch 54/280\n",
            "42/42 - 7s - loss: 0.6288 - accuracy: 0.6655 - val_loss: 0.6156 - val_accuracy: 0.6797 - 7s/epoch - 168ms/step\n",
            "Epoch 55/280\n",
            "42/42 - 7s - loss: 0.6147 - accuracy: 0.6725 - val_loss: 0.6143 - val_accuracy: 0.6825 - 7s/epoch - 171ms/step\n",
            "Epoch 56/280\n",
            "42/42 - 7s - loss: 0.6278 - accuracy: 0.6825 - val_loss: 0.6182 - val_accuracy: 0.6753 - 7s/epoch - 174ms/step\n",
            "Epoch 57/280\n",
            "42/42 - 7s - loss: 0.6301 - accuracy: 0.6730 - val_loss: 0.6242 - val_accuracy: 0.6753 - 7s/epoch - 165ms/step\n",
            "Epoch 58/280\n",
            "42/42 - 7s - loss: 0.6113 - accuracy: 0.6924 - val_loss: 0.6178 - val_accuracy: 0.6753 - 7s/epoch - 174ms/step\n",
            "Epoch 59/280\n",
            "42/42 - 6s - loss: 0.6016 - accuracy: 0.6919 - val_loss: 0.6196 - val_accuracy: 0.6797 - 6s/epoch - 144ms/step\n",
            "Epoch 60/280\n",
            "42/42 - 8s - loss: 0.6078 - accuracy: 0.6854 - val_loss: 0.6171 - val_accuracy: 0.6797 - 8s/epoch - 187ms/step\n",
            "Epoch 61/280\n",
            "42/42 - 7s - loss: 0.5966 - accuracy: 0.6944 - val_loss: 0.6156 - val_accuracy: 0.6811 - 7s/epoch - 165ms/step\n",
            "Epoch 62/280\n",
            "42/42 - 8s - loss: 0.6066 - accuracy: 0.6989 - val_loss: 0.6139 - val_accuracy: 0.6869 - 8s/epoch - 183ms/step\n",
            "Epoch 63/280\n",
            "42/42 - 7s - loss: 0.5728 - accuracy: 0.7159 - val_loss: 0.6256 - val_accuracy: 0.6623 - 7s/epoch - 168ms/step\n",
            "Epoch 64/280\n",
            "42/42 - 8s - loss: 0.5831 - accuracy: 0.6994 - val_loss: 0.6188 - val_accuracy: 0.6782 - 8s/epoch - 193ms/step\n",
            "Epoch 65/280\n",
            "42/42 - 7s - loss: 0.5988 - accuracy: 0.6964 - val_loss: 0.6162 - val_accuracy: 0.6811 - 7s/epoch - 166ms/step\n",
            "Epoch 66/280\n",
            "42/42 - 7s - loss: 0.5863 - accuracy: 0.6994 - val_loss: 0.6218 - val_accuracy: 0.6854 - 7s/epoch - 168ms/step\n",
            "Epoch 67/280\n",
            "42/42 - 6s - loss: 0.5866 - accuracy: 0.6974 - val_loss: 0.6260 - val_accuracy: 0.6782 - 6s/epoch - 144ms/step\n",
            "Epoch 68/280\n",
            "42/42 - 7s - loss: 0.5735 - accuracy: 0.7074 - val_loss: 0.6240 - val_accuracy: 0.6652 - 7s/epoch - 172ms/step\n",
            "Epoch 69/280\n",
            "42/42 - 7s - loss: 0.5709 - accuracy: 0.7104 - val_loss: 0.6288 - val_accuracy: 0.6768 - 7s/epoch - 168ms/step\n",
            "Epoch 70/280\n",
            "42/42 - 7s - loss: 0.5586 - accuracy: 0.7233 - val_loss: 0.6255 - val_accuracy: 0.6739 - 7s/epoch - 171ms/step\n",
            "Epoch 71/280\n",
            "42/42 - 7s - loss: 0.5836 - accuracy: 0.7049 - val_loss: 0.6240 - val_accuracy: 0.6652 - 7s/epoch - 168ms/step\n",
            "Epoch 72/280\n",
            "42/42 - 7s - loss: 0.5697 - accuracy: 0.7134 - val_loss: 0.6210 - val_accuracy: 0.6681 - 7s/epoch - 177ms/step\n",
            "Epoch 73/280\n",
            "42/42 - 7s - loss: 0.5680 - accuracy: 0.7124 - val_loss: 0.6267 - val_accuracy: 0.6710 - 7s/epoch - 166ms/step\n",
            "Epoch 74/280\n",
            "42/42 - 8s - loss: 0.5454 - accuracy: 0.7268 - val_loss: 0.6204 - val_accuracy: 0.6681 - 8s/epoch - 194ms/step\n",
            "Epoch 75/280\n",
            "42/42 - 6s - loss: 0.5429 - accuracy: 0.7303 - val_loss: 0.6231 - val_accuracy: 0.6739 - 6s/epoch - 148ms/step\n",
            "Epoch 76/280\n",
            "42/42 - 7s - loss: 0.5454 - accuracy: 0.7343 - val_loss: 0.6239 - val_accuracy: 0.6710 - 7s/epoch - 176ms/step\n",
            "Epoch 77/280\n",
            "42/42 - 6s - loss: 0.5299 - accuracy: 0.7393 - val_loss: 0.6247 - val_accuracy: 0.6652 - 6s/epoch - 149ms/step\n",
            "Epoch 78/280\n",
            "42/42 - 8s - loss: 0.5336 - accuracy: 0.7323 - val_loss: 0.6226 - val_accuracy: 0.6710 - 8s/epoch - 197ms/step\n",
            "Epoch 79/280\n",
            "42/42 - 7s - loss: 0.5292 - accuracy: 0.7303 - val_loss: 0.6199 - val_accuracy: 0.6696 - 7s/epoch - 168ms/step\n",
            "Epoch 80/280\n",
            "42/42 - 8s - loss: 0.5316 - accuracy: 0.7373 - val_loss: 0.6373 - val_accuracy: 0.6407 - 8s/epoch - 188ms/step\n",
            "Epoch 81/280\n",
            "42/42 - 7s - loss: 0.5239 - accuracy: 0.7413 - val_loss: 0.6354 - val_accuracy: 0.6652 - 7s/epoch - 168ms/step\n",
            "Epoch 82/280\n",
            "42/42 - 7s - loss: 0.5281 - accuracy: 0.7463 - val_loss: 0.6357 - val_accuracy: 0.6537 - 7s/epoch - 157ms/step\n",
            "Epoch 83/280\n",
            "42/42 - 7s - loss: 0.5243 - accuracy: 0.7368 - val_loss: 0.6379 - val_accuracy: 0.6537 - 7s/epoch - 167ms/step\n",
            "Epoch 84/280\n",
            "42/42 - 7s - loss: 0.5310 - accuracy: 0.7388 - val_loss: 0.6271 - val_accuracy: 0.6753 - 7s/epoch - 160ms/step\n",
            "Epoch 85/280\n",
            "42/42 - 7s - loss: 0.4948 - accuracy: 0.7527 - val_loss: 0.6254 - val_accuracy: 0.6652 - 7s/epoch - 167ms/step\n",
            "Epoch 86/280\n",
            "42/42 - 7s - loss: 0.5167 - accuracy: 0.7478 - val_loss: 0.6301 - val_accuracy: 0.6724 - 7s/epoch - 156ms/step\n",
            "Epoch 87/280\n",
            "42/42 - 7s - loss: 0.4926 - accuracy: 0.7622 - val_loss: 0.6345 - val_accuracy: 0.6623 - 7s/epoch - 170ms/step\n",
            "Epoch 88/280\n",
            "42/42 - 8s - loss: 0.4892 - accuracy: 0.7622 - val_loss: 0.6273 - val_accuracy: 0.6782 - 8s/epoch - 185ms/step\n",
            "Epoch 89/280\n",
            "42/42 - 8s - loss: 0.4703 - accuracy: 0.7757 - val_loss: 0.6305 - val_accuracy: 0.6768 - 8s/epoch - 180ms/step\n",
            "Epoch 90/280\n",
            "42/42 - 7s - loss: 0.5126 - accuracy: 0.7512 - val_loss: 0.6237 - val_accuracy: 0.6825 - 7s/epoch - 172ms/step\n",
            "Epoch 91/280\n",
            "42/42 - 8s - loss: 0.4814 - accuracy: 0.7747 - val_loss: 0.6459 - val_accuracy: 0.6407 - 8s/epoch - 186ms/step\n",
            "Epoch 92/280\n",
            "42/42 - 7s - loss: 0.4717 - accuracy: 0.7737 - val_loss: 0.6424 - val_accuracy: 0.6494 - 7s/epoch - 169ms/step\n",
            "Epoch 93/280\n",
            "42/42 - 8s - loss: 0.4798 - accuracy: 0.7797 - val_loss: 0.6330 - val_accuracy: 0.6739 - 8s/epoch - 192ms/step\n",
            "Epoch 94/280\n",
            "42/42 - 7s - loss: 0.4804 - accuracy: 0.7682 - val_loss: 0.6583 - val_accuracy: 0.6176 - 7s/epoch - 170ms/step\n",
            "Epoch 95/280\n",
            "42/42 - 7s - loss: 0.4624 - accuracy: 0.7782 - val_loss: 0.6438 - val_accuracy: 0.6436 - 7s/epoch - 175ms/step\n",
            "Epoch 96/280\n",
            "42/42 - 7s - loss: 0.4585 - accuracy: 0.7667 - val_loss: 0.6547 - val_accuracy: 0.6219 - 7s/epoch - 169ms/step\n",
            "Epoch 97/280\n",
            "42/42 - 7s - loss: 0.4507 - accuracy: 0.7767 - val_loss: 0.6416 - val_accuracy: 0.6479 - 7s/epoch - 175ms/step\n",
            "Epoch 98/280\n",
            "42/42 - 7s - loss: 0.4541 - accuracy: 0.7787 - val_loss: 0.6311 - val_accuracy: 0.6768 - 7s/epoch - 171ms/step\n",
            "Epoch 99/280\n",
            "42/42 - 8s - loss: 0.4561 - accuracy: 0.7827 - val_loss: 0.6418 - val_accuracy: 0.6392 - 8s/epoch - 200ms/step\n",
            "Epoch 100/280\n",
            "42/42 - 7s - loss: 0.4438 - accuracy: 0.7807 - val_loss: 0.6474 - val_accuracy: 0.6320 - 7s/epoch - 171ms/step\n",
            "Epoch 101/280\n",
            "42/42 - 7s - loss: 0.4466 - accuracy: 0.7767 - val_loss: 0.6591 - val_accuracy: 0.6277 - 7s/epoch - 167ms/step\n",
            "Epoch 102/280\n",
            "42/42 - 7s - loss: 0.4381 - accuracy: 0.7906 - val_loss: 0.6458 - val_accuracy: 0.6306 - 7s/epoch - 171ms/step\n",
            "Epoch 103/280\n",
            "42/42 - 8s - loss: 0.4441 - accuracy: 0.7916 - val_loss: 0.6435 - val_accuracy: 0.6378 - 8s/epoch - 185ms/step\n",
            "Epoch 104/280\n",
            "42/42 - 7s - loss: 0.4512 - accuracy: 0.7752 - val_loss: 0.6379 - val_accuracy: 0.6450 - 7s/epoch - 173ms/step\n",
            "Epoch 105/280\n",
            "42/42 - 7s - loss: 0.4282 - accuracy: 0.7931 - val_loss: 0.6359 - val_accuracy: 0.6392 - 7s/epoch - 159ms/step\n",
            "Epoch 106/280\n",
            "42/42 - 7s - loss: 0.4302 - accuracy: 0.7996 - val_loss: 0.6315 - val_accuracy: 0.6537 - 7s/epoch - 178ms/step\n",
            "Epoch 107/280\n",
            "42/42 - 8s - loss: 0.4302 - accuracy: 0.7906 - val_loss: 0.6408 - val_accuracy: 0.6508 - 8s/epoch - 180ms/step\n",
            "Epoch 108/280\n",
            "42/42 - 8s - loss: 0.4166 - accuracy: 0.8001 - val_loss: 0.6320 - val_accuracy: 0.6551 - 8s/epoch - 186ms/step\n",
            "Epoch 109/280\n",
            "42/42 - 6s - loss: 0.3997 - accuracy: 0.8111 - val_loss: 0.6356 - val_accuracy: 0.6522 - 6s/epoch - 151ms/step\n",
            "Epoch 110/280\n",
            "42/42 - 8s - loss: 0.4205 - accuracy: 0.7971 - val_loss: 0.6487 - val_accuracy: 0.6349 - 8s/epoch - 179ms/step\n",
            "Epoch 111/280\n",
            "42/42 - 7s - loss: 0.4113 - accuracy: 0.8156 - val_loss: 0.6474 - val_accuracy: 0.6450 - 7s/epoch - 170ms/step\n",
            "Epoch 112/280\n",
            "42/42 - 8s - loss: 0.3977 - accuracy: 0.8071 - val_loss: 0.6322 - val_accuracy: 0.6580 - 8s/epoch - 184ms/step\n",
            "Epoch 113/280\n",
            "42/42 - 7s - loss: 0.4198 - accuracy: 0.7976 - val_loss: 0.6247 - val_accuracy: 0.6623 - 7s/epoch - 173ms/step\n",
            "Epoch 114/280\n",
            "42/42 - 7s - loss: 0.3920 - accuracy: 0.8151 - val_loss: 0.6315 - val_accuracy: 0.6580 - 7s/epoch - 178ms/step\n",
            "Epoch 115/280\n",
            "42/42 - 7s - loss: 0.3960 - accuracy: 0.8101 - val_loss: 0.6376 - val_accuracy: 0.6465 - 7s/epoch - 170ms/step\n",
            "Epoch 116/280\n",
            "42/42 - 8s - loss: 0.3965 - accuracy: 0.8131 - val_loss: 0.6441 - val_accuracy: 0.6494 - 8s/epoch - 183ms/step\n",
            "Epoch 117/280\n",
            "42/42 - 6s - loss: 0.4039 - accuracy: 0.8106 - val_loss: 0.6382 - val_accuracy: 0.6494 - 6s/epoch - 152ms/step\n",
            "Epoch 118/280\n",
            "42/42 - 8s - loss: 0.3800 - accuracy: 0.8190 - val_loss: 0.6230 - val_accuracy: 0.6638 - 8s/epoch - 200ms/step\n",
            "Epoch 119/280\n",
            "42/42 - 7s - loss: 0.3778 - accuracy: 0.8300 - val_loss: 0.6180 - val_accuracy: 0.6696 - 7s/epoch - 172ms/step\n",
            "Epoch 120/280\n",
            "42/42 - 8s - loss: 0.3709 - accuracy: 0.8310 - val_loss: 0.6213 - val_accuracy: 0.6681 - 8s/epoch - 179ms/step\n",
            "Epoch 121/280\n",
            "42/42 - 7s - loss: 0.3823 - accuracy: 0.8131 - val_loss: 0.6066 - val_accuracy: 0.6840 - 7s/epoch - 170ms/step\n",
            "Epoch 122/280\n",
            "42/42 - 8s - loss: 0.3856 - accuracy: 0.8121 - val_loss: 0.6192 - val_accuracy: 0.6681 - 8s/epoch - 190ms/step\n",
            "Epoch 123/280\n",
            "42/42 - 7s - loss: 0.3616 - accuracy: 0.8295 - val_loss: 0.6389 - val_accuracy: 0.6551 - 7s/epoch - 163ms/step\n",
            "Epoch 124/280\n",
            "42/42 - 7s - loss: 0.3691 - accuracy: 0.8300 - val_loss: 0.6224 - val_accuracy: 0.6667 - 7s/epoch - 167ms/step\n",
            "Epoch 125/280\n",
            "42/42 - 7s - loss: 0.3684 - accuracy: 0.8340 - val_loss: 0.6112 - val_accuracy: 0.6782 - 7s/epoch - 170ms/step\n",
            "Epoch 126/280\n",
            "42/42 - 7s - loss: 0.3689 - accuracy: 0.8365 - val_loss: 0.6253 - val_accuracy: 0.6623 - 7s/epoch - 162ms/step\n",
            "Epoch 127/280\n",
            "42/42 - 7s - loss: 0.3388 - accuracy: 0.8475 - val_loss: 0.6127 - val_accuracy: 0.6797 - 7s/epoch - 170ms/step\n",
            "Epoch 128/280\n",
            "42/42 - 7s - loss: 0.3572 - accuracy: 0.8245 - val_loss: 0.6083 - val_accuracy: 0.6797 - 7s/epoch - 162ms/step\n",
            "Epoch 129/280\n",
            "42/42 - 7s - loss: 0.3532 - accuracy: 0.8375 - val_loss: 0.6058 - val_accuracy: 0.6840 - 7s/epoch - 170ms/step\n",
            "Epoch 130/280\n",
            "42/42 - 7s - loss: 0.3481 - accuracy: 0.8390 - val_loss: 0.6173 - val_accuracy: 0.6681 - 7s/epoch - 162ms/step\n",
            "Epoch 131/280\n",
            "42/42 - 7s - loss: 0.3393 - accuracy: 0.8460 - val_loss: 0.5850 - val_accuracy: 0.6984 - 7s/epoch - 170ms/step\n",
            "Epoch 132/280\n",
            "42/42 - 7s - loss: 0.3522 - accuracy: 0.8375 - val_loss: 0.5952 - val_accuracy: 0.6926 - 7s/epoch - 163ms/step\n",
            "Epoch 133/280\n",
            "42/42 - 7s - loss: 0.3390 - accuracy: 0.8485 - val_loss: 0.6106 - val_accuracy: 0.6768 - 7s/epoch - 171ms/step\n",
            "Epoch 134/280\n",
            "42/42 - 8s - loss: 0.3405 - accuracy: 0.8430 - val_loss: 0.5784 - val_accuracy: 0.6984 - 8s/epoch - 184ms/step\n",
            "Epoch 135/280\n",
            "42/42 - 7s - loss: 0.3365 - accuracy: 0.8450 - val_loss: 0.5777 - val_accuracy: 0.7027 - 7s/epoch - 171ms/step\n",
            "Epoch 136/280\n",
            "42/42 - 7s - loss: 0.3349 - accuracy: 0.8564 - val_loss: 0.5890 - val_accuracy: 0.6912 - 7s/epoch - 175ms/step\n",
            "Epoch 137/280\n",
            "42/42 - 8s - loss: 0.3093 - accuracy: 0.8634 - val_loss: 0.5901 - val_accuracy: 0.6926 - 8s/epoch - 183ms/step\n",
            "Epoch 138/280\n",
            "42/42 - 7s - loss: 0.3124 - accuracy: 0.8584 - val_loss: 0.5971 - val_accuracy: 0.6970 - 7s/epoch - 169ms/step\n",
            "Epoch 139/280\n",
            "42/42 - 7s - loss: 0.3366 - accuracy: 0.8544 - val_loss: 0.6117 - val_accuracy: 0.6782 - 7s/epoch - 173ms/step\n",
            "Epoch 140/280\n",
            "42/42 - 6s - loss: 0.3140 - accuracy: 0.8559 - val_loss: 0.5732 - val_accuracy: 0.7027 - 6s/epoch - 151ms/step\n",
            "Epoch 141/280\n",
            "42/42 - 8s - loss: 0.3197 - accuracy: 0.8554 - val_loss: 0.5642 - val_accuracy: 0.7172 - 8s/epoch - 184ms/step\n",
            "Epoch 142/280\n",
            "42/42 - 6s - loss: 0.3158 - accuracy: 0.8569 - val_loss: 0.5587 - val_accuracy: 0.7157 - 6s/epoch - 148ms/step\n",
            "Epoch 143/280\n",
            "42/42 - 7s - loss: 0.3078 - accuracy: 0.8574 - val_loss: 0.5579 - val_accuracy: 0.7172 - 7s/epoch - 175ms/step\n",
            "Epoch 144/280\n",
            "42/42 - 7s - loss: 0.3015 - accuracy: 0.8639 - val_loss: 0.5936 - val_accuracy: 0.7027 - 7s/epoch - 170ms/step\n",
            "Epoch 145/280\n",
            "42/42 - 8s - loss: 0.3094 - accuracy: 0.8614 - val_loss: 0.5754 - val_accuracy: 0.7056 - 8s/epoch - 189ms/step\n",
            "Epoch 146/280\n",
            "42/42 - 6s - loss: 0.2877 - accuracy: 0.8684 - val_loss: 0.6279 - val_accuracy: 0.6566 - 6s/epoch - 152ms/step\n",
            "Epoch 147/280\n",
            "42/42 - 7s - loss: 0.2930 - accuracy: 0.8679 - val_loss: 0.5569 - val_accuracy: 0.7229 - 7s/epoch - 177ms/step\n",
            "Epoch 148/280\n",
            "42/42 - 6s - loss: 0.2850 - accuracy: 0.8724 - val_loss: 0.5360 - val_accuracy: 0.7287 - 6s/epoch - 152ms/step\n",
            "Epoch 149/280\n",
            "42/42 - 7s - loss: 0.2922 - accuracy: 0.8704 - val_loss: 0.5559 - val_accuracy: 0.7201 - 7s/epoch - 177ms/step\n",
            "Epoch 150/280\n",
            "42/42 - 7s - loss: 0.2957 - accuracy: 0.8749 - val_loss: 0.5630 - val_accuracy: 0.7157 - 7s/epoch - 170ms/step\n",
            "Epoch 151/280\n",
            "42/42 - 7s - loss: 0.2884 - accuracy: 0.8724 - val_loss: 0.5392 - val_accuracy: 0.7302 - 7s/epoch - 173ms/step\n",
            "Epoch 152/280\n",
            "42/42 - 6s - loss: 0.2766 - accuracy: 0.8759 - val_loss: 0.5754 - val_accuracy: 0.7100 - 6s/epoch - 151ms/step\n",
            "Epoch 153/280\n",
            "42/42 - 7s - loss: 0.2828 - accuracy: 0.8719 - val_loss: 0.5635 - val_accuracy: 0.7114 - 7s/epoch - 178ms/step\n",
            "Epoch 154/280\n",
            "42/42 - 7s - loss: 0.2805 - accuracy: 0.8754 - val_loss: 0.5381 - val_accuracy: 0.7302 - 7s/epoch - 168ms/step\n",
            "Epoch 155/280\n",
            "42/42 - 7s - loss: 0.2811 - accuracy: 0.8764 - val_loss: 0.5312 - val_accuracy: 0.7273 - 7s/epoch - 174ms/step\n",
            "Epoch 156/280\n",
            "42/42 - 6s - loss: 0.2723 - accuracy: 0.8754 - val_loss: 0.5588 - val_accuracy: 0.7186 - 6s/epoch - 152ms/step\n",
            "Epoch 157/280\n",
            "42/42 - 8s - loss: 0.2717 - accuracy: 0.8729 - val_loss: 0.5457 - val_accuracy: 0.7287 - 8s/epoch - 201ms/step\n",
            "Epoch 158/280\n",
            "42/42 - 7s - loss: 0.2581 - accuracy: 0.8873 - val_loss: 0.5117 - val_accuracy: 0.7460 - 7s/epoch - 171ms/step\n",
            "Epoch 159/280\n",
            "42/42 - 7s - loss: 0.2662 - accuracy: 0.8848 - val_loss: 0.5246 - val_accuracy: 0.7345 - 7s/epoch - 174ms/step\n",
            "Epoch 160/280\n",
            "42/42 - 6s - loss: 0.2664 - accuracy: 0.8863 - val_loss: 0.5306 - val_accuracy: 0.7287 - 6s/epoch - 152ms/step\n",
            "Epoch 161/280\n",
            "42/42 - 7s - loss: 0.2538 - accuracy: 0.8888 - val_loss: 0.5217 - val_accuracy: 0.7403 - 7s/epoch - 178ms/step\n",
            "Epoch 162/280\n",
            "42/42 - 6s - loss: 0.2530 - accuracy: 0.8953 - val_loss: 0.5027 - val_accuracy: 0.7504 - 6s/epoch - 149ms/step\n",
            "Epoch 163/280\n",
            "42/42 - 8s - loss: 0.2573 - accuracy: 0.8883 - val_loss: 0.5041 - val_accuracy: 0.7518 - 8s/epoch - 198ms/step\n",
            "Epoch 164/280\n",
            "42/42 - 6s - loss: 0.2513 - accuracy: 0.8858 - val_loss: 0.5152 - val_accuracy: 0.7504 - 6s/epoch - 153ms/step\n",
            "Epoch 165/280\n",
            "42/42 - 7s - loss: 0.2594 - accuracy: 0.8868 - val_loss: 0.5027 - val_accuracy: 0.7475 - 7s/epoch - 177ms/step\n",
            "Epoch 166/280\n",
            "42/42 - 7s - loss: 0.2417 - accuracy: 0.8958 - val_loss: 0.4846 - val_accuracy: 0.7648 - 7s/epoch - 172ms/step\n",
            "Epoch 167/280\n",
            "42/42 - 7s - loss: 0.2476 - accuracy: 0.8908 - val_loss: 0.5024 - val_accuracy: 0.7605 - 7s/epoch - 171ms/step\n",
            "Epoch 168/280\n",
            "42/42 - 7s - loss: 0.2327 - accuracy: 0.9028 - val_loss: 0.4723 - val_accuracy: 0.7763 - 7s/epoch - 170ms/step\n",
            "Epoch 169/280\n",
            "42/42 - 7s - loss: 0.2344 - accuracy: 0.8988 - val_loss: 0.4764 - val_accuracy: 0.7749 - 7s/epoch - 169ms/step\n",
            "Epoch 170/280\n",
            "42/42 - 7s - loss: 0.2282 - accuracy: 0.9033 - val_loss: 0.4835 - val_accuracy: 0.7648 - 7s/epoch - 171ms/step\n",
            "Epoch 171/280\n",
            "42/42 - 8s - loss: 0.2408 - accuracy: 0.8938 - val_loss: 0.5182 - val_accuracy: 0.7431 - 8s/epoch - 184ms/step\n",
            "Epoch 172/280\n",
            "42/42 - 7s - loss: 0.2372 - accuracy: 0.9013 - val_loss: 0.4952 - val_accuracy: 0.7590 - 7s/epoch - 172ms/step\n",
            "Epoch 173/280\n",
            "42/42 - 7s - loss: 0.2386 - accuracy: 0.9023 - val_loss: 0.4849 - val_accuracy: 0.7720 - 7s/epoch - 177ms/step\n",
            "Epoch 174/280\n",
            "42/42 - 7s - loss: 0.2237 - accuracy: 0.9048 - val_loss: 0.4542 - val_accuracy: 0.7937 - 7s/epoch - 178ms/step\n",
            "Epoch 175/280\n",
            "42/42 - 6s - loss: 0.2347 - accuracy: 0.8973 - val_loss: 0.4652 - val_accuracy: 0.7835 - 6s/epoch - 146ms/step\n",
            "Epoch 176/280\n",
            "42/42 - 7s - loss: 0.2268 - accuracy: 0.9003 - val_loss: 0.4627 - val_accuracy: 0.7937 - 7s/epoch - 173ms/step\n",
            "Epoch 177/280\n",
            "42/42 - 6s - loss: 0.2207 - accuracy: 0.9053 - val_loss: 0.4875 - val_accuracy: 0.7590 - 6s/epoch - 153ms/step\n",
            "Epoch 178/280\n",
            "42/42 - 7s - loss: 0.2204 - accuracy: 0.9033 - val_loss: 0.4586 - val_accuracy: 0.7850 - 7s/epoch - 173ms/step\n",
            "Epoch 179/280\n",
            "42/42 - 7s - loss: 0.2088 - accuracy: 0.9153 - val_loss: 0.4513 - val_accuracy: 0.7980 - 7s/epoch - 174ms/step\n",
            "Epoch 180/280\n",
            "42/42 - 8s - loss: 0.2169 - accuracy: 0.9063 - val_loss: 0.4525 - val_accuracy: 0.7951 - 8s/epoch - 179ms/step\n",
            "Epoch 181/280\n",
            "42/42 - 6s - loss: 0.2147 - accuracy: 0.9078 - val_loss: 0.4502 - val_accuracy: 0.7922 - 6s/epoch - 149ms/step\n",
            "Epoch 182/280\n",
            "42/42 - 8s - loss: 0.2043 - accuracy: 0.9143 - val_loss: 0.4730 - val_accuracy: 0.7749 - 8s/epoch - 179ms/step\n",
            "Epoch 183/280\n",
            "42/42 - 7s - loss: 0.2008 - accuracy: 0.9163 - val_loss: 0.4674 - val_accuracy: 0.7792 - 7s/epoch - 170ms/step\n",
            "Epoch 184/280\n",
            "42/42 - 8s - loss: 0.2086 - accuracy: 0.9192 - val_loss: 0.4549 - val_accuracy: 0.7908 - 8s/epoch - 188ms/step\n",
            "Epoch 185/280\n",
            "42/42 - 7s - loss: 0.1988 - accuracy: 0.9138 - val_loss: 0.4277 - val_accuracy: 0.8139 - 7s/epoch - 169ms/step\n",
            "Epoch 186/280\n",
            "42/42 - 8s - loss: 0.2029 - accuracy: 0.9128 - val_loss: 0.4389 - val_accuracy: 0.8023 - 8s/epoch - 196ms/step\n",
            "Epoch 187/280\n",
            "42/42 - 7s - loss: 0.1815 - accuracy: 0.9277 - val_loss: 0.4379 - val_accuracy: 0.8023 - 7s/epoch - 169ms/step\n",
            "Epoch 188/280\n",
            "42/42 - 7s - loss: 0.1869 - accuracy: 0.9182 - val_loss: 0.4219 - val_accuracy: 0.8167 - 7s/epoch - 178ms/step\n",
            "Epoch 189/280\n",
            "42/42 - 6s - loss: 0.1962 - accuracy: 0.9212 - val_loss: 0.4598 - val_accuracy: 0.7835 - 6s/epoch - 149ms/step\n",
            "Epoch 190/280\n",
            "42/42 - 8s - loss: 0.1861 - accuracy: 0.9252 - val_loss: 0.4346 - val_accuracy: 0.8052 - 8s/epoch - 197ms/step\n",
            "Epoch 191/280\n",
            "42/42 - 7s - loss: 0.1955 - accuracy: 0.9217 - val_loss: 0.4352 - val_accuracy: 0.8009 - 7s/epoch - 168ms/step\n",
            "Epoch 192/280\n",
            "42/42 - 7s - loss: 0.1843 - accuracy: 0.9282 - val_loss: 0.4201 - val_accuracy: 0.8182 - 7s/epoch - 166ms/step\n",
            "Epoch 193/280\n",
            "42/42 - 7s - loss: 0.1850 - accuracy: 0.9207 - val_loss: 0.4461 - val_accuracy: 0.7980 - 7s/epoch - 168ms/step\n",
            "Epoch 194/280\n",
            "42/42 - 7s - loss: 0.1784 - accuracy: 0.9277 - val_loss: 0.4494 - val_accuracy: 0.7908 - 7s/epoch - 162ms/step\n",
            "Epoch 195/280\n",
            "42/42 - 7s - loss: 0.1816 - accuracy: 0.9292 - val_loss: 0.4103 - val_accuracy: 0.8312 - 7s/epoch - 169ms/step\n",
            "Epoch 196/280\n",
            "42/42 - 8s - loss: 0.1830 - accuracy: 0.9267 - val_loss: 0.4247 - val_accuracy: 0.8110 - 8s/epoch - 184ms/step\n",
            "Epoch 197/280\n",
            "42/42 - 7s - loss: 0.1767 - accuracy: 0.9267 - val_loss: 0.4137 - val_accuracy: 0.8139 - 7s/epoch - 173ms/step\n",
            "Epoch 198/280\n",
            "42/42 - 7s - loss: 0.1688 - accuracy: 0.9252 - val_loss: 0.4001 - val_accuracy: 0.8312 - 7s/epoch - 155ms/step\n",
            "Epoch 199/280\n",
            "42/42 - 7s - loss: 0.1742 - accuracy: 0.9277 - val_loss: 0.3850 - val_accuracy: 0.8355 - 7s/epoch - 166ms/step\n",
            "Epoch 200/280\n",
            "42/42 - 7s - loss: 0.1686 - accuracy: 0.9317 - val_loss: 0.3957 - val_accuracy: 0.8355 - 7s/epoch - 160ms/step\n",
            "Epoch 201/280\n",
            "42/42 - 7s - loss: 0.1623 - accuracy: 0.9277 - val_loss: 0.3919 - val_accuracy: 0.8369 - 7s/epoch - 163ms/step\n",
            "Epoch 202/280\n",
            "42/42 - 7s - loss: 0.1652 - accuracy: 0.9342 - val_loss: 0.4133 - val_accuracy: 0.8124 - 7s/epoch - 160ms/step\n",
            "Epoch 203/280\n",
            "42/42 - 7s - loss: 0.1645 - accuracy: 0.9262 - val_loss: 0.3737 - val_accuracy: 0.8456 - 7s/epoch - 171ms/step\n",
            "Epoch 204/280\n",
            "42/42 - 7s - loss: 0.1596 - accuracy: 0.9312 - val_loss: 0.4278 - val_accuracy: 0.7980 - 7s/epoch - 158ms/step\n",
            "Epoch 205/280\n",
            "42/42 - 7s - loss: 0.1534 - accuracy: 0.9412 - val_loss: 0.3940 - val_accuracy: 0.8254 - 7s/epoch - 172ms/step\n",
            "Epoch 206/280\n",
            "42/42 - 7s - loss: 0.1570 - accuracy: 0.9347 - val_loss: 0.3995 - val_accuracy: 0.8211 - 7s/epoch - 169ms/step\n",
            "Epoch 207/280\n",
            "42/42 - 7s - loss: 0.1560 - accuracy: 0.9382 - val_loss: 0.3737 - val_accuracy: 0.8442 - 7s/epoch - 168ms/step\n",
            "Epoch 208/280\n",
            "42/42 - 6s - loss: 0.1559 - accuracy: 0.9352 - val_loss: 0.3821 - val_accuracy: 0.8341 - 6s/epoch - 151ms/step\n",
            "Epoch 209/280\n",
            "42/42 - 7s - loss: 0.1466 - accuracy: 0.9422 - val_loss: 0.3887 - val_accuracy: 0.8254 - 7s/epoch - 171ms/step\n",
            "Epoch 210/280\n",
            "42/42 - 6s - loss: 0.1475 - accuracy: 0.9437 - val_loss: 0.3835 - val_accuracy: 0.8297 - 6s/epoch - 148ms/step\n",
            "Epoch 211/280\n",
            "42/42 - 7s - loss: 0.1441 - accuracy: 0.9427 - val_loss: 0.3636 - val_accuracy: 0.8413 - 7s/epoch - 173ms/step\n",
            "Epoch 212/280\n",
            "42/42 - 6s - loss: 0.1423 - accuracy: 0.9492 - val_loss: 0.3749 - val_accuracy: 0.8355 - 6s/epoch - 151ms/step\n",
            "Epoch 213/280\n",
            "42/42 - 7s - loss: 0.1473 - accuracy: 0.9447 - val_loss: 0.3941 - val_accuracy: 0.8182 - 7s/epoch - 170ms/step\n",
            "Epoch 214/280\n",
            "42/42 - 6s - loss: 0.1303 - accuracy: 0.9526 - val_loss: 0.3642 - val_accuracy: 0.8384 - 6s/epoch - 146ms/step\n",
            "Epoch 215/280\n",
            "42/42 - 7s - loss: 0.1376 - accuracy: 0.9427 - val_loss: 0.3524 - val_accuracy: 0.8485 - 7s/epoch - 169ms/step\n",
            "Epoch 216/280\n",
            "42/42 - 7s - loss: 0.1327 - accuracy: 0.9521 - val_loss: 0.3420 - val_accuracy: 0.8543 - 7s/epoch - 170ms/step\n",
            "Epoch 217/280\n",
            "42/42 - 8s - loss: 0.1458 - accuracy: 0.9437 - val_loss: 0.3690 - val_accuracy: 0.8398 - 8s/epoch - 191ms/step\n",
            "Epoch 218/280\n",
            "42/42 - 6s - loss: 0.1270 - accuracy: 0.9541 - val_loss: 0.3621 - val_accuracy: 0.8413 - 6s/epoch - 146ms/step\n",
            "Epoch 219/280\n",
            "42/42 - 8s - loss: 0.1293 - accuracy: 0.9521 - val_loss: 0.3679 - val_accuracy: 0.8398 - 8s/epoch - 191ms/step\n",
            "Epoch 220/280\n",
            "42/42 - 7s - loss: 0.1301 - accuracy: 0.9427 - val_loss: 0.3650 - val_accuracy: 0.8398 - 7s/epoch - 169ms/step\n",
            "Epoch 221/280\n",
            "42/42 - 8s - loss: 0.1292 - accuracy: 0.9511 - val_loss: 0.3494 - val_accuracy: 0.8514 - 8s/epoch - 183ms/step\n",
            "Epoch 222/280\n",
            "42/42 - 7s - loss: 0.1259 - accuracy: 0.9556 - val_loss: 0.3480 - val_accuracy: 0.8485 - 7s/epoch - 173ms/step\n",
            "Epoch 223/280\n",
            "42/42 - 7s - loss: 0.1193 - accuracy: 0.9551 - val_loss: 0.3315 - val_accuracy: 0.8600 - 7s/epoch - 169ms/step\n",
            "Epoch 224/280\n",
            "42/42 - 7s - loss: 0.1358 - accuracy: 0.9447 - val_loss: 0.3258 - val_accuracy: 0.8644 - 7s/epoch - 173ms/step\n",
            "Epoch 225/280\n",
            "42/42 - 7s - loss: 0.1218 - accuracy: 0.9541 - val_loss: 0.3439 - val_accuracy: 0.8398 - 7s/epoch - 168ms/step\n",
            "Epoch 226/280\n",
            "42/42 - 7s - loss: 0.1311 - accuracy: 0.9497 - val_loss: 0.3915 - val_accuracy: 0.8182 - 7s/epoch - 167ms/step\n",
            "Epoch 227/280\n",
            "42/42 - 6s - loss: 0.1239 - accuracy: 0.9516 - val_loss: 0.3371 - val_accuracy: 0.8499 - 6s/epoch - 150ms/step\n",
            "Epoch 228/280\n",
            "42/42 - 7s - loss: 0.1124 - accuracy: 0.9611 - val_loss: 0.3391 - val_accuracy: 0.8528 - 7s/epoch - 173ms/step\n",
            "Epoch 229/280\n",
            "42/42 - 6s - loss: 0.1259 - accuracy: 0.9511 - val_loss: 0.3368 - val_accuracy: 0.8485 - 6s/epoch - 147ms/step\n",
            "Epoch 230/280\n",
            "42/42 - 8s - loss: 0.1156 - accuracy: 0.9561 - val_loss: 0.3297 - val_accuracy: 0.8571 - 8s/epoch - 191ms/step\n",
            "Epoch 231/280\n",
            "42/42 - 7s - loss: 0.1088 - accuracy: 0.9616 - val_loss: 0.3344 - val_accuracy: 0.8557 - 7s/epoch - 167ms/step\n",
            "Epoch 232/280\n",
            "42/42 - 7s - loss: 0.1069 - accuracy: 0.9556 - val_loss: 0.3289 - val_accuracy: 0.8586 - 7s/epoch - 173ms/step\n",
            "Epoch 233/280\n",
            "42/42 - 7s - loss: 0.1116 - accuracy: 0.9566 - val_loss: 0.3071 - val_accuracy: 0.8730 - 7s/epoch - 169ms/step\n",
            "Epoch 234/280\n",
            "42/42 - 8s - loss: 0.1067 - accuracy: 0.9616 - val_loss: 0.3221 - val_accuracy: 0.8586 - 8s/epoch - 180ms/step\n",
            "Epoch 235/280\n",
            "42/42 - 7s - loss: 0.1083 - accuracy: 0.9606 - val_loss: 0.3332 - val_accuracy: 0.8586 - 7s/epoch - 174ms/step\n",
            "Epoch 236/280\n",
            "42/42 - 7s - loss: 0.0930 - accuracy: 0.9686 - val_loss: 0.3306 - val_accuracy: 0.8571 - 7s/epoch - 169ms/step\n",
            "Epoch 237/280\n",
            "42/42 - 8s - loss: 0.0906 - accuracy: 0.9686 - val_loss: 0.2960 - val_accuracy: 0.8831 - 8s/epoch - 184ms/step\n",
            "Epoch 238/280\n",
            "42/42 - 6s - loss: 0.1095 - accuracy: 0.9626 - val_loss: 0.3139 - val_accuracy: 0.8658 - 6s/epoch - 146ms/step\n",
            "Epoch 239/280\n",
            "42/42 - 7s - loss: 0.1035 - accuracy: 0.9641 - val_loss: 0.3105 - val_accuracy: 0.8687 - 7s/epoch - 170ms/step\n",
            "Epoch 240/280\n",
            "42/42 - 7s - loss: 0.0953 - accuracy: 0.9681 - val_loss: 0.3236 - val_accuracy: 0.8600 - 7s/epoch - 169ms/step\n",
            "Epoch 241/280\n",
            "42/42 - 7s - loss: 0.0946 - accuracy: 0.9681 - val_loss: 0.3076 - val_accuracy: 0.8716 - 7s/epoch - 172ms/step\n",
            "Epoch 242/280\n",
            "42/42 - 6s - loss: 0.0940 - accuracy: 0.9666 - val_loss: 0.3109 - val_accuracy: 0.8687 - 6s/epoch - 145ms/step\n",
            "Epoch 243/280\n",
            "42/42 - 8s - loss: 0.0918 - accuracy: 0.9676 - val_loss: 0.3022 - val_accuracy: 0.8730 - 8s/epoch - 191ms/step\n",
            "Epoch 244/280\n",
            "42/42 - 7s - loss: 0.0912 - accuracy: 0.9651 - val_loss: 0.3081 - val_accuracy: 0.8730 - 7s/epoch - 169ms/step\n",
            "Epoch 245/280\n",
            "42/42 - 7s - loss: 0.0947 - accuracy: 0.9641 - val_loss: 0.2982 - val_accuracy: 0.8759 - 7s/epoch - 166ms/step\n",
            "Epoch 246/280\n",
            "42/42 - 7s - loss: 0.0893 - accuracy: 0.9686 - val_loss: 0.2979 - val_accuracy: 0.8788 - 7s/epoch - 168ms/step\n",
            "Epoch 247/280\n",
            "42/42 - 7s - loss: 0.0883 - accuracy: 0.9726 - val_loss: 0.3001 - val_accuracy: 0.8773 - 7s/epoch - 178ms/step\n",
            "Epoch 248/280\n",
            "42/42 - 7s - loss: 0.0955 - accuracy: 0.9661 - val_loss: 0.3065 - val_accuracy: 0.8687 - 7s/epoch - 172ms/step\n",
            "Epoch 249/280\n",
            "42/42 - 6s - loss: 0.0925 - accuracy: 0.9651 - val_loss: 0.2928 - val_accuracy: 0.8773 - 6s/epoch - 148ms/step\n",
            "Epoch 250/280\n",
            "42/42 - 7s - loss: 0.0816 - accuracy: 0.9716 - val_loss: 0.2930 - val_accuracy: 0.8802 - 7s/epoch - 167ms/step\n",
            "Epoch 251/280\n",
            "42/42 - 7s - loss: 0.0892 - accuracy: 0.9666 - val_loss: 0.2971 - val_accuracy: 0.8773 - 7s/epoch - 168ms/step\n",
            "Epoch 252/280\n",
            "42/42 - 7s - loss: 0.0887 - accuracy: 0.9701 - val_loss: 0.2829 - val_accuracy: 0.8860 - 7s/epoch - 173ms/step\n",
            "Epoch 253/280\n",
            "42/42 - 7s - loss: 0.0832 - accuracy: 0.9726 - val_loss: 0.2994 - val_accuracy: 0.8759 - 7s/epoch - 170ms/step\n",
            "Epoch 254/280\n",
            "42/42 - 8s - loss: 0.0801 - accuracy: 0.9741 - val_loss: 0.2831 - val_accuracy: 0.8903 - 8s/epoch - 193ms/step\n",
            "Epoch 255/280\n",
            "42/42 - 6s - loss: 0.0906 - accuracy: 0.9681 - val_loss: 0.3217 - val_accuracy: 0.8629 - 6s/epoch - 145ms/step\n",
            "Epoch 256/280\n",
            "42/42 - 7s - loss: 0.0820 - accuracy: 0.9696 - val_loss: 0.3115 - val_accuracy: 0.8730 - 7s/epoch - 171ms/step\n",
            "Epoch 257/280\n",
            "42/42 - 6s - loss: 0.0848 - accuracy: 0.9696 - val_loss: 0.2897 - val_accuracy: 0.8846 - 6s/epoch - 149ms/step\n",
            "Epoch 258/280\n",
            "42/42 - 8s - loss: 0.0757 - accuracy: 0.9711 - val_loss: 0.2796 - val_accuracy: 0.8874 - 8s/epoch - 193ms/step\n",
            "Epoch 259/280\n",
            "42/42 - 7s - loss: 0.0745 - accuracy: 0.9736 - val_loss: 0.2787 - val_accuracy: 0.8889 - 7s/epoch - 169ms/step\n",
            "Epoch 260/280\n",
            "42/42 - 7s - loss: 0.0751 - accuracy: 0.9756 - val_loss: 0.3026 - val_accuracy: 0.8730 - 7s/epoch - 161ms/step\n",
            "Epoch 261/280\n",
            "42/42 - 7s - loss: 0.0809 - accuracy: 0.9711 - val_loss: 0.2873 - val_accuracy: 0.8846 - 7s/epoch - 169ms/step\n",
            "Epoch 262/280\n",
            "42/42 - 7s - loss: 0.0654 - accuracy: 0.9771 - val_loss: 0.2910 - val_accuracy: 0.8831 - 7s/epoch - 177ms/step\n",
            "Epoch 263/280\n",
            "42/42 - 7s - loss: 0.0759 - accuracy: 0.9721 - val_loss: 0.2668 - val_accuracy: 0.8932 - 7s/epoch - 170ms/step\n",
            "Epoch 264/280\n",
            "42/42 - 6s - loss: 0.0740 - accuracy: 0.9756 - val_loss: 0.2987 - val_accuracy: 0.8773 - 6s/epoch - 150ms/step\n",
            "Epoch 265/280\n",
            "42/42 - 8s - loss: 0.0809 - accuracy: 0.9706 - val_loss: 0.2738 - val_accuracy: 0.8932 - 8s/epoch - 180ms/step\n",
            "Epoch 266/280\n",
            "42/42 - 7s - loss: 0.0700 - accuracy: 0.9776 - val_loss: 0.2873 - val_accuracy: 0.8817 - 7s/epoch - 168ms/step\n",
            "Epoch 267/280\n",
            "42/42 - 8s - loss: 0.0639 - accuracy: 0.9791 - val_loss: 0.2824 - val_accuracy: 0.8874 - 8s/epoch - 192ms/step\n",
            "Epoch 268/280\n",
            "42/42 - 7s - loss: 0.0667 - accuracy: 0.9781 - val_loss: 0.2854 - val_accuracy: 0.8889 - 7s/epoch - 170ms/step\n",
            "Epoch 269/280\n",
            "42/42 - 8s - loss: 0.0656 - accuracy: 0.9771 - val_loss: 0.2857 - val_accuracy: 0.8846 - 8s/epoch - 193ms/step\n",
            "Epoch 270/280\n",
            "42/42 - 7s - loss: 0.0616 - accuracy: 0.9771 - val_loss: 0.2765 - val_accuracy: 0.8874 - 7s/epoch - 169ms/step\n",
            "Epoch 271/280\n",
            "42/42 - 7s - loss: 0.0668 - accuracy: 0.9786 - val_loss: 0.2741 - val_accuracy: 0.8932 - 7s/epoch - 157ms/step\n",
            "Epoch 272/280\n",
            "42/42 - 7s - loss: 0.0623 - accuracy: 0.9821 - val_loss: 0.2563 - val_accuracy: 0.9048 - 7s/epoch - 163ms/step\n",
            "Epoch 273/280\n",
            "42/42 - 7s - loss: 0.0635 - accuracy: 0.9816 - val_loss: 0.2547 - val_accuracy: 0.9048 - 7s/epoch - 178ms/step\n",
            "Epoch 274/280\n",
            "42/42 - 7s - loss: 0.0602 - accuracy: 0.9811 - val_loss: 0.2716 - val_accuracy: 0.8918 - 7s/epoch - 167ms/step\n",
            "Epoch 275/280\n",
            "42/42 - 7s - loss: 0.0661 - accuracy: 0.9771 - val_loss: 0.2676 - val_accuracy: 0.8889 - 7s/epoch - 170ms/step\n",
            "Epoch 276/280\n",
            "42/42 - 8s - loss: 0.0640 - accuracy: 0.9806 - val_loss: 0.2473 - val_accuracy: 0.9105 - 8s/epoch - 183ms/step\n",
            "Epoch 277/280\n",
            "42/42 - 7s - loss: 0.0607 - accuracy: 0.9801 - val_loss: 0.2516 - val_accuracy: 0.9048 - 7s/epoch - 167ms/step\n",
            "Epoch 278/280\n",
            "42/42 - 7s - loss: 0.0550 - accuracy: 0.9835 - val_loss: 0.2705 - val_accuracy: 0.8961 - 7s/epoch - 168ms/step\n",
            "Epoch 279/280\n",
            "42/42 - 7s - loss: 0.0582 - accuracy: 0.9796 - val_loss: 0.2460 - val_accuracy: 0.9062 - 7s/epoch - 168ms/step\n",
            "Epoch 280/280\n",
            "42/42 - 7s - loss: 0.0597 - accuracy: 0.9781 - val_loss: 0.2736 - val_accuracy: 0.8918 - 7s/epoch - 174ms/step\n",
            "Training end\n",
            "Testing start\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-b671816773dd>:224: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  interPrediction=model.predict_generator(generate_arrays_for_predict(indexPat, filesPath), max_queue_size=4, steps=len(filesPath))\n",
            "<ipython-input-9-b671816773dd>:226: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  preictPrediction=model.predict_generator(generate_arrays_for_predict(indexPat, filesPath), max_queue_size=4, steps=len(filesPath))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing end\n",
            "Model saved\n",
            "True Positive, False Positive, False negative, Second of Inter in Test, Sensitivity, FPR\n",
            "49,2,2,10500,0.9607843137254902,0.6857142857142857\n",
            "SEIZURE OUT: 2\n",
            "Training start\n",
            "Epoch 1/280\n",
            "42/42 - 25s - loss: 0.9192 - accuracy: 0.5156 - val_loss: 0.9176 - val_accuracy: 0.3907 - 25s/epoch - 606ms/step\n",
            "Epoch 2/280\n",
            "42/42 - 7s - loss: 0.8297 - accuracy: 0.5257 - val_loss: 0.8384 - val_accuracy: 0.3907 - 7s/epoch - 170ms/step\n",
            "Epoch 3/280\n",
            "42/42 - 8s - loss: 0.8287 - accuracy: 0.5195 - val_loss: 0.7877 - val_accuracy: 0.3907 - 8s/epoch - 193ms/step\n",
            "Epoch 4/280\n",
            "42/42 - 7s - loss: 0.8311 - accuracy: 0.5204 - val_loss: 0.7546 - val_accuracy: 0.3907 - 7s/epoch - 174ms/step\n",
            "Epoch 5/280\n",
            "42/42 - 7s - loss: 0.8147 - accuracy: 0.5142 - val_loss: 0.7274 - val_accuracy: 0.3907 - 7s/epoch - 173ms/step\n",
            "Epoch 6/280\n",
            "42/42 - 7s - loss: 0.8158 - accuracy: 0.5142 - val_loss: 0.6993 - val_accuracy: 0.3907 - 7s/epoch - 172ms/step\n",
            "Epoch 7/280\n",
            "42/42 - 8s - loss: 0.8325 - accuracy: 0.5051 - val_loss: 0.6839 - val_accuracy: 0.4016 - 8s/epoch - 190ms/step\n",
            "Epoch 8/280\n",
            "42/42 - 7s - loss: 0.8262 - accuracy: 0.5026 - val_loss: 0.6788 - val_accuracy: 0.5116 - 7s/epoch - 173ms/step\n",
            "Epoch 9/280\n",
            "42/42 - 7s - loss: 0.8243 - accuracy: 0.5166 - val_loss: 0.6697 - val_accuracy: 0.7070 - 7s/epoch - 174ms/step\n",
            "Epoch 10/280\n",
            "42/42 - 8s - loss: 0.8117 - accuracy: 0.5123 - val_loss: 0.6651 - val_accuracy: 0.7829 - 8s/epoch - 191ms/step\n",
            "Epoch 11/280\n",
            "42/42 - 6s - loss: 0.8164 - accuracy: 0.5180 - val_loss: 0.6603 - val_accuracy: 0.8047 - 6s/epoch - 151ms/step\n",
            "Epoch 12/280\n",
            "42/42 - 7s - loss: 0.8298 - accuracy: 0.5070 - val_loss: 0.6615 - val_accuracy: 0.7705 - 7s/epoch - 175ms/step\n",
            "Epoch 13/280\n",
            "42/42 - 6s - loss: 0.8226 - accuracy: 0.5041 - val_loss: 0.6595 - val_accuracy: 0.7798 - 6s/epoch - 152ms/step\n",
            "Epoch 14/280\n",
            "42/42 - 7s - loss: 0.8037 - accuracy: 0.5214 - val_loss: 0.6563 - val_accuracy: 0.7690 - 7s/epoch - 177ms/step\n",
            "Epoch 15/280\n",
            "42/42 - 6s - loss: 0.8089 - accuracy: 0.5147 - val_loss: 0.6526 - val_accuracy: 0.7628 - 6s/epoch - 148ms/step\n",
            "Epoch 16/280\n",
            "42/42 - 8s - loss: 0.8293 - accuracy: 0.5065 - val_loss: 0.6505 - val_accuracy: 0.7581 - 8s/epoch - 197ms/step\n",
            "Epoch 17/280\n",
            "42/42 - 7s - loss: 0.8063 - accuracy: 0.5209 - val_loss: 0.6511 - val_accuracy: 0.7597 - 7s/epoch - 173ms/step\n",
            "Epoch 18/280\n",
            "42/42 - 8s - loss: 0.8125 - accuracy: 0.5132 - val_loss: 0.6460 - val_accuracy: 0.7380 - 8s/epoch - 187ms/step\n",
            "Epoch 19/280\n",
            "42/42 - 8s - loss: 0.8197 - accuracy: 0.5055 - val_loss: 0.6412 - val_accuracy: 0.7349 - 8s/epoch - 179ms/step\n",
            "Epoch 20/280\n",
            "42/42 - 7s - loss: 0.7981 - accuracy: 0.5272 - val_loss: 0.6437 - val_accuracy: 0.7581 - 7s/epoch - 175ms/step\n",
            "Epoch 21/280\n",
            "42/42 - 8s - loss: 0.8127 - accuracy: 0.5190 - val_loss: 0.6397 - val_accuracy: 0.7674 - 8s/epoch - 193ms/step\n",
            "Epoch 22/280\n",
            "42/42 - 6s - loss: 0.7899 - accuracy: 0.5248 - val_loss: 0.6366 - val_accuracy: 0.7628 - 6s/epoch - 145ms/step\n",
            "Epoch 23/280\n",
            "42/42 - 8s - loss: 0.8188 - accuracy: 0.5103 - val_loss: 0.6414 - val_accuracy: 0.7519 - 8s/epoch - 194ms/step\n",
            "Epoch 24/280\n",
            "42/42 - 6s - loss: 0.7917 - accuracy: 0.5228 - val_loss: 0.6263 - val_accuracy: 0.7488 - 6s/epoch - 151ms/step\n",
            "Epoch 25/280\n",
            "42/42 - 8s - loss: 0.7775 - accuracy: 0.5411 - val_loss: 0.6229 - val_accuracy: 0.7721 - 8s/epoch - 194ms/step\n",
            "Epoch 26/280\n",
            "42/42 - 7s - loss: 0.7893 - accuracy: 0.5272 - val_loss: 0.6310 - val_accuracy: 0.7597 - 7s/epoch - 172ms/step\n",
            "Epoch 27/280\n",
            "42/42 - 7s - loss: 0.7833 - accuracy: 0.5378 - val_loss: 0.6244 - val_accuracy: 0.7705 - 7s/epoch - 161ms/step\n",
            "Epoch 28/280\n",
            "42/42 - 7s - loss: 0.7842 - accuracy: 0.5349 - val_loss: 0.6225 - val_accuracy: 0.7752 - 7s/epoch - 172ms/step\n",
            "Epoch 29/280\n",
            "42/42 - 7s - loss: 0.7731 - accuracy: 0.5358 - val_loss: 0.6100 - val_accuracy: 0.7798 - 7s/epoch - 178ms/step\n",
            "Epoch 30/280\n",
            "42/42 - 8s - loss: 0.7751 - accuracy: 0.5430 - val_loss: 0.6034 - val_accuracy: 0.7845 - 8s/epoch - 185ms/step\n",
            "Epoch 31/280\n",
            "42/42 - 7s - loss: 0.7703 - accuracy: 0.5392 - val_loss: 0.5976 - val_accuracy: 0.7814 - 7s/epoch - 169ms/step\n",
            "Epoch 32/280\n",
            "42/42 - 8s - loss: 0.7580 - accuracy: 0.5724 - val_loss: 0.5999 - val_accuracy: 0.7767 - 8s/epoch - 195ms/step\n",
            "Epoch 33/280\n",
            "42/42 - 7s - loss: 0.7867 - accuracy: 0.5373 - val_loss: 0.5925 - val_accuracy: 0.7876 - 7s/epoch - 171ms/step\n",
            "Epoch 34/280\n",
            "42/42 - 7s - loss: 0.7655 - accuracy: 0.5426 - val_loss: 0.5893 - val_accuracy: 0.7860 - 7s/epoch - 172ms/step\n",
            "Epoch 35/280\n",
            "42/42 - 7s - loss: 0.7801 - accuracy: 0.5430 - val_loss: 0.5834 - val_accuracy: 0.7907 - 7s/epoch - 156ms/step\n",
            "Epoch 36/280\n",
            "42/42 - 8s - loss: 0.7665 - accuracy: 0.5613 - val_loss: 0.5830 - val_accuracy: 0.7891 - 8s/epoch - 187ms/step\n",
            "Epoch 37/280\n",
            "42/42 - 7s - loss: 0.7811 - accuracy: 0.5445 - val_loss: 0.5804 - val_accuracy: 0.7953 - 7s/epoch - 173ms/step\n",
            "Epoch 38/280\n",
            "42/42 - 7s - loss: 0.7611 - accuracy: 0.5604 - val_loss: 0.5736 - val_accuracy: 0.7922 - 7s/epoch - 156ms/step\n",
            "Epoch 39/280\n",
            "42/42 - 8s - loss: 0.7403 - accuracy: 0.5661 - val_loss: 0.5639 - val_accuracy: 0.7984 - 8s/epoch - 184ms/step\n",
            "Epoch 40/280\n",
            "42/42 - 6s - loss: 0.7549 - accuracy: 0.5666 - val_loss: 0.5596 - val_accuracy: 0.8016 - 6s/epoch - 149ms/step\n",
            "Epoch 41/280\n",
            "42/42 - 8s - loss: 0.7529 - accuracy: 0.5772 - val_loss: 0.5510 - val_accuracy: 0.8078 - 8s/epoch - 187ms/step\n",
            "Epoch 42/280\n",
            "42/42 - 7s - loss: 0.7460 - accuracy: 0.5830 - val_loss: 0.5482 - val_accuracy: 0.8062 - 7s/epoch - 173ms/step\n",
            "Epoch 43/280\n",
            "42/42 - 7s - loss: 0.7664 - accuracy: 0.5541 - val_loss: 0.5452 - val_accuracy: 0.8062 - 7s/epoch - 173ms/step\n",
            "Epoch 44/280\n",
            "42/42 - 6s - loss: 0.7359 - accuracy: 0.5729 - val_loss: 0.5407 - val_accuracy: 0.8171 - 6s/epoch - 149ms/step\n",
            "Epoch 45/280\n",
            "42/42 - 7s - loss: 0.7374 - accuracy: 0.5772 - val_loss: 0.5408 - val_accuracy: 0.8031 - 7s/epoch - 174ms/step\n",
            "Epoch 46/280\n",
            "42/42 - 6s - loss: 0.7269 - accuracy: 0.5868 - val_loss: 0.5362 - val_accuracy: 0.8062 - 6s/epoch - 149ms/step\n",
            "Epoch 47/280\n",
            "42/42 - 8s - loss: 0.7377 - accuracy: 0.5738 - val_loss: 0.5309 - val_accuracy: 0.8093 - 8s/epoch - 193ms/step\n",
            "Epoch 48/280\n",
            "42/42 - 7s - loss: 0.7145 - accuracy: 0.5974 - val_loss: 0.5147 - val_accuracy: 0.8264 - 7s/epoch - 170ms/step\n",
            "Epoch 49/280\n",
            "42/42 - 8s - loss: 0.7355 - accuracy: 0.5849 - val_loss: 0.5221 - val_accuracy: 0.8155 - 8s/epoch - 180ms/step\n",
            "Epoch 50/280\n",
            "42/42 - 7s - loss: 0.7260 - accuracy: 0.5796 - val_loss: 0.5159 - val_accuracy: 0.8155 - 7s/epoch - 177ms/step\n",
            "Epoch 51/280\n",
            "42/42 - 6s - loss: 0.7132 - accuracy: 0.5859 - val_loss: 0.5105 - val_accuracy: 0.8217 - 6s/epoch - 148ms/step\n",
            "Epoch 52/280\n",
            "42/42 - 7s - loss: 0.7098 - accuracy: 0.6003 - val_loss: 0.5061 - val_accuracy: 0.8295 - 7s/epoch - 171ms/step\n",
            "Epoch 53/280\n",
            "42/42 - 6s - loss: 0.7026 - accuracy: 0.6008 - val_loss: 0.5034 - val_accuracy: 0.8264 - 6s/epoch - 153ms/step\n",
            "Epoch 54/280\n",
            "42/42 - 8s - loss: 0.7077 - accuracy: 0.5979 - val_loss: 0.5049 - val_accuracy: 0.8202 - 8s/epoch - 188ms/step\n",
            "Epoch 55/280\n",
            "42/42 - 7s - loss: 0.7070 - accuracy: 0.5984 - val_loss: 0.4956 - val_accuracy: 0.8264 - 7s/epoch - 172ms/step\n",
            "Epoch 56/280\n",
            "42/42 - 7s - loss: 0.7086 - accuracy: 0.5916 - val_loss: 0.4954 - val_accuracy: 0.8279 - 7s/epoch - 170ms/step\n",
            "Epoch 57/280\n",
            "42/42 - 6s - loss: 0.7029 - accuracy: 0.5955 - val_loss: 0.4898 - val_accuracy: 0.8279 - 6s/epoch - 149ms/step\n",
            "Epoch 58/280\n",
            "42/42 - 7s - loss: 0.7047 - accuracy: 0.5950 - val_loss: 0.4848 - val_accuracy: 0.8326 - 7s/epoch - 175ms/step\n",
            "Epoch 59/280\n",
            "42/42 - 6s - loss: 0.6926 - accuracy: 0.6051 - val_loss: 0.4841 - val_accuracy: 0.8310 - 6s/epoch - 152ms/step\n",
            "Epoch 60/280\n",
            "42/42 - 7s - loss: 0.6849 - accuracy: 0.6166 - val_loss: 0.4831 - val_accuracy: 0.8295 - 7s/epoch - 171ms/step\n",
            "Epoch 61/280\n",
            "42/42 - 6s - loss: 0.6897 - accuracy: 0.6037 - val_loss: 0.4825 - val_accuracy: 0.8248 - 6s/epoch - 149ms/step\n",
            "Epoch 62/280\n",
            "42/42 - 8s - loss: 0.6895 - accuracy: 0.6109 - val_loss: 0.4783 - val_accuracy: 0.8326 - 8s/epoch - 198ms/step\n",
            "Epoch 63/280\n",
            "42/42 - 7s - loss: 0.6782 - accuracy: 0.6147 - val_loss: 0.4740 - val_accuracy: 0.8295 - 7s/epoch - 174ms/step\n",
            "Epoch 64/280\n",
            "42/42 - 8s - loss: 0.6750 - accuracy: 0.6325 - val_loss: 0.4721 - val_accuracy: 0.8310 - 8s/epoch - 183ms/step\n",
            "Epoch 65/280\n",
            "42/42 - 7s - loss: 0.6915 - accuracy: 0.6219 - val_loss: 0.4729 - val_accuracy: 0.8341 - 7s/epoch - 174ms/step\n",
            "Epoch 66/280\n",
            "42/42 - 6s - loss: 0.6694 - accuracy: 0.6301 - val_loss: 0.4729 - val_accuracy: 0.8372 - 6s/epoch - 150ms/step\n",
            "Epoch 67/280\n",
            "42/42 - 7s - loss: 0.6773 - accuracy: 0.6296 - val_loss: 0.4680 - val_accuracy: 0.8372 - 7s/epoch - 174ms/step\n",
            "Epoch 68/280\n",
            "42/42 - 6s - loss: 0.6575 - accuracy: 0.6272 - val_loss: 0.4649 - val_accuracy: 0.8372 - 6s/epoch - 149ms/step\n",
            "Epoch 69/280\n",
            "42/42 - 8s - loss: 0.6584 - accuracy: 0.6344 - val_loss: 0.4660 - val_accuracy: 0.8357 - 8s/epoch - 188ms/step\n",
            "Epoch 70/280\n",
            "42/42 - 6s - loss: 0.6704 - accuracy: 0.6186 - val_loss: 0.4632 - val_accuracy: 0.8341 - 6s/epoch - 149ms/step\n",
            "Epoch 71/280\n",
            "42/42 - 8s - loss: 0.6565 - accuracy: 0.6455 - val_loss: 0.4585 - val_accuracy: 0.8341 - 8s/epoch - 193ms/step\n",
            "Epoch 72/280\n",
            "42/42 - 6s - loss: 0.6647 - accuracy: 0.6388 - val_loss: 0.4583 - val_accuracy: 0.8388 - 6s/epoch - 150ms/step\n",
            "Epoch 73/280\n",
            "42/42 - 7s - loss: 0.6556 - accuracy: 0.6272 - val_loss: 0.4517 - val_accuracy: 0.8372 - 7s/epoch - 175ms/step\n",
            "Epoch 74/280\n",
            "42/42 - 6s - loss: 0.6598 - accuracy: 0.6450 - val_loss: 0.4521 - val_accuracy: 0.8403 - 6s/epoch - 150ms/step\n",
            "Epoch 75/280\n",
            "42/42 - 8s - loss: 0.6343 - accuracy: 0.6590 - val_loss: 0.4502 - val_accuracy: 0.8450 - 8s/epoch - 194ms/step\n",
            "Epoch 76/280\n",
            "42/42 - 7s - loss: 0.6606 - accuracy: 0.6450 - val_loss: 0.4468 - val_accuracy: 0.8388 - 7s/epoch - 171ms/step\n",
            "Epoch 77/280\n",
            "42/42 - 7s - loss: 0.6358 - accuracy: 0.6604 - val_loss: 0.4447 - val_accuracy: 0.8481 - 7s/epoch - 157ms/step\n",
            "Epoch 78/280\n",
            "42/42 - 7s - loss: 0.6335 - accuracy: 0.6585 - val_loss: 0.4435 - val_accuracy: 0.8496 - 7s/epoch - 172ms/step\n",
            "Epoch 79/280\n",
            "42/42 - 7s - loss: 0.6186 - accuracy: 0.6657 - val_loss: 0.4402 - val_accuracy: 0.8512 - 7s/epoch - 156ms/step\n",
            "Epoch 80/280\n",
            "42/42 - 7s - loss: 0.6426 - accuracy: 0.6484 - val_loss: 0.4338 - val_accuracy: 0.8419 - 7s/epoch - 174ms/step\n",
            "Epoch 81/280\n",
            "42/42 - 6s - loss: 0.6453 - accuracy: 0.6494 - val_loss: 0.4326 - val_accuracy: 0.8403 - 6s/epoch - 153ms/step\n",
            "Epoch 82/280\n",
            "42/42 - 8s - loss: 0.6510 - accuracy: 0.6527 - val_loss: 0.4357 - val_accuracy: 0.8450 - 8s/epoch - 181ms/step\n",
            "Epoch 83/280\n",
            "42/42 - 6s - loss: 0.6103 - accuracy: 0.6662 - val_loss: 0.4347 - val_accuracy: 0.8512 - 6s/epoch - 148ms/step\n",
            "Epoch 84/280\n",
            "42/42 - 7s - loss: 0.6076 - accuracy: 0.6782 - val_loss: 0.4248 - val_accuracy: 0.8434 - 7s/epoch - 173ms/step\n",
            "Epoch 85/280\n",
            "42/42 - 7s - loss: 0.6318 - accuracy: 0.6652 - val_loss: 0.4254 - val_accuracy: 0.8419 - 7s/epoch - 174ms/step\n",
            "Epoch 86/280\n",
            "42/42 - 8s - loss: 0.6306 - accuracy: 0.6662 - val_loss: 0.4238 - val_accuracy: 0.8527 - 8s/epoch - 197ms/step\n",
            "Epoch 87/280\n",
            "42/42 - 6s - loss: 0.6221 - accuracy: 0.6657 - val_loss: 0.4203 - val_accuracy: 0.8496 - 6s/epoch - 147ms/step\n",
            "Epoch 88/280\n",
            "42/42 - 7s - loss: 0.6266 - accuracy: 0.6604 - val_loss: 0.4175 - val_accuracy: 0.8512 - 7s/epoch - 170ms/step\n",
            "Epoch 89/280\n",
            "42/42 - 6s - loss: 0.6359 - accuracy: 0.6619 - val_loss: 0.4150 - val_accuracy: 0.8481 - 6s/epoch - 154ms/step\n",
            "Epoch 90/280\n",
            "42/42 - 7s - loss: 0.6216 - accuracy: 0.6715 - val_loss: 0.4171 - val_accuracy: 0.8512 - 7s/epoch - 171ms/step\n",
            "Epoch 91/280\n",
            "42/42 - 7s - loss: 0.6122 - accuracy: 0.6715 - val_loss: 0.4160 - val_accuracy: 0.8589 - 7s/epoch - 171ms/step\n",
            "Epoch 92/280\n",
            "42/42 - 7s - loss: 0.6084 - accuracy: 0.6792 - val_loss: 0.4104 - val_accuracy: 0.8527 - 7s/epoch - 166ms/step\n",
            "Epoch 93/280\n",
            "42/42 - 7s - loss: 0.5893 - accuracy: 0.6859 - val_loss: 0.4102 - val_accuracy: 0.8543 - 7s/epoch - 173ms/step\n",
            "Epoch 94/280\n",
            "42/42 - 7s - loss: 0.6102 - accuracy: 0.6840 - val_loss: 0.4087 - val_accuracy: 0.8527 - 7s/epoch - 159ms/step\n",
            "Epoch 95/280\n",
            "42/42 - 7s - loss: 0.6140 - accuracy: 0.6729 - val_loss: 0.4117 - val_accuracy: 0.8574 - 7s/epoch - 172ms/step\n",
            "Epoch 96/280\n",
            "42/42 - 7s - loss: 0.6049 - accuracy: 0.6888 - val_loss: 0.4076 - val_accuracy: 0.8574 - 7s/epoch - 158ms/step\n",
            "Epoch 97/280\n",
            "42/42 - 8s - loss: 0.5994 - accuracy: 0.6840 - val_loss: 0.4048 - val_accuracy: 0.8605 - 8s/epoch - 182ms/step\n",
            "Epoch 98/280\n",
            "42/42 - 7s - loss: 0.5873 - accuracy: 0.6902 - val_loss: 0.4044 - val_accuracy: 0.8558 - 7s/epoch - 173ms/step\n",
            "Epoch 99/280\n",
            "42/42 - 8s - loss: 0.6180 - accuracy: 0.6710 - val_loss: 0.4059 - val_accuracy: 0.8434 - 8s/epoch - 194ms/step\n",
            "Epoch 100/280\n",
            "42/42 - 7s - loss: 0.6114 - accuracy: 0.6566 - val_loss: 0.4047 - val_accuracy: 0.8574 - 7s/epoch - 170ms/step\n",
            "Epoch 101/280\n",
            "42/42 - 8s - loss: 0.5843 - accuracy: 0.6970 - val_loss: 0.4056 - val_accuracy: 0.8589 - 8s/epoch - 197ms/step\n",
            "Epoch 102/280\n",
            "42/42 - 7s - loss: 0.5801 - accuracy: 0.7056 - val_loss: 0.4018 - val_accuracy: 0.8589 - 7s/epoch - 170ms/step\n",
            "Epoch 103/280\n",
            "42/42 - 8s - loss: 0.5976 - accuracy: 0.6782 - val_loss: 0.3969 - val_accuracy: 0.8605 - 8s/epoch - 180ms/step\n",
            "Epoch 104/280\n",
            "42/42 - 7s - loss: 0.5719 - accuracy: 0.6994 - val_loss: 0.3934 - val_accuracy: 0.8605 - 7s/epoch - 171ms/step\n",
            "Epoch 105/280\n",
            "42/42 - 6s - loss: 0.5850 - accuracy: 0.6830 - val_loss: 0.3950 - val_accuracy: 0.8558 - 6s/epoch - 150ms/step\n",
            "Epoch 106/280\n",
            "42/42 - 8s - loss: 0.5869 - accuracy: 0.6883 - val_loss: 0.3990 - val_accuracy: 0.8543 - 8s/epoch - 187ms/step\n",
            "Epoch 107/280\n",
            "42/42 - 6s - loss: 0.5702 - accuracy: 0.7013 - val_loss: 0.3927 - val_accuracy: 0.8574 - 6s/epoch - 149ms/step\n",
            "Epoch 108/280\n",
            "42/42 - 7s - loss: 0.5731 - accuracy: 0.7090 - val_loss: 0.3940 - val_accuracy: 0.8605 - 7s/epoch - 174ms/step\n",
            "Epoch 109/280\n",
            "42/42 - 6s - loss: 0.5946 - accuracy: 0.6854 - val_loss: 0.3925 - val_accuracy: 0.8558 - 6s/epoch - 153ms/step\n",
            "Epoch 110/280\n",
            "42/42 - 7s - loss: 0.5764 - accuracy: 0.7003 - val_loss: 0.3880 - val_accuracy: 0.8589 - 7s/epoch - 173ms/step\n",
            "Epoch 111/280\n",
            "42/42 - 6s - loss: 0.5694 - accuracy: 0.7143 - val_loss: 0.3864 - val_accuracy: 0.8589 - 6s/epoch - 153ms/step\n",
            "Epoch 112/280\n",
            "42/42 - 8s - loss: 0.5527 - accuracy: 0.7104 - val_loss: 0.3848 - val_accuracy: 0.8589 - 8s/epoch - 194ms/step\n",
            "Epoch 113/280\n",
            "42/42 - 7s - loss: 0.5586 - accuracy: 0.7061 - val_loss: 0.3847 - val_accuracy: 0.8589 - 7s/epoch - 171ms/step\n",
            "Epoch 114/280\n",
            "42/42 - 7s - loss: 0.5718 - accuracy: 0.6989 - val_loss: 0.3866 - val_accuracy: 0.8574 - 7s/epoch - 168ms/step\n",
            "Epoch 115/280\n",
            "42/42 - 7s - loss: 0.5520 - accuracy: 0.7138 - val_loss: 0.3852 - val_accuracy: 0.8605 - 7s/epoch - 174ms/step\n",
            "Epoch 116/280\n",
            "42/42 - 8s - loss: 0.5653 - accuracy: 0.7186 - val_loss: 0.3784 - val_accuracy: 0.8605 - 8s/epoch - 182ms/step\n",
            "Epoch 117/280\n",
            "42/42 - 8s - loss: 0.5516 - accuracy: 0.7210 - val_loss: 0.3860 - val_accuracy: 0.8543 - 8s/epoch - 180ms/step\n",
            "Epoch 118/280\n",
            "42/42 - 6s - loss: 0.5295 - accuracy: 0.7244 - val_loss: 0.3777 - val_accuracy: 0.8636 - 6s/epoch - 149ms/step\n",
            "Epoch 119/280\n",
            "42/42 - 7s - loss: 0.5305 - accuracy: 0.7263 - val_loss: 0.3810 - val_accuracy: 0.8574 - 7s/epoch - 177ms/step\n",
            "Epoch 120/280\n",
            "42/42 - 6s - loss: 0.5386 - accuracy: 0.7152 - val_loss: 0.3762 - val_accuracy: 0.8589 - 6s/epoch - 148ms/step\n",
            "Epoch 121/280\n",
            "42/42 - 8s - loss: 0.5261 - accuracy: 0.7354 - val_loss: 0.3727 - val_accuracy: 0.8636 - 8s/epoch - 191ms/step\n",
            "Epoch 122/280\n",
            "42/42 - 6s - loss: 0.5342 - accuracy: 0.7297 - val_loss: 0.3770 - val_accuracy: 0.8543 - 6s/epoch - 151ms/step\n",
            "Epoch 123/280\n",
            "42/42 - 8s - loss: 0.5375 - accuracy: 0.7239 - val_loss: 0.3739 - val_accuracy: 0.8589 - 8s/epoch - 195ms/step\n",
            "Epoch 124/280\n",
            "42/42 - 7s - loss: 0.5172 - accuracy: 0.7383 - val_loss: 0.3711 - val_accuracy: 0.8574 - 7s/epoch - 175ms/step\n",
            "Epoch 125/280\n",
            "42/42 - 7s - loss: 0.5253 - accuracy: 0.7403 - val_loss: 0.3672 - val_accuracy: 0.8620 - 7s/epoch - 170ms/step\n",
            "Epoch 126/280\n",
            "42/42 - 7s - loss: 0.5235 - accuracy: 0.7369 - val_loss: 0.3709 - val_accuracy: 0.8589 - 7s/epoch - 171ms/step\n",
            "Epoch 127/280\n",
            "42/42 - 8s - loss: 0.5151 - accuracy: 0.7335 - val_loss: 0.3656 - val_accuracy: 0.8636 - 8s/epoch - 182ms/step\n",
            "Epoch 128/280\n",
            "42/42 - 7s - loss: 0.5271 - accuracy: 0.7249 - val_loss: 0.3717 - val_accuracy: 0.8558 - 7s/epoch - 178ms/step\n",
            "Epoch 129/280\n",
            "42/42 - 7s - loss: 0.5416 - accuracy: 0.7249 - val_loss: 0.3680 - val_accuracy: 0.8589 - 7s/epoch - 174ms/step\n",
            "Epoch 130/280\n",
            "42/42 - 7s - loss: 0.5198 - accuracy: 0.7417 - val_loss: 0.3683 - val_accuracy: 0.8558 - 7s/epoch - 173ms/step\n",
            "Epoch 131/280\n",
            "42/42 - 6s - loss: 0.5089 - accuracy: 0.7369 - val_loss: 0.3636 - val_accuracy: 0.8605 - 6s/epoch - 151ms/step\n",
            "Epoch 132/280\n",
            "42/42 - 7s - loss: 0.5006 - accuracy: 0.7561 - val_loss: 0.3588 - val_accuracy: 0.8620 - 7s/epoch - 173ms/step\n",
            "Epoch 133/280\n",
            "42/42 - 6s - loss: 0.5073 - accuracy: 0.7364 - val_loss: 0.3613 - val_accuracy: 0.8543 - 6s/epoch - 152ms/step\n",
            "Epoch 134/280\n",
            "42/42 - 8s - loss: 0.4957 - accuracy: 0.7547 - val_loss: 0.3585 - val_accuracy: 0.8651 - 8s/epoch - 193ms/step\n",
            "Epoch 135/280\n",
            "42/42 - 7s - loss: 0.5003 - accuracy: 0.7557 - val_loss: 0.3592 - val_accuracy: 0.8605 - 7s/epoch - 173ms/step\n",
            "Epoch 136/280\n",
            "42/42 - 7s - loss: 0.4968 - accuracy: 0.7499 - val_loss: 0.3569 - val_accuracy: 0.8605 - 7s/epoch - 168ms/step\n",
            "Epoch 137/280\n",
            "42/42 - 7s - loss: 0.4869 - accuracy: 0.7600 - val_loss: 0.3555 - val_accuracy: 0.8589 - 7s/epoch - 162ms/step\n",
            "Epoch 138/280\n",
            "42/42 - 7s - loss: 0.4906 - accuracy: 0.7518 - val_loss: 0.3546 - val_accuracy: 0.8574 - 7s/epoch - 167ms/step\n",
            "Epoch 139/280\n",
            "42/42 - 7s - loss: 0.4853 - accuracy: 0.7528 - val_loss: 0.3544 - val_accuracy: 0.8589 - 7s/epoch - 172ms/step\n",
            "Epoch 140/280\n",
            "42/42 - 7s - loss: 0.4864 - accuracy: 0.7489 - val_loss: 0.3510 - val_accuracy: 0.8605 - 7s/epoch - 160ms/step\n",
            "Epoch 141/280\n",
            "42/42 - 8s - loss: 0.4897 - accuracy: 0.7542 - val_loss: 0.3474 - val_accuracy: 0.8589 - 8s/epoch - 182ms/step\n",
            "Epoch 142/280\n",
            "42/42 - 6s - loss: 0.4894 - accuracy: 0.7552 - val_loss: 0.3534 - val_accuracy: 0.8574 - 6s/epoch - 151ms/step\n",
            "Epoch 143/280\n",
            "42/42 - 8s - loss: 0.4711 - accuracy: 0.7686 - val_loss: 0.3512 - val_accuracy: 0.8636 - 8s/epoch - 189ms/step\n",
            "Epoch 144/280\n",
            "42/42 - 7s - loss: 0.4670 - accuracy: 0.7648 - val_loss: 0.3443 - val_accuracy: 0.8574 - 7s/epoch - 171ms/step\n",
            "Epoch 145/280\n",
            "42/42 - 7s - loss: 0.4658 - accuracy: 0.7754 - val_loss: 0.3421 - val_accuracy: 0.8605 - 7s/epoch - 176ms/step\n",
            "Epoch 146/280\n",
            "42/42 - 7s - loss: 0.4757 - accuracy: 0.7585 - val_loss: 0.3471 - val_accuracy: 0.8589 - 7s/epoch - 173ms/step\n",
            "Epoch 147/280\n",
            "42/42 - 8s - loss: 0.4802 - accuracy: 0.7658 - val_loss: 0.3537 - val_accuracy: 0.8620 - 8s/epoch - 196ms/step\n",
            "Epoch 148/280\n",
            "42/42 - 7s - loss: 0.4724 - accuracy: 0.7653 - val_loss: 0.3351 - val_accuracy: 0.8636 - 7s/epoch - 173ms/step\n",
            "Epoch 149/280\n",
            "42/42 - 7s - loss: 0.4595 - accuracy: 0.7686 - val_loss: 0.3395 - val_accuracy: 0.8620 - 7s/epoch - 178ms/step\n",
            "Epoch 150/280\n",
            "42/42 - 8s - loss: 0.4648 - accuracy: 0.7730 - val_loss: 0.3414 - val_accuracy: 0.8636 - 8s/epoch - 179ms/step\n",
            "Epoch 151/280\n",
            "42/42 - 6s - loss: 0.4672 - accuracy: 0.7638 - val_loss: 0.3384 - val_accuracy: 0.8605 - 6s/epoch - 153ms/step\n",
            "Epoch 152/280\n",
            "42/42 - 7s - loss: 0.4561 - accuracy: 0.7816 - val_loss: 0.3409 - val_accuracy: 0.8620 - 7s/epoch - 175ms/step\n",
            "Epoch 153/280\n",
            "42/42 - 7s - loss: 0.4385 - accuracy: 0.7908 - val_loss: 0.3377 - val_accuracy: 0.8636 - 7s/epoch - 172ms/step\n",
            "Epoch 154/280\n",
            "42/42 - 7s - loss: 0.4468 - accuracy: 0.7811 - val_loss: 0.3325 - val_accuracy: 0.8636 - 7s/epoch - 173ms/step\n",
            "Epoch 155/280\n",
            "42/42 - 6s - loss: 0.4413 - accuracy: 0.7831 - val_loss: 0.3354 - val_accuracy: 0.8636 - 6s/epoch - 149ms/step\n",
            "Epoch 156/280\n",
            "42/42 - 7s - loss: 0.4470 - accuracy: 0.7816 - val_loss: 0.3388 - val_accuracy: 0.8651 - 7s/epoch - 171ms/step\n",
            "Epoch 157/280\n",
            "42/42 - 7s - loss: 0.4517 - accuracy: 0.7797 - val_loss: 0.3300 - val_accuracy: 0.8667 - 7s/epoch - 171ms/step\n",
            "Epoch 158/280\n",
            "42/42 - 8s - loss: 0.4366 - accuracy: 0.7898 - val_loss: 0.3291 - val_accuracy: 0.8667 - 8s/epoch - 195ms/step\n",
            "Epoch 159/280\n",
            "42/42 - 7s - loss: 0.4391 - accuracy: 0.7893 - val_loss: 0.3249 - val_accuracy: 0.8651 - 7s/epoch - 173ms/step\n",
            "Epoch 160/280\n",
            "42/42 - 7s - loss: 0.4399 - accuracy: 0.7869 - val_loss: 0.3282 - val_accuracy: 0.8651 - 7s/epoch - 178ms/step\n",
            "Epoch 161/280\n",
            "42/42 - 8s - loss: 0.4323 - accuracy: 0.7869 - val_loss: 0.3269 - val_accuracy: 0.8682 - 8s/epoch - 179ms/step\n",
            "Epoch 162/280\n",
            "42/42 - 7s - loss: 0.4223 - accuracy: 0.7917 - val_loss: 0.3276 - val_accuracy: 0.8651 - 7s/epoch - 174ms/step\n",
            "Epoch 163/280\n",
            "42/42 - 8s - loss: 0.4357 - accuracy: 0.7912 - val_loss: 0.3215 - val_accuracy: 0.8698 - 8s/epoch - 195ms/step\n",
            "Epoch 164/280\n",
            "42/42 - 7s - loss: 0.4261 - accuracy: 0.7869 - val_loss: 0.3188 - val_accuracy: 0.8682 - 7s/epoch - 171ms/step\n",
            "Epoch 165/280\n",
            "42/42 - 7s - loss: 0.4367 - accuracy: 0.7874 - val_loss: 0.3282 - val_accuracy: 0.8620 - 7s/epoch - 178ms/step\n",
            "Epoch 166/280\n",
            "42/42 - 7s - loss: 0.4208 - accuracy: 0.8004 - val_loss: 0.3217 - val_accuracy: 0.8667 - 7s/epoch - 158ms/step\n",
            "Epoch 167/280\n",
            "42/42 - 8s - loss: 0.4285 - accuracy: 0.7903 - val_loss: 0.3144 - val_accuracy: 0.8698 - 8s/epoch - 190ms/step\n",
            "Epoch 168/280\n",
            "42/42 - 7s - loss: 0.4368 - accuracy: 0.7754 - val_loss: 0.3187 - val_accuracy: 0.8667 - 7s/epoch - 172ms/step\n",
            "Epoch 169/280\n",
            "42/42 - 7s - loss: 0.4191 - accuracy: 0.7912 - val_loss: 0.3194 - val_accuracy: 0.8651 - 7s/epoch - 157ms/step\n",
            "Epoch 170/280\n",
            "42/42 - 8s - loss: 0.4097 - accuracy: 0.8076 - val_loss: 0.3193 - val_accuracy: 0.8667 - 8s/epoch - 179ms/step\n",
            "Epoch 171/280\n",
            "42/42 - 6s - loss: 0.4071 - accuracy: 0.7999 - val_loss: 0.3171 - val_accuracy: 0.8667 - 6s/epoch - 152ms/step\n",
            "Epoch 172/280\n",
            "42/42 - 8s - loss: 0.4148 - accuracy: 0.8028 - val_loss: 0.3192 - val_accuracy: 0.8667 - 8s/epoch - 184ms/step\n",
            "Epoch 173/280\n",
            "42/42 - 6s - loss: 0.4097 - accuracy: 0.7951 - val_loss: 0.3212 - val_accuracy: 0.8636 - 6s/epoch - 154ms/step\n",
            "Epoch 174/280\n",
            "42/42 - 7s - loss: 0.3943 - accuracy: 0.8090 - val_loss: 0.3104 - val_accuracy: 0.8682 - 7s/epoch - 171ms/step\n",
            "Epoch 175/280\n",
            "42/42 - 7s - loss: 0.3947 - accuracy: 0.8134 - val_loss: 0.3180 - val_accuracy: 0.8605 - 7s/epoch - 171ms/step\n",
            "Epoch 176/280\n",
            "42/42 - 8s - loss: 0.4093 - accuracy: 0.8018 - val_loss: 0.3127 - val_accuracy: 0.8651 - 8s/epoch - 197ms/step\n",
            "Epoch 177/280\n",
            "42/42 - 7s - loss: 0.4008 - accuracy: 0.7994 - val_loss: 0.3135 - val_accuracy: 0.8620 - 7s/epoch - 172ms/step\n",
            "Epoch 178/280\n",
            "42/42 - 7s - loss: 0.3928 - accuracy: 0.8139 - val_loss: 0.3084 - val_accuracy: 0.8636 - 7s/epoch - 169ms/step\n",
            "Epoch 179/280\n",
            "42/42 - 7s - loss: 0.3997 - accuracy: 0.8076 - val_loss: 0.3037 - val_accuracy: 0.8698 - 7s/epoch - 172ms/step\n",
            "Epoch 180/280\n",
            "42/42 - 8s - loss: 0.3782 - accuracy: 0.8158 - val_loss: 0.3027 - val_accuracy: 0.8651 - 8s/epoch - 181ms/step\n",
            "Epoch 181/280\n",
            "42/42 - 7s - loss: 0.3743 - accuracy: 0.8177 - val_loss: 0.2996 - val_accuracy: 0.8729 - 7s/epoch - 173ms/step\n",
            "Epoch 182/280\n",
            "42/42 - 6s - loss: 0.3899 - accuracy: 0.8143 - val_loss: 0.3098 - val_accuracy: 0.8636 - 6s/epoch - 152ms/step\n",
            "Epoch 183/280\n",
            "42/42 - 8s - loss: 0.3713 - accuracy: 0.8139 - val_loss: 0.3074 - val_accuracy: 0.8667 - 8s/epoch - 192ms/step\n",
            "Epoch 184/280\n",
            "42/42 - 6s - loss: 0.3693 - accuracy: 0.8273 - val_loss: 0.2956 - val_accuracy: 0.8713 - 6s/epoch - 150ms/step\n",
            "Epoch 185/280\n",
            "42/42 - 7s - loss: 0.3778 - accuracy: 0.8240 - val_loss: 0.2977 - val_accuracy: 0.8698 - 7s/epoch - 176ms/step\n",
            "Epoch 186/280\n",
            "42/42 - 6s - loss: 0.3834 - accuracy: 0.8134 - val_loss: 0.3023 - val_accuracy: 0.8682 - 6s/epoch - 150ms/step\n",
            "Epoch 187/280\n",
            "42/42 - 8s - loss: 0.3653 - accuracy: 0.8302 - val_loss: 0.3060 - val_accuracy: 0.8651 - 8s/epoch - 195ms/step\n",
            "Epoch 188/280\n",
            "42/42 - 6s - loss: 0.3716 - accuracy: 0.8240 - val_loss: 0.3034 - val_accuracy: 0.8682 - 6s/epoch - 147ms/step\n",
            "Epoch 189/280\n",
            "42/42 - 7s - loss: 0.3704 - accuracy: 0.8273 - val_loss: 0.3035 - val_accuracy: 0.8682 - 7s/epoch - 177ms/step\n",
            "Epoch 190/280\n",
            "42/42 - 6s - loss: 0.3581 - accuracy: 0.8418 - val_loss: 0.3045 - val_accuracy: 0.8729 - 6s/epoch - 151ms/step\n",
            "Epoch 191/280\n",
            "42/42 - 7s - loss: 0.3582 - accuracy: 0.8307 - val_loss: 0.3069 - val_accuracy: 0.8760 - 7s/epoch - 176ms/step\n",
            "Epoch 192/280\n",
            "42/42 - 6s - loss: 0.3709 - accuracy: 0.8240 - val_loss: 0.2996 - val_accuracy: 0.8713 - 6s/epoch - 151ms/step\n",
            "Epoch 193/280\n",
            "42/42 - 7s - loss: 0.3540 - accuracy: 0.8312 - val_loss: 0.3156 - val_accuracy: 0.8775 - 7s/epoch - 178ms/step\n",
            "Epoch 194/280\n",
            "42/42 - 7s - loss: 0.3511 - accuracy: 0.8360 - val_loss: 0.3004 - val_accuracy: 0.8713 - 7s/epoch - 170ms/step\n",
            "Epoch 195/280\n",
            "42/42 - 7s - loss: 0.3422 - accuracy: 0.8389 - val_loss: 0.3011 - val_accuracy: 0.8744 - 7s/epoch - 162ms/step\n",
            "Epoch 196/280\n",
            "42/42 - 7s - loss: 0.3458 - accuracy: 0.8369 - val_loss: 0.2986 - val_accuracy: 0.8729 - 7s/epoch - 163ms/step\n",
            "Epoch 197/280\n",
            "42/42 - 7s - loss: 0.3444 - accuracy: 0.8384 - val_loss: 0.2985 - val_accuracy: 0.8713 - 7s/epoch - 164ms/step\n",
            "Epoch 198/280\n",
            "42/42 - 7s - loss: 0.3388 - accuracy: 0.8461 - val_loss: 0.3093 - val_accuracy: 0.8806 - 7s/epoch - 176ms/step\n",
            "Epoch 199/280\n",
            "42/42 - 7s - loss: 0.3415 - accuracy: 0.8413 - val_loss: 0.2900 - val_accuracy: 0.8744 - 7s/epoch - 175ms/step\n",
            "Epoch 200/280\n",
            "42/42 - 7s - loss: 0.3480 - accuracy: 0.8369 - val_loss: 0.3092 - val_accuracy: 0.8822 - 7s/epoch - 173ms/step\n",
            "Epoch 201/280\n",
            "42/42 - 7s - loss: 0.3419 - accuracy: 0.8432 - val_loss: 0.2855 - val_accuracy: 0.8791 - 7s/epoch - 172ms/step\n",
            "Epoch 202/280\n",
            "42/42 - 7s - loss: 0.3385 - accuracy: 0.8422 - val_loss: 0.3035 - val_accuracy: 0.8837 - 7s/epoch - 171ms/step\n",
            "Epoch 203/280\n",
            "42/42 - 7s - loss: 0.3335 - accuracy: 0.8432 - val_loss: 0.2908 - val_accuracy: 0.8806 - 7s/epoch - 170ms/step\n",
            "Epoch 204/280\n",
            "42/42 - 8s - loss: 0.3395 - accuracy: 0.8384 - val_loss: 0.3000 - val_accuracy: 0.8822 - 8s/epoch - 195ms/step\n",
            "Epoch 205/280\n",
            "42/42 - 7s - loss: 0.3225 - accuracy: 0.8586 - val_loss: 0.2877 - val_accuracy: 0.8853 - 7s/epoch - 172ms/step\n",
            "Epoch 206/280\n",
            "42/42 - 8s - loss: 0.3326 - accuracy: 0.8389 - val_loss: 0.2850 - val_accuracy: 0.8822 - 8s/epoch - 183ms/step\n",
            "Epoch 207/280\n",
            "42/42 - 8s - loss: 0.3192 - accuracy: 0.8591 - val_loss: 0.2981 - val_accuracy: 0.8884 - 8s/epoch - 180ms/step\n",
            "Epoch 208/280\n",
            "42/42 - 7s - loss: 0.3353 - accuracy: 0.8413 - val_loss: 0.2789 - val_accuracy: 0.8837 - 7s/epoch - 172ms/step\n",
            "Epoch 209/280\n",
            "42/42 - 8s - loss: 0.3132 - accuracy: 0.8499 - val_loss: 0.2919 - val_accuracy: 0.8868 - 8s/epoch - 195ms/step\n",
            "Epoch 210/280\n",
            "42/42 - 6s - loss: 0.3153 - accuracy: 0.8562 - val_loss: 0.2877 - val_accuracy: 0.8868 - 6s/epoch - 149ms/step\n",
            "Epoch 211/280\n",
            "42/42 - 7s - loss: 0.3220 - accuracy: 0.8461 - val_loss: 0.2705 - val_accuracy: 0.8837 - 7s/epoch - 176ms/step\n",
            "Epoch 212/280\n",
            "42/42 - 6s - loss: 0.3176 - accuracy: 0.8523 - val_loss: 0.2906 - val_accuracy: 0.8853 - 6s/epoch - 151ms/step\n",
            "Epoch 213/280\n",
            "42/42 - 7s - loss: 0.3266 - accuracy: 0.8470 - val_loss: 0.2923 - val_accuracy: 0.8806 - 7s/epoch - 178ms/step\n",
            "Epoch 214/280\n",
            "42/42 - 6s - loss: 0.3157 - accuracy: 0.8523 - val_loss: 0.2827 - val_accuracy: 0.8837 - 6s/epoch - 152ms/step\n",
            "Epoch 215/280\n",
            "42/42 - 7s - loss: 0.2970 - accuracy: 0.8735 - val_loss: 0.2920 - val_accuracy: 0.8791 - 7s/epoch - 176ms/step\n",
            "Epoch 216/280\n",
            "42/42 - 7s - loss: 0.3051 - accuracy: 0.8620 - val_loss: 0.2960 - val_accuracy: 0.8791 - 7s/epoch - 172ms/step\n",
            "Epoch 217/280\n",
            "42/42 - 8s - loss: 0.2985 - accuracy: 0.8634 - val_loss: 0.2964 - val_accuracy: 0.8822 - 8s/epoch - 188ms/step\n",
            "Epoch 218/280\n",
            "42/42 - 8s - loss: 0.3247 - accuracy: 0.8485 - val_loss: 0.2759 - val_accuracy: 0.8868 - 8s/epoch - 179ms/step\n",
            "Epoch 219/280\n",
            "42/42 - 6s - loss: 0.3119 - accuracy: 0.8528 - val_loss: 0.2905 - val_accuracy: 0.8853 - 6s/epoch - 152ms/step\n",
            "Epoch 220/280\n",
            "42/42 - 7s - loss: 0.3045 - accuracy: 0.8620 - val_loss: 0.3095 - val_accuracy: 0.8791 - 7s/epoch - 173ms/step\n",
            "Epoch 221/280\n",
            "42/42 - 6s - loss: 0.2850 - accuracy: 0.8749 - val_loss: 0.2874 - val_accuracy: 0.8868 - 6s/epoch - 153ms/step\n",
            "Epoch 222/280\n",
            "42/42 - 7s - loss: 0.2917 - accuracy: 0.8648 - val_loss: 0.2853 - val_accuracy: 0.8868 - 7s/epoch - 171ms/step\n",
            "Epoch 223/280\n",
            "42/42 - 6s - loss: 0.3091 - accuracy: 0.8567 - val_loss: 0.2974 - val_accuracy: 0.8822 - 6s/epoch - 151ms/step\n",
            "Epoch 224/280\n",
            "42/42 - 8s - loss: 0.2928 - accuracy: 0.8653 - val_loss: 0.2760 - val_accuracy: 0.8930 - 8s/epoch - 192ms/step\n",
            "Epoch 225/280\n",
            "42/42 - 7s - loss: 0.2764 - accuracy: 0.8884 - val_loss: 0.2884 - val_accuracy: 0.8853 - 7s/epoch - 173ms/step\n",
            "Epoch 226/280\n",
            "42/42 - 8s - loss: 0.2977 - accuracy: 0.8552 - val_loss: 0.2738 - val_accuracy: 0.8930 - 8s/epoch - 197ms/step\n",
            "Epoch 227/280\n",
            "42/42 - 7s - loss: 0.2819 - accuracy: 0.8797 - val_loss: 0.2888 - val_accuracy: 0.8853 - 7s/epoch - 156ms/step\n",
            "Epoch 228/280\n",
            "42/42 - 7s - loss: 0.2798 - accuracy: 0.8826 - val_loss: 0.2860 - val_accuracy: 0.8837 - 7s/epoch - 168ms/step\n",
            "Epoch 229/280\n",
            "42/42 - 7s - loss: 0.2885 - accuracy: 0.8672 - val_loss: 0.2739 - val_accuracy: 0.8899 - 7s/epoch - 174ms/step\n",
            "Epoch 230/280\n",
            "42/42 - 8s - loss: 0.2766 - accuracy: 0.8826 - val_loss: 0.2710 - val_accuracy: 0.8961 - 8s/epoch - 181ms/step\n",
            "Epoch 231/280\n",
            "42/42 - 8s - loss: 0.2666 - accuracy: 0.8797 - val_loss: 0.2792 - val_accuracy: 0.8884 - 8s/epoch - 196ms/step\n",
            "Epoch 232/280\n",
            "42/42 - 6s - loss: 0.2719 - accuracy: 0.8831 - val_loss: 0.2727 - val_accuracy: 0.8930 - 6s/epoch - 153ms/step\n",
            "Epoch 233/280\n",
            "42/42 - 8s - loss: 0.2778 - accuracy: 0.8793 - val_loss: 0.2929 - val_accuracy: 0.8853 - 8s/epoch - 196ms/step\n",
            "Epoch 234/280\n",
            "42/42 - 7s - loss: 0.2685 - accuracy: 0.8764 - val_loss: 0.2712 - val_accuracy: 0.8884 - 7s/epoch - 177ms/step\n",
            "Epoch 235/280\n",
            "42/42 - 8s - loss: 0.2814 - accuracy: 0.8692 - val_loss: 0.2829 - val_accuracy: 0.8868 - 8s/epoch - 194ms/step\n",
            "Epoch 236/280\n",
            "42/42 - 7s - loss: 0.2723 - accuracy: 0.8802 - val_loss: 0.2980 - val_accuracy: 0.8884 - 7s/epoch - 178ms/step\n",
            "Epoch 237/280\n",
            "42/42 - 8s - loss: 0.2700 - accuracy: 0.8778 - val_loss: 0.2776 - val_accuracy: 0.8899 - 8s/epoch - 181ms/step\n",
            "Epoch 238/280\n",
            "42/42 - 8s - loss: 0.2763 - accuracy: 0.8769 - val_loss: 0.2933 - val_accuracy: 0.8884 - 8s/epoch - 180ms/step\n",
            "Epoch 239/280\n",
            "42/42 - 7s - loss: 0.2692 - accuracy: 0.8841 - val_loss: 0.2854 - val_accuracy: 0.8884 - 7s/epoch - 176ms/step\n",
            "Epoch 240/280\n",
            "42/42 - 7s - loss: 0.2577 - accuracy: 0.8913 - val_loss: 0.2749 - val_accuracy: 0.8946 - 7s/epoch - 176ms/step\n",
            "Epoch 241/280\n",
            "42/42 - 7s - loss: 0.2514 - accuracy: 0.8932 - val_loss: 0.3082 - val_accuracy: 0.8822 - 7s/epoch - 176ms/step\n",
            "Epoch 242/280\n",
            "42/42 - 7s - loss: 0.2582 - accuracy: 0.8846 - val_loss: 0.3028 - val_accuracy: 0.8853 - 7s/epoch - 173ms/step\n",
            "Epoch 243/280\n",
            "42/42 - 7s - loss: 0.2557 - accuracy: 0.8889 - val_loss: 0.3015 - val_accuracy: 0.8837 - 7s/epoch - 162ms/step\n",
            "Epoch 244/280\n",
            "42/42 - 7s - loss: 0.2595 - accuracy: 0.8850 - val_loss: 0.2795 - val_accuracy: 0.8930 - 7s/epoch - 164ms/step\n",
            "Epoch 245/280\n",
            "42/42 - 7s - loss: 0.2374 - accuracy: 0.9019 - val_loss: 0.2826 - val_accuracy: 0.8899 - 7s/epoch - 177ms/step\n",
            "Epoch 246/280\n",
            "42/42 - 8s - loss: 0.2385 - accuracy: 0.9024 - val_loss: 0.2680 - val_accuracy: 0.8977 - 8s/epoch - 184ms/step\n",
            "Epoch 247/280\n",
            "42/42 - 7s - loss: 0.2377 - accuracy: 0.8975 - val_loss: 0.2670 - val_accuracy: 0.9008 - 7s/epoch - 176ms/step\n",
            "Epoch 248/280\n",
            "42/42 - 6s - loss: 0.2406 - accuracy: 0.8966 - val_loss: 0.2849 - val_accuracy: 0.8946 - 6s/epoch - 154ms/step\n",
            "Epoch 249/280\n",
            "42/42 - 8s - loss: 0.2409 - accuracy: 0.8913 - val_loss: 0.2774 - val_accuracy: 0.8961 - 8s/epoch - 196ms/step\n",
            "Epoch 250/280\n",
            "42/42 - 7s - loss: 0.2393 - accuracy: 0.9004 - val_loss: 0.3042 - val_accuracy: 0.8837 - 7s/epoch - 157ms/step\n",
            "Epoch 251/280\n",
            "42/42 - 8s - loss: 0.2382 - accuracy: 0.8942 - val_loss: 0.2670 - val_accuracy: 0.8992 - 8s/epoch - 200ms/step\n",
            "Epoch 252/280\n",
            "42/42 - 7s - loss: 0.2339 - accuracy: 0.8966 - val_loss: 0.2916 - val_accuracy: 0.8884 - 7s/epoch - 158ms/step\n",
            "Epoch 253/280\n",
            "42/42 - 7s - loss: 0.2343 - accuracy: 0.8932 - val_loss: 0.3023 - val_accuracy: 0.8853 - 7s/epoch - 171ms/step\n",
            "Epoch 254/280\n",
            "42/42 - 7s - loss: 0.2441 - accuracy: 0.8899 - val_loss: 0.2778 - val_accuracy: 0.8946 - 7s/epoch - 176ms/step\n",
            "Epoch 255/280\n",
            "42/42 - 8s - loss: 0.2359 - accuracy: 0.8971 - val_loss: 0.2984 - val_accuracy: 0.8853 - 8s/epoch - 183ms/step\n",
            "Epoch 256/280\n",
            "42/42 - 8s - loss: 0.2307 - accuracy: 0.8995 - val_loss: 0.2758 - val_accuracy: 0.8977 - 8s/epoch - 187ms/step\n",
            "Epoch 257/280\n",
            "42/42 - 6s - loss: 0.2147 - accuracy: 0.9158 - val_loss: 0.2930 - val_accuracy: 0.8868 - 6s/epoch - 154ms/step\n",
            "Epoch 258/280\n",
            "42/42 - 8s - loss: 0.2427 - accuracy: 0.8918 - val_loss: 0.2956 - val_accuracy: 0.8853 - 8s/epoch - 200ms/step\n",
            "Epoch 259/280\n",
            "42/42 - 7s - loss: 0.2211 - accuracy: 0.9173 - val_loss: 0.2738 - val_accuracy: 0.9008 - 7s/epoch - 176ms/step\n",
            "Epoch 260/280\n",
            "42/42 - 7s - loss: 0.2320 - accuracy: 0.9009 - val_loss: 0.2581 - val_accuracy: 0.9039 - 7s/epoch - 173ms/step\n",
            "Epoch 261/280\n",
            "42/42 - 7s - loss: 0.2262 - accuracy: 0.9072 - val_loss: 0.2851 - val_accuracy: 0.8946 - 7s/epoch - 176ms/step\n",
            "Epoch 262/280\n",
            "42/42 - 8s - loss: 0.2171 - accuracy: 0.9120 - val_loss: 0.2639 - val_accuracy: 0.9008 - 8s/epoch - 187ms/step\n",
            "Epoch 263/280\n",
            "42/42 - 8s - loss: 0.2186 - accuracy: 0.9062 - val_loss: 0.2944 - val_accuracy: 0.8930 - 8s/epoch - 190ms/step\n",
            "Epoch 264/280\n",
            "42/42 - 7s - loss: 0.2204 - accuracy: 0.9028 - val_loss: 0.2733 - val_accuracy: 0.9039 - 7s/epoch - 175ms/step\n",
            "Epoch 265/280\n",
            "42/42 - 8s - loss: 0.2175 - accuracy: 0.9129 - val_loss: 0.3096 - val_accuracy: 0.8775 - 8s/epoch - 198ms/step\n",
            "Epoch 266/280\n",
            "42/42 - 8s - loss: 0.2091 - accuracy: 0.9110 - val_loss: 0.2824 - val_accuracy: 0.8946 - 8s/epoch - 179ms/step\n",
            "Epoch 267/280\n",
            "42/42 - 7s - loss: 0.2250 - accuracy: 0.9048 - val_loss: 0.2904 - val_accuracy: 0.8930 - 7s/epoch - 168ms/step\n",
            "Epoch 268/280\n",
            "42/42 - 8s - loss: 0.2030 - accuracy: 0.9125 - val_loss: 0.2784 - val_accuracy: 0.8977 - 8s/epoch - 179ms/step\n",
            "Epoch 269/280\n",
            "42/42 - 7s - loss: 0.2090 - accuracy: 0.9153 - val_loss: 0.2701 - val_accuracy: 0.9008 - 7s/epoch - 161ms/step\n",
            "Epoch 270/280\n",
            "42/42 - 8s - loss: 0.2137 - accuracy: 0.9067 - val_loss: 0.2935 - val_accuracy: 0.8868 - 8s/epoch - 186ms/step\n",
            "Epoch 271/280\n",
            "42/42 - 6s - loss: 0.2009 - accuracy: 0.9211 - val_loss: 0.2829 - val_accuracy: 0.8899 - 6s/epoch - 155ms/step\n",
            "Epoch 272/280\n",
            "42/42 - 7s - loss: 0.2010 - accuracy: 0.9144 - val_loss: 0.2706 - val_accuracy: 0.9039 - 7s/epoch - 173ms/step\n",
            "Epoch 273/280\n",
            "42/42 - 7s - loss: 0.1987 - accuracy: 0.9259 - val_loss: 0.3254 - val_accuracy: 0.8760 - 7s/epoch - 156ms/step\n",
            "Epoch 274/280\n",
            "42/42 - 8s - loss: 0.2003 - accuracy: 0.9216 - val_loss: 0.2593 - val_accuracy: 0.9039 - 8s/epoch - 180ms/step\n",
            "Epoch 275/280\n",
            "42/42 - 7s - loss: 0.1955 - accuracy: 0.9206 - val_loss: 0.2916 - val_accuracy: 0.8915 - 7s/epoch - 155ms/step\n",
            "Epoch 276/280\n",
            "42/42 - 7s - loss: 0.2078 - accuracy: 0.9043 - val_loss: 0.2775 - val_accuracy: 0.8930 - 7s/epoch - 179ms/step\n",
            "Epoch 277/280\n",
            "42/42 - 7s - loss: 0.1979 - accuracy: 0.9235 - val_loss: 0.3174 - val_accuracy: 0.8791 - 7s/epoch - 155ms/step\n",
            "Epoch 278/280\n",
            "42/42 - 8s - loss: 0.1848 - accuracy: 0.9240 - val_loss: 0.2821 - val_accuracy: 0.8930 - 8s/epoch - 197ms/step\n",
            "Epoch 279/280\n",
            "42/42 - 7s - loss: 0.1931 - accuracy: 0.9211 - val_loss: 0.2768 - val_accuracy: 0.8977 - 7s/epoch - 177ms/step\n",
            "Epoch 280/280\n",
            "42/42 - 7s - loss: 0.1910 - accuracy: 0.9245 - val_loss: 0.2805 - val_accuracy: 0.8961 - 7s/epoch - 162ms/step\n",
            "Training end\n",
            "Testing start\n",
            "Testing end\n",
            "Model saved\n",
            "True Positive, False Positive, False negative, Second of Inter in Test, Sensitivity, FPR\n",
            "31,0,15,10500,0.6739130434782609,0.0\n",
            "SEIZURE OUT: 3\n",
            "Training start\n",
            "Epoch 1/280\n",
            "42/42 - 12s - loss: 0.9299 - accuracy: 0.4964 - val_loss: 0.8164 - val_accuracy: 0.3516 - 12s/epoch - 297ms/step\n",
            "Epoch 2/280\n",
            "42/42 - 8s - loss: 0.8927 - accuracy: 0.5041 - val_loss: 0.7740 - val_accuracy: 0.3516 - 8s/epoch - 179ms/step\n",
            "Epoch 3/280\n",
            "42/42 - 9s - loss: 0.8467 - accuracy: 0.5118 - val_loss: 0.7426 - val_accuracy: 0.3516 - 9s/epoch - 214ms/step\n",
            "Epoch 4/280\n",
            "42/42 - 10s - loss: 0.8274 - accuracy: 0.5224 - val_loss: 0.7267 - val_accuracy: 0.3516 - 10s/epoch - 249ms/step\n",
            "Epoch 5/280\n",
            "42/42 - 7s - loss: 0.8285 - accuracy: 0.5108 - val_loss: 0.7220 - val_accuracy: 0.3516 - 7s/epoch - 171ms/step\n",
            "Epoch 6/280\n",
            "42/42 - 9s - loss: 0.8343 - accuracy: 0.5022 - val_loss: 0.7228 - val_accuracy: 0.3516 - 9s/epoch - 206ms/step\n",
            "Epoch 7/280\n",
            "42/42 - 7s - loss: 0.8158 - accuracy: 0.5296 - val_loss: 0.7254 - val_accuracy: 0.3516 - 7s/epoch - 175ms/step\n",
            "Epoch 8/280\n",
            "42/42 - 8s - loss: 0.8347 - accuracy: 0.4935 - val_loss: 0.7303 - val_accuracy: 0.3516 - 8s/epoch - 179ms/step\n",
            "Epoch 9/280\n",
            "42/42 - 7s - loss: 0.8211 - accuracy: 0.5152 - val_loss: 0.7287 - val_accuracy: 0.3516 - 7s/epoch - 175ms/step\n",
            "Epoch 10/280\n",
            "42/42 - 7s - loss: 0.8163 - accuracy: 0.5070 - val_loss: 0.7277 - val_accuracy: 0.3516 - 7s/epoch - 163ms/step\n",
            "Epoch 11/280\n",
            "42/42 - 8s - loss: 0.8047 - accuracy: 0.5195 - val_loss: 0.7291 - val_accuracy: 0.3516 - 8s/epoch - 189ms/step\n",
            "Epoch 12/280\n",
            "42/42 - 7s - loss: 0.8180 - accuracy: 0.5036 - val_loss: 0.7308 - val_accuracy: 0.3516 - 7s/epoch - 170ms/step\n",
            "Epoch 13/280\n",
            "42/42 - 8s - loss: 0.8133 - accuracy: 0.5041 - val_loss: 0.7244 - val_accuracy: 0.3516 - 8s/epoch - 179ms/step\n",
            "Epoch 14/280\n",
            "42/42 - 6s - loss: 0.8010 - accuracy: 0.5224 - val_loss: 0.7191 - val_accuracy: 0.3516 - 6s/epoch - 150ms/step\n",
            "Epoch 15/280\n",
            "42/42 - 9s - loss: 0.8176 - accuracy: 0.5123 - val_loss: 0.7234 - val_accuracy: 0.3516 - 9s/epoch - 209ms/step\n",
            "Epoch 16/280\n",
            "42/42 - 8s - loss: 0.8090 - accuracy: 0.5079 - val_loss: 0.7236 - val_accuracy: 0.3516 - 8s/epoch - 195ms/step\n",
            "Epoch 17/280\n",
            "42/42 - 8s - loss: 0.8047 - accuracy: 0.5118 - val_loss: 0.7236 - val_accuracy: 0.3516 - 8s/epoch - 179ms/step\n",
            "Epoch 18/280\n",
            "42/42 - 7s - loss: 0.7959 - accuracy: 0.5267 - val_loss: 0.7308 - val_accuracy: 0.3516 - 7s/epoch - 175ms/step\n",
            "Epoch 19/280\n",
            "42/42 - 7s - loss: 0.8153 - accuracy: 0.5060 - val_loss: 0.7254 - val_accuracy: 0.3516 - 7s/epoch - 176ms/step\n",
            "Epoch 20/280\n",
            "42/42 - 8s - loss: 0.8169 - accuracy: 0.4954 - val_loss: 0.7218 - val_accuracy: 0.3516 - 8s/epoch - 198ms/step\n",
            "Epoch 21/280\n",
            "42/42 - 6s - loss: 0.8086 - accuracy: 0.5108 - val_loss: 0.7131 - val_accuracy: 0.3532 - 6s/epoch - 146ms/step\n",
            "Epoch 22/280\n",
            "42/42 - 9s - loss: 0.8172 - accuracy: 0.5075 - val_loss: 0.7129 - val_accuracy: 0.3532 - 9s/epoch - 217ms/step\n",
            "Epoch 23/280\n",
            "42/42 - 8s - loss: 0.8152 - accuracy: 0.5103 - val_loss: 0.7161 - val_accuracy: 0.3516 - 8s/epoch - 200ms/step\n",
            "Epoch 24/280\n",
            "42/42 - 7s - loss: 0.7988 - accuracy: 0.5113 - val_loss: 0.7146 - val_accuracy: 0.3516 - 7s/epoch - 161ms/step\n",
            "Epoch 25/280\n",
            "42/42 - 8s - loss: 0.8088 - accuracy: 0.5017 - val_loss: 0.7121 - val_accuracy: 0.3516 - 8s/epoch - 184ms/step\n",
            "Epoch 26/280\n",
            "42/42 - 7s - loss: 0.8063 - accuracy: 0.5118 - val_loss: 0.7131 - val_accuracy: 0.3516 - 7s/epoch - 165ms/step\n",
            "Epoch 27/280\n",
            "42/42 - 9s - loss: 0.8059 - accuracy: 0.5171 - val_loss: 0.7084 - val_accuracy: 0.3565 - 9s/epoch - 216ms/step\n",
            "Epoch 28/280\n",
            "42/42 - 8s - loss: 0.7947 - accuracy: 0.5089 - val_loss: 0.7058 - val_accuracy: 0.3581 - 8s/epoch - 191ms/step\n",
            "Epoch 29/280\n",
            "42/42 - 7s - loss: 0.8043 - accuracy: 0.5147 - val_loss: 0.7006 - val_accuracy: 0.3984 - 7s/epoch - 166ms/step\n",
            "Epoch 30/280\n",
            "42/42 - 8s - loss: 0.8024 - accuracy: 0.5099 - val_loss: 0.6960 - val_accuracy: 0.4258 - 8s/epoch - 194ms/step\n",
            "Epoch 31/280\n",
            "42/42 - 8s - loss: 0.7888 - accuracy: 0.5166 - val_loss: 0.6968 - val_accuracy: 0.4242 - 8s/epoch - 188ms/step\n",
            "Epoch 32/280\n",
            "42/42 - 8s - loss: 0.7944 - accuracy: 0.5329 - val_loss: 0.6897 - val_accuracy: 0.4935 - 8s/epoch - 194ms/step\n",
            "Epoch 33/280\n",
            "42/42 - 8s - loss: 0.7939 - accuracy: 0.5277 - val_loss: 0.6845 - val_accuracy: 0.5516 - 8s/epoch - 181ms/step\n",
            "Epoch 34/280\n",
            "42/42 - 8s - loss: 0.7811 - accuracy: 0.5267 - val_loss: 0.6944 - val_accuracy: 0.4629 - 8s/epoch - 187ms/step\n",
            "Epoch 35/280\n",
            "42/42 - 8s - loss: 0.7911 - accuracy: 0.5118 - val_loss: 0.6935 - val_accuracy: 0.4597 - 8s/epoch - 182ms/step\n",
            "Epoch 36/280\n",
            "42/42 - 7s - loss: 0.7858 - accuracy: 0.5277 - val_loss: 0.6873 - val_accuracy: 0.5113 - 7s/epoch - 174ms/step\n",
            "Epoch 37/280\n",
            "42/42 - 7s - loss: 0.7696 - accuracy: 0.5320 - val_loss: 0.6787 - val_accuracy: 0.5806 - 7s/epoch - 168ms/step\n",
            "Epoch 38/280\n",
            "42/42 - 6s - loss: 0.7805 - accuracy: 0.5185 - val_loss: 0.6825 - val_accuracy: 0.5484 - 6s/epoch - 148ms/step\n",
            "Epoch 39/280\n",
            "42/42 - 7s - loss: 0.7824 - accuracy: 0.5195 - val_loss: 0.6665 - val_accuracy: 0.6419 - 7s/epoch - 169ms/step\n",
            "Epoch 40/280\n",
            "42/42 - 6s - loss: 0.7638 - accuracy: 0.5329 - val_loss: 0.6685 - val_accuracy: 0.6161 - 6s/epoch - 149ms/step\n",
            "Epoch 41/280\n",
            "42/42 - 8s - loss: 0.7809 - accuracy: 0.5219 - val_loss: 0.6559 - val_accuracy: 0.6694 - 8s/epoch - 195ms/step\n",
            "Epoch 42/280\n",
            "42/42 - 7s - loss: 0.7588 - accuracy: 0.5416 - val_loss: 0.6620 - val_accuracy: 0.6274 - 7s/epoch - 172ms/step\n",
            "Epoch 43/280\n",
            "42/42 - 7s - loss: 0.7729 - accuracy: 0.5368 - val_loss: 0.6524 - val_accuracy: 0.6581 - 7s/epoch - 174ms/step\n",
            "Epoch 44/280\n",
            "42/42 - 7s - loss: 0.7564 - accuracy: 0.5402 - val_loss: 0.6502 - val_accuracy: 0.6484 - 7s/epoch - 161ms/step\n",
            "Epoch 45/280\n",
            "42/42 - 7s - loss: 0.7625 - accuracy: 0.5474 - val_loss: 0.6350 - val_accuracy: 0.7113 - 7s/epoch - 172ms/step\n",
            "Epoch 46/280\n",
            "42/42 - 7s - loss: 0.7724 - accuracy: 0.5354 - val_loss: 0.6320 - val_accuracy: 0.6984 - 7s/epoch - 164ms/step\n",
            "Epoch 47/280\n",
            "42/42 - 7s - loss: 0.7691 - accuracy: 0.5368 - val_loss: 0.6317 - val_accuracy: 0.6968 - 7s/epoch - 171ms/step\n",
            "Epoch 48/280\n",
            "42/42 - 8s - loss: 0.7570 - accuracy: 0.5440 - val_loss: 0.6272 - val_accuracy: 0.6984 - 8s/epoch - 199ms/step\n",
            "Epoch 49/280\n",
            "42/42 - 6s - loss: 0.7329 - accuracy: 0.5782 - val_loss: 0.6246 - val_accuracy: 0.6694 - 6s/epoch - 154ms/step\n",
            "Epoch 50/280\n",
            "42/42 - 8s - loss: 0.7168 - accuracy: 0.5791 - val_loss: 0.6143 - val_accuracy: 0.7048 - 8s/epoch - 194ms/step\n",
            "Epoch 51/280\n",
            "42/42 - 6s - loss: 0.7214 - accuracy: 0.5690 - val_loss: 0.6108 - val_accuracy: 0.7081 - 6s/epoch - 150ms/step\n",
            "Epoch 52/280\n",
            "42/42 - 7s - loss: 0.7207 - accuracy: 0.5810 - val_loss: 0.6199 - val_accuracy: 0.6629 - 7s/epoch - 177ms/step\n",
            "Epoch 53/280\n",
            "42/42 - 7s - loss: 0.7112 - accuracy: 0.5844 - val_loss: 0.6046 - val_accuracy: 0.6919 - 7s/epoch - 177ms/step\n",
            "Epoch 54/280\n",
            "42/42 - 8s - loss: 0.7080 - accuracy: 0.5849 - val_loss: 0.6094 - val_accuracy: 0.6726 - 8s/epoch - 198ms/step\n",
            "Epoch 55/280\n",
            "42/42 - 7s - loss: 0.7121 - accuracy: 0.5868 - val_loss: 0.6278 - val_accuracy: 0.6306 - 7s/epoch - 176ms/step\n",
            "Epoch 56/280\n",
            "42/42 - 7s - loss: 0.7001 - accuracy: 0.6094 - val_loss: 0.5896 - val_accuracy: 0.7113 - 7s/epoch - 159ms/step\n",
            "Epoch 57/280\n",
            "42/42 - 8s - loss: 0.6795 - accuracy: 0.6123 - val_loss: 0.5878 - val_accuracy: 0.7016 - 8s/epoch - 184ms/step\n",
            "Epoch 58/280\n",
            "42/42 - 7s - loss: 0.6871 - accuracy: 0.6075 - val_loss: 0.5795 - val_accuracy: 0.7194 - 7s/epoch - 171ms/step\n",
            "Epoch 59/280\n",
            "42/42 - 8s - loss: 0.6933 - accuracy: 0.6003 - val_loss: 0.5728 - val_accuracy: 0.7210 - 8s/epoch - 194ms/step\n",
            "Epoch 60/280\n",
            "42/42 - 7s - loss: 0.6586 - accuracy: 0.6479 - val_loss: 0.5968 - val_accuracy: 0.6774 - 7s/epoch - 173ms/step\n",
            "Epoch 61/280\n",
            "42/42 - 7s - loss: 0.6630 - accuracy: 0.6354 - val_loss: 0.5776 - val_accuracy: 0.6984 - 7s/epoch - 171ms/step\n",
            "Epoch 62/280\n",
            "42/42 - 6s - loss: 0.6635 - accuracy: 0.6359 - val_loss: 0.5778 - val_accuracy: 0.6952 - 6s/epoch - 150ms/step\n",
            "Epoch 63/280\n",
            "42/42 - 8s - loss: 0.6640 - accuracy: 0.6335 - val_loss: 0.5760 - val_accuracy: 0.6952 - 8s/epoch - 196ms/step\n",
            "Epoch 64/280\n",
            "42/42 - 7s - loss: 0.6768 - accuracy: 0.6229 - val_loss: 0.5466 - val_accuracy: 0.7306 - 7s/epoch - 162ms/step\n",
            "Epoch 65/280\n",
            "42/42 - 7s - loss: 0.6548 - accuracy: 0.6489 - val_loss: 0.5641 - val_accuracy: 0.7032 - 7s/epoch - 160ms/step\n",
            "Epoch 66/280\n",
            "42/42 - 7s - loss: 0.6585 - accuracy: 0.6378 - val_loss: 0.5513 - val_accuracy: 0.7194 - 7s/epoch - 172ms/step\n",
            "Epoch 67/280\n",
            "42/42 - 6s - loss: 0.6412 - accuracy: 0.6489 - val_loss: 0.5388 - val_accuracy: 0.7306 - 6s/epoch - 154ms/step\n",
            "Epoch 68/280\n",
            "42/42 - 7s - loss: 0.6393 - accuracy: 0.6575 - val_loss: 0.5570 - val_accuracy: 0.7048 - 7s/epoch - 178ms/step\n",
            "Epoch 69/280\n",
            "42/42 - 7s - loss: 0.6349 - accuracy: 0.6696 - val_loss: 0.5436 - val_accuracy: 0.7113 - 7s/epoch - 174ms/step\n",
            "Epoch 70/280\n",
            "42/42 - 7s - loss: 0.6586 - accuracy: 0.6643 - val_loss: 0.5243 - val_accuracy: 0.7306 - 7s/epoch - 174ms/step\n",
            "Epoch 71/280\n",
            "42/42 - 7s - loss: 0.6147 - accuracy: 0.6753 - val_loss: 0.5164 - val_accuracy: 0.7355 - 7s/epoch - 172ms/step\n",
            "Epoch 72/280\n",
            "42/42 - 7s - loss: 0.5973 - accuracy: 0.6912 - val_loss: 0.5497 - val_accuracy: 0.7081 - 7s/epoch - 173ms/step\n",
            "Epoch 73/280\n",
            "42/42 - 6s - loss: 0.6196 - accuracy: 0.6854 - val_loss: 0.5280 - val_accuracy: 0.7258 - 6s/epoch - 148ms/step\n",
            "Epoch 74/280\n",
            "42/42 - 7s - loss: 0.6060 - accuracy: 0.6797 - val_loss: 0.5162 - val_accuracy: 0.7306 - 7s/epoch - 173ms/step\n",
            "Epoch 75/280\n",
            "42/42 - 6s - loss: 0.5901 - accuracy: 0.6975 - val_loss: 0.5274 - val_accuracy: 0.7226 - 6s/epoch - 148ms/step\n",
            "Epoch 76/280\n",
            "42/42 - 7s - loss: 0.5930 - accuracy: 0.6989 - val_loss: 0.5232 - val_accuracy: 0.7258 - 7s/epoch - 169ms/step\n",
            "Epoch 77/280\n",
            "42/42 - 7s - loss: 0.5964 - accuracy: 0.6902 - val_loss: 0.5102 - val_accuracy: 0.7306 - 7s/epoch - 174ms/step\n",
            "Epoch 78/280\n",
            "42/42 - 8s - loss: 0.6060 - accuracy: 0.6893 - val_loss: 0.5174 - val_accuracy: 0.7274 - 8s/epoch - 194ms/step\n",
            "Epoch 79/280\n",
            "42/42 - 7s - loss: 0.5798 - accuracy: 0.7037 - val_loss: 0.5019 - val_accuracy: 0.7403 - 7s/epoch - 172ms/step\n",
            "Epoch 80/280\n",
            "42/42 - 8s - loss: 0.5747 - accuracy: 0.7177 - val_loss: 0.4981 - val_accuracy: 0.7387 - 8s/epoch - 181ms/step\n",
            "Epoch 81/280\n",
            "42/42 - 7s - loss: 0.5611 - accuracy: 0.7191 - val_loss: 0.4931 - val_accuracy: 0.7419 - 7s/epoch - 171ms/step\n",
            "Epoch 82/280\n",
            "42/42 - 6s - loss: 0.5625 - accuracy: 0.7205 - val_loss: 0.5015 - val_accuracy: 0.7387 - 6s/epoch - 151ms/step\n",
            "Epoch 83/280\n",
            "42/42 - 7s - loss: 0.5654 - accuracy: 0.7162 - val_loss: 0.4988 - val_accuracy: 0.7387 - 7s/epoch - 176ms/step\n",
            "Epoch 84/280\n",
            "42/42 - 6s - loss: 0.5451 - accuracy: 0.7383 - val_loss: 0.4933 - val_accuracy: 0.7419 - 6s/epoch - 152ms/step\n",
            "Epoch 85/280\n",
            "42/42 - 7s - loss: 0.5573 - accuracy: 0.7306 - val_loss: 0.5002 - val_accuracy: 0.7355 - 7s/epoch - 171ms/step\n",
            "Epoch 86/280\n",
            "42/42 - 7s - loss: 0.5711 - accuracy: 0.7225 - val_loss: 0.5015 - val_accuracy: 0.7355 - 7s/epoch - 173ms/step\n",
            "Epoch 87/280\n",
            "42/42 - 7s - loss: 0.5346 - accuracy: 0.7388 - val_loss: 0.4932 - val_accuracy: 0.7419 - 7s/epoch - 169ms/step\n",
            "Epoch 88/280\n",
            "42/42 - 7s - loss: 0.5576 - accuracy: 0.7258 - val_loss: 0.4772 - val_accuracy: 0.7548 - 7s/epoch - 172ms/step\n",
            "Epoch 89/280\n",
            "42/42 - 8s - loss: 0.5437 - accuracy: 0.7340 - val_loss: 0.4898 - val_accuracy: 0.7468 - 8s/epoch - 191ms/step\n",
            "Epoch 90/280\n",
            "42/42 - 6s - loss: 0.5378 - accuracy: 0.7460 - val_loss: 0.4945 - val_accuracy: 0.7452 - 6s/epoch - 151ms/step\n",
            "Epoch 91/280\n",
            "42/42 - 7s - loss: 0.5372 - accuracy: 0.7350 - val_loss: 0.4974 - val_accuracy: 0.7339 - 7s/epoch - 167ms/step\n",
            "Epoch 92/280\n",
            "42/42 - 6s - loss: 0.5369 - accuracy: 0.7398 - val_loss: 0.4762 - val_accuracy: 0.7516 - 6s/epoch - 152ms/step\n",
            "Epoch 93/280\n",
            "42/42 - 7s - loss: 0.5183 - accuracy: 0.7581 - val_loss: 0.4756 - val_accuracy: 0.7532 - 7s/epoch - 165ms/step\n",
            "Epoch 94/280\n",
            "42/42 - 6s - loss: 0.5274 - accuracy: 0.7407 - val_loss: 0.4805 - val_accuracy: 0.7468 - 6s/epoch - 147ms/step\n",
            "Epoch 95/280\n",
            "42/42 - 8s - loss: 0.5105 - accuracy: 0.7566 - val_loss: 0.4703 - val_accuracy: 0.7484 - 8s/epoch - 191ms/step\n",
            "Epoch 96/280\n",
            "42/42 - 7s - loss: 0.5198 - accuracy: 0.7614 - val_loss: 0.4810 - val_accuracy: 0.7484 - 7s/epoch - 158ms/step\n",
            "Epoch 97/280\n",
            "42/42 - 7s - loss: 0.5289 - accuracy: 0.7504 - val_loss: 0.4743 - val_accuracy: 0.7484 - 7s/epoch - 157ms/step\n",
            "Epoch 98/280\n",
            "42/42 - 7s - loss: 0.4860 - accuracy: 0.7725 - val_loss: 0.4662 - val_accuracy: 0.7516 - 7s/epoch - 156ms/step\n",
            "Epoch 99/280\n",
            "42/42 - 8s - loss: 0.5154 - accuracy: 0.7576 - val_loss: 0.4661 - val_accuracy: 0.7500 - 8s/epoch - 183ms/step\n",
            "Epoch 100/280\n",
            "42/42 - 7s - loss: 0.4892 - accuracy: 0.7720 - val_loss: 0.4775 - val_accuracy: 0.7452 - 7s/epoch - 177ms/step\n",
            "Epoch 101/280\n",
            "42/42 - 7s - loss: 0.4936 - accuracy: 0.7691 - val_loss: 0.4790 - val_accuracy: 0.7484 - 7s/epoch - 170ms/step\n",
            "Epoch 102/280\n",
            "42/42 - 7s - loss: 0.5055 - accuracy: 0.7648 - val_loss: 0.4731 - val_accuracy: 0.7484 - 7s/epoch - 171ms/step\n",
            "Epoch 103/280\n",
            "42/42 - 7s - loss: 0.4935 - accuracy: 0.7763 - val_loss: 0.4625 - val_accuracy: 0.7532 - 7s/epoch - 170ms/step\n",
            "Epoch 104/280\n",
            "42/42 - 8s - loss: 0.4906 - accuracy: 0.7734 - val_loss: 0.4580 - val_accuracy: 0.7548 - 8s/epoch - 193ms/step\n",
            "Epoch 105/280\n",
            "42/42 - 7s - loss: 0.4888 - accuracy: 0.7691 - val_loss: 0.4616 - val_accuracy: 0.7581 - 7s/epoch - 171ms/step\n",
            "Epoch 106/280\n",
            "42/42 - 7s - loss: 0.4978 - accuracy: 0.7715 - val_loss: 0.4630 - val_accuracy: 0.7500 - 7s/epoch - 166ms/step\n",
            "Epoch 107/280\n",
            "42/42 - 7s - loss: 0.4898 - accuracy: 0.7754 - val_loss: 0.4592 - val_accuracy: 0.7565 - 7s/epoch - 171ms/step\n",
            "Epoch 108/280\n",
            "42/42 - 8s - loss: 0.4912 - accuracy: 0.7629 - val_loss: 0.4556 - val_accuracy: 0.7548 - 8s/epoch - 182ms/step\n",
            "Epoch 109/280\n",
            "42/42 - 7s - loss: 0.4946 - accuracy: 0.7691 - val_loss: 0.4556 - val_accuracy: 0.7581 - 7s/epoch - 174ms/step\n",
            "Epoch 110/280\n",
            "42/42 - 7s - loss: 0.4856 - accuracy: 0.7783 - val_loss: 0.4504 - val_accuracy: 0.7597 - 7s/epoch - 171ms/step\n",
            "Epoch 111/280\n",
            "42/42 - 7s - loss: 0.4741 - accuracy: 0.7821 - val_loss: 0.4475 - val_accuracy: 0.7629 - 7s/epoch - 170ms/step\n",
            "Epoch 112/280\n",
            "42/42 - 7s - loss: 0.4834 - accuracy: 0.7802 - val_loss: 0.4490 - val_accuracy: 0.7565 - 7s/epoch - 171ms/step\n",
            "Epoch 113/280\n",
            "42/42 - 7s - loss: 0.4737 - accuracy: 0.7802 - val_loss: 0.4392 - val_accuracy: 0.7694 - 7s/epoch - 172ms/step\n",
            "Epoch 114/280\n",
            "42/42 - 7s - loss: 0.4694 - accuracy: 0.7816 - val_loss: 0.4432 - val_accuracy: 0.7581 - 7s/epoch - 168ms/step\n",
            "Epoch 115/280\n",
            "42/42 - 7s - loss: 0.4520 - accuracy: 0.7946 - val_loss: 0.4498 - val_accuracy: 0.7597 - 7s/epoch - 170ms/step\n",
            "Epoch 116/280\n",
            "42/42 - 6s - loss: 0.4466 - accuracy: 0.7965 - val_loss: 0.4434 - val_accuracy: 0.7645 - 6s/epoch - 150ms/step\n",
            "Epoch 117/280\n",
            "42/42 - 8s - loss: 0.4752 - accuracy: 0.7797 - val_loss: 0.4479 - val_accuracy: 0.7629 - 8s/epoch - 195ms/step\n",
            "Epoch 118/280\n",
            "42/42 - 7s - loss: 0.4608 - accuracy: 0.7922 - val_loss: 0.4473 - val_accuracy: 0.7645 - 7s/epoch - 169ms/step\n",
            "Epoch 119/280\n",
            "42/42 - 8s - loss: 0.4366 - accuracy: 0.8038 - val_loss: 0.4466 - val_accuracy: 0.7694 - 8s/epoch - 180ms/step\n",
            "Epoch 120/280\n",
            "42/42 - 8s - loss: 0.4498 - accuracy: 0.7980 - val_loss: 0.4364 - val_accuracy: 0.7710 - 8s/epoch - 197ms/step\n",
            "Epoch 121/280\n",
            "42/42 - 6s - loss: 0.4610 - accuracy: 0.7821 - val_loss: 0.4347 - val_accuracy: 0.7726 - 6s/epoch - 144ms/step\n",
            "Epoch 122/280\n",
            "42/42 - 8s - loss: 0.4485 - accuracy: 0.7922 - val_loss: 0.4344 - val_accuracy: 0.7726 - 8s/epoch - 190ms/step\n",
            "Epoch 123/280\n",
            "42/42 - 6s - loss: 0.4456 - accuracy: 0.7965 - val_loss: 0.4378 - val_accuracy: 0.7726 - 6s/epoch - 148ms/step\n",
            "Epoch 124/280\n",
            "42/42 - 7s - loss: 0.4461 - accuracy: 0.7927 - val_loss: 0.4359 - val_accuracy: 0.7742 - 7s/epoch - 171ms/step\n",
            "Epoch 125/280\n",
            "42/42 - 6s - loss: 0.4519 - accuracy: 0.7917 - val_loss: 0.4504 - val_accuracy: 0.7581 - 6s/epoch - 148ms/step\n",
            "Epoch 126/280\n",
            "42/42 - 7s - loss: 0.4366 - accuracy: 0.8023 - val_loss: 0.4313 - val_accuracy: 0.7726 - 7s/epoch - 171ms/step\n",
            "Epoch 127/280\n",
            "42/42 - 7s - loss: 0.4366 - accuracy: 0.8047 - val_loss: 0.4455 - val_accuracy: 0.7645 - 7s/epoch - 173ms/step\n",
            "Epoch 128/280\n",
            "42/42 - 7s - loss: 0.4464 - accuracy: 0.7961 - val_loss: 0.4287 - val_accuracy: 0.7758 - 7s/epoch - 169ms/step\n",
            "Epoch 129/280\n",
            "42/42 - 6s - loss: 0.4195 - accuracy: 0.8100 - val_loss: 0.4236 - val_accuracy: 0.7758 - 6s/epoch - 148ms/step\n",
            "Epoch 130/280\n",
            "42/42 - 7s - loss: 0.4198 - accuracy: 0.8114 - val_loss: 0.4278 - val_accuracy: 0.7758 - 7s/epoch - 169ms/step\n",
            "Epoch 131/280\n",
            "42/42 - 7s - loss: 0.4270 - accuracy: 0.8158 - val_loss: 0.4166 - val_accuracy: 0.7774 - 7s/epoch - 169ms/step\n",
            "Epoch 132/280\n",
            "42/42 - 7s - loss: 0.4215 - accuracy: 0.8009 - val_loss: 0.4202 - val_accuracy: 0.7774 - 7s/epoch - 161ms/step\n",
            "Epoch 133/280\n",
            "42/42 - 7s - loss: 0.4191 - accuracy: 0.8139 - val_loss: 0.4180 - val_accuracy: 0.7855 - 7s/epoch - 172ms/step\n",
            "Epoch 134/280\n",
            "42/42 - 7s - loss: 0.4287 - accuracy: 0.8086 - val_loss: 0.4182 - val_accuracy: 0.7790 - 7s/epoch - 162ms/step\n",
            "Epoch 135/280\n",
            "42/42 - 7s - loss: 0.4059 - accuracy: 0.8191 - val_loss: 0.4409 - val_accuracy: 0.7661 - 7s/epoch - 169ms/step\n",
            "Epoch 136/280\n",
            "42/42 - 8s - loss: 0.4265 - accuracy: 0.8042 - val_loss: 0.4295 - val_accuracy: 0.7710 - 8s/epoch - 179ms/step\n",
            "Epoch 137/280\n",
            "42/42 - 7s - loss: 0.4291 - accuracy: 0.8004 - val_loss: 0.4110 - val_accuracy: 0.7887 - 7s/epoch - 171ms/step\n",
            "Epoch 138/280\n",
            "42/42 - 6s - loss: 0.4185 - accuracy: 0.8177 - val_loss: 0.4143 - val_accuracy: 0.7806 - 6s/epoch - 146ms/step\n",
            "Epoch 139/280\n",
            "42/42 - 8s - loss: 0.4096 - accuracy: 0.8172 - val_loss: 0.4455 - val_accuracy: 0.7629 - 8s/epoch - 183ms/step\n",
            "Epoch 140/280\n",
            "42/42 - 6s - loss: 0.4331 - accuracy: 0.8018 - val_loss: 0.4231 - val_accuracy: 0.7806 - 6s/epoch - 150ms/step\n",
            "Epoch 141/280\n",
            "42/42 - 7s - loss: 0.4220 - accuracy: 0.8114 - val_loss: 0.4282 - val_accuracy: 0.7726 - 7s/epoch - 172ms/step\n",
            "Epoch 142/280\n",
            "42/42 - 6s - loss: 0.4121 - accuracy: 0.8201 - val_loss: 0.4227 - val_accuracy: 0.7774 - 6s/epoch - 145ms/step\n",
            "Epoch 143/280\n",
            "42/42 - 7s - loss: 0.4021 - accuracy: 0.8167 - val_loss: 0.4180 - val_accuracy: 0.7774 - 7s/epoch - 172ms/step\n",
            "Epoch 144/280\n",
            "42/42 - 6s - loss: 0.4139 - accuracy: 0.8086 - val_loss: 0.4108 - val_accuracy: 0.7823 - 6s/epoch - 146ms/step\n",
            "Epoch 145/280\n",
            "42/42 - 7s - loss: 0.3927 - accuracy: 0.8331 - val_loss: 0.4052 - val_accuracy: 0.7871 - 7s/epoch - 171ms/step\n",
            "Epoch 146/280\n",
            "42/42 - 6s - loss: 0.3975 - accuracy: 0.8148 - val_loss: 0.4113 - val_accuracy: 0.7806 - 6s/epoch - 143ms/step\n",
            "Epoch 147/280\n",
            "42/42 - 7s - loss: 0.4131 - accuracy: 0.8143 - val_loss: 0.4014 - val_accuracy: 0.7871 - 7s/epoch - 169ms/step\n",
            "Epoch 148/280\n",
            "42/42 - 6s - loss: 0.3821 - accuracy: 0.8211 - val_loss: 0.4003 - val_accuracy: 0.7903 - 6s/epoch - 147ms/step\n",
            "Epoch 149/280\n",
            "42/42 - 7s - loss: 0.3905 - accuracy: 0.8235 - val_loss: 0.4009 - val_accuracy: 0.7839 - 7s/epoch - 166ms/step\n",
            "Epoch 150/280\n",
            "42/42 - 6s - loss: 0.3885 - accuracy: 0.8254 - val_loss: 0.3983 - val_accuracy: 0.7935 - 6s/epoch - 145ms/step\n",
            "Epoch 151/280\n",
            "42/42 - 7s - loss: 0.3985 - accuracy: 0.8163 - val_loss: 0.3947 - val_accuracy: 0.7855 - 7s/epoch - 167ms/step\n",
            "Epoch 152/280\n",
            "42/42 - 6s - loss: 0.3710 - accuracy: 0.8437 - val_loss: 0.4004 - val_accuracy: 0.7839 - 6s/epoch - 150ms/step\n",
            "Epoch 153/280\n",
            "42/42 - 8s - loss: 0.3878 - accuracy: 0.8278 - val_loss: 0.4013 - val_accuracy: 0.7855 - 8s/epoch - 186ms/step\n",
            "Epoch 154/280\n",
            "42/42 - 6s - loss: 0.3842 - accuracy: 0.8393 - val_loss: 0.4043 - val_accuracy: 0.7871 - 6s/epoch - 144ms/step\n",
            "Epoch 155/280\n",
            "42/42 - 8s - loss: 0.3748 - accuracy: 0.8316 - val_loss: 0.3899 - val_accuracy: 0.7935 - 8s/epoch - 191ms/step\n",
            "Epoch 156/280\n",
            "42/42 - 6s - loss: 0.3416 - accuracy: 0.8470 - val_loss: 0.3873 - val_accuracy: 0.7887 - 6s/epoch - 148ms/step\n",
            "Epoch 157/280\n",
            "42/42 - 7s - loss: 0.3651 - accuracy: 0.8456 - val_loss: 0.3921 - val_accuracy: 0.7839 - 7s/epoch - 172ms/step\n",
            "Epoch 158/280\n",
            "42/42 - 7s - loss: 0.3738 - accuracy: 0.8341 - val_loss: 0.3823 - val_accuracy: 0.7968 - 7s/epoch - 171ms/step\n",
            "Epoch 159/280\n",
            "42/42 - 7s - loss: 0.3706 - accuracy: 0.8393 - val_loss: 0.3899 - val_accuracy: 0.7903 - 7s/epoch - 165ms/step\n",
            "Epoch 160/280\n",
            "42/42 - 6s - loss: 0.3770 - accuracy: 0.8389 - val_loss: 0.3798 - val_accuracy: 0.8000 - 6s/epoch - 145ms/step\n",
            "Epoch 161/280\n",
            "42/42 - 7s - loss: 0.3491 - accuracy: 0.8442 - val_loss: 0.3856 - val_accuracy: 0.7919 - 7s/epoch - 168ms/step\n",
            "Epoch 162/280\n",
            "42/42 - 6s - loss: 0.3488 - accuracy: 0.8480 - val_loss: 0.3851 - val_accuracy: 0.7903 - 6s/epoch - 146ms/step\n",
            "Epoch 163/280\n",
            "42/42 - 8s - loss: 0.3614 - accuracy: 0.8475 - val_loss: 0.3819 - val_accuracy: 0.7968 - 8s/epoch - 192ms/step\n",
            "Epoch 164/280\n",
            "42/42 - 6s - loss: 0.3484 - accuracy: 0.8519 - val_loss: 0.3858 - val_accuracy: 0.7968 - 6s/epoch - 152ms/step\n",
            "Epoch 165/280\n",
            "42/42 - 8s - loss: 0.3575 - accuracy: 0.8519 - val_loss: 0.3818 - val_accuracy: 0.7968 - 8s/epoch - 185ms/step\n",
            "Epoch 166/280\n",
            "42/42 - 7s - loss: 0.3568 - accuracy: 0.8413 - val_loss: 0.3838 - val_accuracy: 0.7952 - 7s/epoch - 170ms/step\n",
            "Epoch 167/280\n",
            "42/42 - 6s - loss: 0.3576 - accuracy: 0.8475 - val_loss: 0.3820 - val_accuracy: 0.7952 - 6s/epoch - 149ms/step\n",
            "Epoch 168/280\n",
            "42/42 - 7s - loss: 0.3590 - accuracy: 0.8422 - val_loss: 0.3813 - val_accuracy: 0.7952 - 7s/epoch - 172ms/step\n",
            "Epoch 169/280\n",
            "42/42 - 6s - loss: 0.3558 - accuracy: 0.8437 - val_loss: 0.3764 - val_accuracy: 0.7984 - 6s/epoch - 145ms/step\n",
            "Epoch 170/280\n",
            "42/42 - 7s - loss: 0.3526 - accuracy: 0.8413 - val_loss: 0.3698 - val_accuracy: 0.8097 - 7s/epoch - 170ms/step\n",
            "Epoch 171/280\n",
            "42/42 - 6s - loss: 0.3452 - accuracy: 0.8509 - val_loss: 0.3660 - val_accuracy: 0.8065 - 6s/epoch - 147ms/step\n",
            "Epoch 172/280\n",
            "42/42 - 7s - loss: 0.3196 - accuracy: 0.8629 - val_loss: 0.3718 - val_accuracy: 0.8016 - 7s/epoch - 179ms/step\n",
            "Epoch 173/280\n",
            "42/42 - 7s - loss: 0.3317 - accuracy: 0.8528 - val_loss: 0.3662 - val_accuracy: 0.8048 - 7s/epoch - 169ms/step\n",
            "Epoch 174/280\n",
            "42/42 - 7s - loss: 0.3378 - accuracy: 0.8519 - val_loss: 0.3598 - val_accuracy: 0.8177 - 7s/epoch - 166ms/step\n",
            "Epoch 175/280\n",
            "42/42 - 6s - loss: 0.3265 - accuracy: 0.8519 - val_loss: 0.3584 - val_accuracy: 0.8145 - 6s/epoch - 144ms/step\n",
            "Epoch 176/280\n",
            "42/42 - 8s - loss: 0.3321 - accuracy: 0.8547 - val_loss: 0.3553 - val_accuracy: 0.8161 - 8s/epoch - 190ms/step\n",
            "Epoch 177/280\n",
            "42/42 - 7s - loss: 0.3270 - accuracy: 0.8576 - val_loss: 0.3512 - val_accuracy: 0.8177 - 7s/epoch - 169ms/step\n",
            "Epoch 178/280\n",
            "42/42 - 7s - loss: 0.3191 - accuracy: 0.8672 - val_loss: 0.3523 - val_accuracy: 0.8145 - 7s/epoch - 168ms/step\n",
            "Epoch 179/280\n",
            "42/42 - 7s - loss: 0.3267 - accuracy: 0.8672 - val_loss: 0.3458 - val_accuracy: 0.8210 - 7s/epoch - 172ms/step\n",
            "Epoch 180/280\n",
            "42/42 - 7s - loss: 0.3206 - accuracy: 0.8576 - val_loss: 0.3511 - val_accuracy: 0.8194 - 7s/epoch - 170ms/step\n",
            "Epoch 181/280\n",
            "42/42 - 7s - loss: 0.3130 - accuracy: 0.8653 - val_loss: 0.3488 - val_accuracy: 0.8210 - 7s/epoch - 171ms/step\n",
            "Epoch 182/280\n",
            "42/42 - 7s - loss: 0.3189 - accuracy: 0.8620 - val_loss: 0.3439 - val_accuracy: 0.8226 - 7s/epoch - 177ms/step\n",
            "Epoch 183/280\n",
            "42/42 - 7s - loss: 0.3135 - accuracy: 0.8687 - val_loss: 0.3466 - val_accuracy: 0.8177 - 7s/epoch - 175ms/step\n",
            "Epoch 184/280\n",
            "42/42 - 6s - loss: 0.3102 - accuracy: 0.8668 - val_loss: 0.3411 - val_accuracy: 0.8242 - 6s/epoch - 147ms/step\n",
            "Epoch 185/280\n",
            "42/42 - 7s - loss: 0.3171 - accuracy: 0.8571 - val_loss: 0.3394 - val_accuracy: 0.8323 - 7s/epoch - 178ms/step\n",
            "Epoch 186/280\n",
            "42/42 - 6s - loss: 0.3098 - accuracy: 0.8682 - val_loss: 0.3437 - val_accuracy: 0.8290 - 6s/epoch - 144ms/step\n",
            "Epoch 187/280\n",
            "42/42 - 8s - loss: 0.2996 - accuracy: 0.8783 - val_loss: 0.3378 - val_accuracy: 0.8290 - 8s/epoch - 181ms/step\n",
            "Epoch 188/280\n",
            "42/42 - 6s - loss: 0.3111 - accuracy: 0.8648 - val_loss: 0.3388 - val_accuracy: 0.8306 - 6s/epoch - 145ms/step\n",
            "Epoch 189/280\n",
            "42/42 - 8s - loss: 0.3031 - accuracy: 0.8730 - val_loss: 0.3424 - val_accuracy: 0.8258 - 8s/epoch - 188ms/step\n",
            "Epoch 190/280\n",
            "42/42 - 6s - loss: 0.2961 - accuracy: 0.8716 - val_loss: 0.3321 - val_accuracy: 0.8403 - 6s/epoch - 142ms/step\n",
            "Epoch 191/280\n",
            "42/42 - 8s - loss: 0.2897 - accuracy: 0.8865 - val_loss: 0.3358 - val_accuracy: 0.8306 - 8s/epoch - 192ms/step\n",
            "Epoch 192/280\n",
            "42/42 - 7s - loss: 0.2966 - accuracy: 0.8687 - val_loss: 0.3321 - val_accuracy: 0.8339 - 7s/epoch - 170ms/step\n",
            "Epoch 193/280\n",
            "42/42 - 7s - loss: 0.3144 - accuracy: 0.8634 - val_loss: 0.3327 - val_accuracy: 0.8339 - 7s/epoch - 167ms/step\n",
            "Epoch 194/280\n",
            "42/42 - 6s - loss: 0.2967 - accuracy: 0.8716 - val_loss: 0.3366 - val_accuracy: 0.8371 - 6s/epoch - 143ms/step\n",
            "Epoch 195/280\n",
            "42/42 - 7s - loss: 0.2983 - accuracy: 0.8730 - val_loss: 0.3307 - val_accuracy: 0.8323 - 7s/epoch - 168ms/step\n",
            "Epoch 196/280\n",
            "42/42 - 7s - loss: 0.2941 - accuracy: 0.8610 - val_loss: 0.3343 - val_accuracy: 0.8419 - 7s/epoch - 168ms/step\n",
            "Epoch 197/280\n",
            "42/42 - 8s - loss: 0.2806 - accuracy: 0.8797 - val_loss: 0.3321 - val_accuracy: 0.8371 - 8s/epoch - 192ms/step\n",
            "Epoch 198/280\n",
            "42/42 - 7s - loss: 0.2899 - accuracy: 0.8677 - val_loss: 0.3345 - val_accuracy: 0.8323 - 7s/epoch - 170ms/step\n",
            "Epoch 199/280\n",
            "42/42 - 6s - loss: 0.2775 - accuracy: 0.8831 - val_loss: 0.3280 - val_accuracy: 0.8403 - 6s/epoch - 152ms/step\n",
            "Epoch 200/280\n",
            "42/42 - 7s - loss: 0.2744 - accuracy: 0.8769 - val_loss: 0.3262 - val_accuracy: 0.8403 - 7s/epoch - 172ms/step\n",
            "Epoch 201/280\n",
            "42/42 - 7s - loss: 0.2848 - accuracy: 0.8822 - val_loss: 0.3233 - val_accuracy: 0.8452 - 7s/epoch - 173ms/step\n",
            "Epoch 202/280\n",
            "42/42 - 7s - loss: 0.2734 - accuracy: 0.8889 - val_loss: 0.3274 - val_accuracy: 0.8419 - 7s/epoch - 170ms/step\n",
            "Epoch 203/280\n",
            "42/42 - 6s - loss: 0.2899 - accuracy: 0.8721 - val_loss: 0.3228 - val_accuracy: 0.8339 - 6s/epoch - 149ms/step\n",
            "Epoch 204/280\n",
            "42/42 - 7s - loss: 0.2914 - accuracy: 0.8759 - val_loss: 0.3263 - val_accuracy: 0.8387 - 7s/epoch - 172ms/step\n",
            "Epoch 205/280\n",
            "42/42 - 7s - loss: 0.2636 - accuracy: 0.8850 - val_loss: 0.3287 - val_accuracy: 0.8419 - 7s/epoch - 171ms/step\n",
            "Epoch 206/280\n",
            "42/42 - 8s - loss: 0.2568 - accuracy: 0.8942 - val_loss: 0.3277 - val_accuracy: 0.8435 - 8s/epoch - 192ms/step\n",
            "Epoch 207/280\n",
            "42/42 - 7s - loss: 0.2717 - accuracy: 0.8855 - val_loss: 0.3195 - val_accuracy: 0.8484 - 7s/epoch - 170ms/step\n",
            "Epoch 208/280\n",
            "42/42 - 7s - loss: 0.2636 - accuracy: 0.8889 - val_loss: 0.3252 - val_accuracy: 0.8403 - 7s/epoch - 169ms/step\n",
            "Epoch 209/280\n",
            "42/42 - 7s - loss: 0.2605 - accuracy: 0.8855 - val_loss: 0.3227 - val_accuracy: 0.8403 - 7s/epoch - 169ms/step\n",
            "Epoch 210/280\n",
            "42/42 - 8s - loss: 0.2660 - accuracy: 0.8942 - val_loss: 0.3251 - val_accuracy: 0.8419 - 8s/epoch - 180ms/step\n",
            "Epoch 211/280\n",
            "42/42 - 8s - loss: 0.2671 - accuracy: 0.8865 - val_loss: 0.3180 - val_accuracy: 0.8387 - 8s/epoch - 180ms/step\n",
            "Epoch 212/280\n",
            "42/42 - 7s - loss: 0.2581 - accuracy: 0.8947 - val_loss: 0.3152 - val_accuracy: 0.8532 - 7s/epoch - 172ms/step\n",
            "Epoch 213/280\n",
            "42/42 - 7s - loss: 0.2610 - accuracy: 0.8913 - val_loss: 0.3170 - val_accuracy: 0.8435 - 7s/epoch - 171ms/step\n",
            "Epoch 214/280\n",
            "42/42 - 6s - loss: 0.2500 - accuracy: 0.8975 - val_loss: 0.3241 - val_accuracy: 0.8468 - 6s/epoch - 144ms/step\n",
            "Epoch 215/280\n",
            "42/42 - 7s - loss: 0.2525 - accuracy: 0.8966 - val_loss: 0.3169 - val_accuracy: 0.8516 - 7s/epoch - 166ms/step\n",
            "Epoch 216/280\n",
            "42/42 - 7s - loss: 0.2519 - accuracy: 0.8908 - val_loss: 0.3158 - val_accuracy: 0.8516 - 7s/epoch - 168ms/step\n",
            "Epoch 217/280\n",
            "42/42 - 7s - loss: 0.2477 - accuracy: 0.8937 - val_loss: 0.3254 - val_accuracy: 0.8403 - 7s/epoch - 169ms/step\n",
            "Epoch 218/280\n",
            "42/42 - 6s - loss: 0.2514 - accuracy: 0.8927 - val_loss: 0.3130 - val_accuracy: 0.8548 - 6s/epoch - 147ms/step\n",
            "Epoch 219/280\n",
            "42/42 - 7s - loss: 0.2415 - accuracy: 0.9009 - val_loss: 0.3183 - val_accuracy: 0.8500 - 7s/epoch - 166ms/step\n",
            "Epoch 220/280\n",
            "42/42 - 6s - loss: 0.2415 - accuracy: 0.9009 - val_loss: 0.3145 - val_accuracy: 0.8532 - 6s/epoch - 146ms/step\n",
            "Epoch 221/280\n",
            "42/42 - 7s - loss: 0.2426 - accuracy: 0.9057 - val_loss: 0.3153 - val_accuracy: 0.8548 - 7s/epoch - 169ms/step\n",
            "Epoch 222/280\n",
            "42/42 - 6s - loss: 0.2376 - accuracy: 0.9024 - val_loss: 0.3128 - val_accuracy: 0.8565 - 6s/epoch - 146ms/step\n",
            "Epoch 223/280\n",
            "42/42 - 7s - loss: 0.2379 - accuracy: 0.9028 - val_loss: 0.3106 - val_accuracy: 0.8565 - 7s/epoch - 167ms/step\n",
            "Epoch 224/280\n",
            "42/42 - 6s - loss: 0.2402 - accuracy: 0.8923 - val_loss: 0.3134 - val_accuracy: 0.8500 - 6s/epoch - 147ms/step\n",
            "Epoch 225/280\n",
            "42/42 - 7s - loss: 0.2414 - accuracy: 0.8985 - val_loss: 0.3076 - val_accuracy: 0.8629 - 7s/epoch - 169ms/step\n",
            "Epoch 226/280\n",
            "42/42 - 6s - loss: 0.2442 - accuracy: 0.8980 - val_loss: 0.3105 - val_accuracy: 0.8532 - 6s/epoch - 148ms/step\n",
            "Epoch 227/280\n",
            "42/42 - 7s - loss: 0.2334 - accuracy: 0.9052 - val_loss: 0.3149 - val_accuracy: 0.8565 - 7s/epoch - 170ms/step\n",
            "Epoch 228/280\n",
            "42/42 - 7s - loss: 0.2278 - accuracy: 0.9091 - val_loss: 0.3071 - val_accuracy: 0.8629 - 7s/epoch - 171ms/step\n",
            "Epoch 229/280\n",
            "42/42 - 8s - loss: 0.2218 - accuracy: 0.9101 - val_loss: 0.3085 - val_accuracy: 0.8548 - 8s/epoch - 192ms/step\n",
            "Epoch 230/280\n",
            "42/42 - 7s - loss: 0.2231 - accuracy: 0.9110 - val_loss: 0.3124 - val_accuracy: 0.8548 - 7s/epoch - 170ms/step\n",
            "Epoch 231/280\n",
            "42/42 - 7s - loss: 0.2309 - accuracy: 0.9014 - val_loss: 0.3061 - val_accuracy: 0.8629 - 7s/epoch - 156ms/step\n",
            "Epoch 232/280\n",
            "42/42 - 7s - loss: 0.2378 - accuracy: 0.8985 - val_loss: 0.3121 - val_accuracy: 0.8613 - 7s/epoch - 157ms/step\n",
            "Epoch 233/280\n",
            "42/42 - 8s - loss: 0.2208 - accuracy: 0.9105 - val_loss: 0.3069 - val_accuracy: 0.8677 - 8s/epoch - 182ms/step\n",
            "Epoch 234/280\n",
            "42/42 - 7s - loss: 0.2256 - accuracy: 0.9067 - val_loss: 0.3072 - val_accuracy: 0.8613 - 7s/epoch - 171ms/step\n",
            "Epoch 235/280\n",
            "42/42 - 7s - loss: 0.2192 - accuracy: 0.9086 - val_loss: 0.3091 - val_accuracy: 0.8532 - 7s/epoch - 172ms/step\n",
            "Epoch 236/280\n",
            "42/42 - 7s - loss: 0.2135 - accuracy: 0.9192 - val_loss: 0.3112 - val_accuracy: 0.8548 - 7s/epoch - 172ms/step\n",
            "Epoch 237/280\n",
            "42/42 - 6s - loss: 0.2050 - accuracy: 0.9173 - val_loss: 0.3071 - val_accuracy: 0.8565 - 6s/epoch - 144ms/step\n",
            "Epoch 238/280\n",
            "42/42 - 8s - loss: 0.2075 - accuracy: 0.9120 - val_loss: 0.3008 - val_accuracy: 0.8694 - 8s/epoch - 184ms/step\n",
            "Epoch 239/280\n",
            "42/42 - 6s - loss: 0.2176 - accuracy: 0.9091 - val_loss: 0.3107 - val_accuracy: 0.8613 - 6s/epoch - 144ms/step\n",
            "Epoch 240/280\n",
            "42/42 - 8s - loss: 0.2114 - accuracy: 0.9149 - val_loss: 0.3075 - val_accuracy: 0.8548 - 8s/epoch - 193ms/step\n",
            "Epoch 241/280\n",
            "42/42 - 6s - loss: 0.2121 - accuracy: 0.9105 - val_loss: 0.3067 - val_accuracy: 0.8581 - 6s/epoch - 146ms/step\n",
            "Epoch 242/280\n",
            "42/42 - 7s - loss: 0.2054 - accuracy: 0.9197 - val_loss: 0.3010 - val_accuracy: 0.8645 - 7s/epoch - 168ms/step\n",
            "Epoch 243/280\n",
            "42/42 - 6s - loss: 0.2185 - accuracy: 0.9057 - val_loss: 0.3019 - val_accuracy: 0.8710 - 6s/epoch - 146ms/step\n",
            "Epoch 244/280\n",
            "42/42 - 8s - loss: 0.2193 - accuracy: 0.9129 - val_loss: 0.2976 - val_accuracy: 0.8710 - 8s/epoch - 192ms/step\n",
            "Epoch 245/280\n",
            "42/42 - 6s - loss: 0.2146 - accuracy: 0.9144 - val_loss: 0.3024 - val_accuracy: 0.8629 - 6s/epoch - 144ms/step\n",
            "Epoch 246/280\n",
            "42/42 - 8s - loss: 0.2077 - accuracy: 0.9129 - val_loss: 0.3102 - val_accuracy: 0.8597 - 8s/epoch - 192ms/step\n",
            "Epoch 247/280\n",
            "42/42 - 7s - loss: 0.2026 - accuracy: 0.9125 - val_loss: 0.3070 - val_accuracy: 0.8581 - 7s/epoch - 170ms/step\n",
            "Epoch 248/280\n",
            "42/42 - 7s - loss: 0.1922 - accuracy: 0.9240 - val_loss: 0.2983 - val_accuracy: 0.8742 - 7s/epoch - 159ms/step\n",
            "Epoch 249/280\n",
            "42/42 - 7s - loss: 0.2027 - accuracy: 0.9230 - val_loss: 0.3030 - val_accuracy: 0.8645 - 7s/epoch - 171ms/step\n",
            "Epoch 250/280\n",
            "42/42 - 6s - loss: 0.2003 - accuracy: 0.9264 - val_loss: 0.2973 - val_accuracy: 0.8742 - 6s/epoch - 149ms/step\n",
            "Epoch 251/280\n",
            "42/42 - 7s - loss: 0.1888 - accuracy: 0.9245 - val_loss: 0.3046 - val_accuracy: 0.8629 - 7s/epoch - 171ms/step\n",
            "Epoch 252/280\n",
            "42/42 - 7s - loss: 0.1984 - accuracy: 0.9288 - val_loss: 0.2994 - val_accuracy: 0.8774 - 7s/epoch - 171ms/step\n",
            "Epoch 253/280\n",
            "42/42 - 8s - loss: 0.1944 - accuracy: 0.9269 - val_loss: 0.2948 - val_accuracy: 0.8726 - 8s/epoch - 186ms/step\n",
            "Epoch 254/280\n",
            "42/42 - 7s - loss: 0.1960 - accuracy: 0.9173 - val_loss: 0.2974 - val_accuracy: 0.8742 - 7s/epoch - 167ms/step\n",
            "Epoch 255/280\n",
            "42/42 - 8s - loss: 0.1894 - accuracy: 0.9245 - val_loss: 0.2971 - val_accuracy: 0.8694 - 8s/epoch - 191ms/step\n",
            "Epoch 256/280\n",
            "42/42 - 7s - loss: 0.1959 - accuracy: 0.9168 - val_loss: 0.2937 - val_accuracy: 0.8790 - 7s/epoch - 170ms/step\n",
            "Epoch 257/280\n",
            "42/42 - 7s - loss: 0.1988 - accuracy: 0.9226 - val_loss: 0.2907 - val_accuracy: 0.8806 - 7s/epoch - 165ms/step\n",
            "Epoch 258/280\n",
            "42/42 - 7s - loss: 0.1826 - accuracy: 0.9293 - val_loss: 0.2924 - val_accuracy: 0.8774 - 7s/epoch - 168ms/step\n",
            "Epoch 259/280\n",
            "42/42 - 7s - loss: 0.1829 - accuracy: 0.9235 - val_loss: 0.2926 - val_accuracy: 0.8758 - 7s/epoch - 178ms/step\n",
            "Epoch 260/280\n",
            "42/42 - 7s - loss: 0.1855 - accuracy: 0.9303 - val_loss: 0.2889 - val_accuracy: 0.8790 - 7s/epoch - 173ms/step\n",
            "Epoch 261/280\n",
            "42/42 - 6s - loss: 0.1968 - accuracy: 0.9235 - val_loss: 0.2878 - val_accuracy: 0.8774 - 6s/epoch - 143ms/step\n",
            "Epoch 262/280\n",
            "42/42 - 7s - loss: 0.1905 - accuracy: 0.9240 - val_loss: 0.2947 - val_accuracy: 0.8742 - 7s/epoch - 168ms/step\n",
            "Epoch 263/280\n",
            "42/42 - 6s - loss: 0.1775 - accuracy: 0.9298 - val_loss: 0.2886 - val_accuracy: 0.8677 - 6s/epoch - 145ms/step\n",
            "Epoch 264/280\n",
            "42/42 - 7s - loss: 0.1662 - accuracy: 0.9384 - val_loss: 0.2963 - val_accuracy: 0.8677 - 7s/epoch - 176ms/step\n",
            "Epoch 265/280\n",
            "42/42 - 6s - loss: 0.1800 - accuracy: 0.9303 - val_loss: 0.2859 - val_accuracy: 0.8742 - 6s/epoch - 147ms/step\n",
            "Epoch 266/280\n",
            "42/42 - 8s - loss: 0.1774 - accuracy: 0.9312 - val_loss: 0.2892 - val_accuracy: 0.8694 - 8s/epoch - 180ms/step\n",
            "Epoch 267/280\n",
            "42/42 - 6s - loss: 0.1803 - accuracy: 0.9274 - val_loss: 0.2831 - val_accuracy: 0.8823 - 6s/epoch - 144ms/step\n",
            "Epoch 268/280\n",
            "42/42 - 8s - loss: 0.1811 - accuracy: 0.9216 - val_loss: 0.2860 - val_accuracy: 0.8806 - 8s/epoch - 184ms/step\n",
            "Epoch 269/280\n",
            "42/42 - 6s - loss: 0.1759 - accuracy: 0.9298 - val_loss: 0.2997 - val_accuracy: 0.8694 - 6s/epoch - 147ms/step\n",
            "Epoch 270/280\n",
            "42/42 - 7s - loss: 0.1677 - accuracy: 0.9370 - val_loss: 0.2879 - val_accuracy: 0.8742 - 7s/epoch - 167ms/step\n",
            "Epoch 271/280\n",
            "42/42 - 6s - loss: 0.1746 - accuracy: 0.9336 - val_loss: 0.2834 - val_accuracy: 0.8806 - 6s/epoch - 144ms/step\n",
            "Epoch 272/280\n",
            "42/42 - 8s - loss: 0.1643 - accuracy: 0.9322 - val_loss: 0.2852 - val_accuracy: 0.8790 - 8s/epoch - 188ms/step\n",
            "Epoch 273/280\n",
            "42/42 - 6s - loss: 0.1717 - accuracy: 0.9312 - val_loss: 0.2817 - val_accuracy: 0.8839 - 6s/epoch - 151ms/step\n",
            "Epoch 274/280\n",
            "42/42 - 8s - loss: 0.1680 - accuracy: 0.9341 - val_loss: 0.2813 - val_accuracy: 0.8871 - 8s/epoch - 190ms/step\n",
            "Epoch 275/280\n",
            "42/42 - 6s - loss: 0.1614 - accuracy: 0.9341 - val_loss: 0.3052 - val_accuracy: 0.8629 - 6s/epoch - 144ms/step\n",
            "Epoch 276/280\n",
            "42/42 - 8s - loss: 0.1479 - accuracy: 0.9466 - val_loss: 0.2893 - val_accuracy: 0.8726 - 8s/epoch - 193ms/step\n",
            "Epoch 277/280\n",
            "42/42 - 6s - loss: 0.1552 - accuracy: 0.9428 - val_loss: 0.2863 - val_accuracy: 0.8726 - 6s/epoch - 145ms/step\n",
            "Epoch 278/280\n",
            "42/42 - 8s - loss: 0.1588 - accuracy: 0.9389 - val_loss: 0.2776 - val_accuracy: 0.8823 - 8s/epoch - 191ms/step\n",
            "Epoch 279/280\n",
            "42/42 - 7s - loss: 0.1614 - accuracy: 0.9351 - val_loss: 0.2804 - val_accuracy: 0.8968 - 7s/epoch - 169ms/step\n",
            "Epoch 280/280\n",
            "42/42 - 7s - loss: 0.1650 - accuracy: 0.9303 - val_loss: 0.2833 - val_accuracy: 0.8855 - 7s/epoch - 157ms/step\n",
            "Training end\n",
            "Testing start\n",
            "Testing end\n",
            "Model saved\n",
            "True Positive, False Positive, False negative, Second of Inter in Test, Sensitivity, FPR\n",
            "46,0,7,10500,0.8679245283018868,0.0\n",
            "SEIZURE OUT: 4\n",
            "Training start\n",
            "Epoch 1/280\n",
            "42/42 - 12s - loss: 0.9986 - accuracy: 0.4377 - val_loss: 0.5174 - val_accuracy: 0.8487 - 12s/epoch - 287ms/step\n",
            "Epoch 2/280\n",
            "42/42 - 12s - loss: 0.8755 - accuracy: 0.4956 - val_loss: 0.5657 - val_accuracy: 0.8487 - 12s/epoch - 295ms/step\n",
            "Epoch 3/280\n",
            "42/42 - 16s - loss: 0.8329 - accuracy: 0.5186 - val_loss: 0.6197 - val_accuracy: 0.8487 - 16s/epoch - 375ms/step\n",
            "Epoch 4/280\n",
            "42/42 - 13s - loss: 0.8353 - accuracy: 0.5319 - val_loss: 0.6815 - val_accuracy: 0.8457 - 13s/epoch - 312ms/step\n",
            "Epoch 5/280\n",
            "42/42 - 9s - loss: 0.8331 - accuracy: 0.5324 - val_loss: 0.7453 - val_accuracy: 0.1513 - 9s/epoch - 220ms/step\n",
            "Epoch 6/280\n",
            "42/42 - 7s - loss: 0.8264 - accuracy: 0.5412 - val_loss: 0.8036 - val_accuracy: 0.1513 - 7s/epoch - 163ms/step\n",
            "Epoch 7/280\n",
            "42/42 - 7s - loss: 0.8332 - accuracy: 0.5442 - val_loss: 0.8599 - val_accuracy: 0.1513 - 7s/epoch - 173ms/step\n",
            "Epoch 8/280\n",
            "42/42 - 7s - loss: 0.8333 - accuracy: 0.5334 - val_loss: 0.9138 - val_accuracy: 0.1513 - 7s/epoch - 176ms/step\n",
            "Epoch 9/280\n",
            "42/42 - 7s - loss: 0.8414 - accuracy: 0.5363 - val_loss: 0.9606 - val_accuracy: 0.1513 - 7s/epoch - 174ms/step\n",
            "Epoch 10/280\n",
            "42/42 - 7s - loss: 0.8309 - accuracy: 0.5304 - val_loss: 1.0133 - val_accuracy: 0.1513 - 7s/epoch - 172ms/step\n",
            "Epoch 11/280\n",
            "42/42 - 7s - loss: 0.8063 - accuracy: 0.5491 - val_loss: 1.0358 - val_accuracy: 0.1513 - 7s/epoch - 175ms/step\n",
            "Epoch 12/280\n",
            "42/42 - 7s - loss: 0.8009 - accuracy: 0.5437 - val_loss: 1.0475 - val_accuracy: 0.1513 - 7s/epoch - 177ms/step\n",
            "Epoch 13/280\n",
            "42/42 - 8s - loss: 0.8388 - accuracy: 0.5368 - val_loss: 1.0570 - val_accuracy: 0.1513 - 8s/epoch - 195ms/step\n",
            "Epoch 14/280\n",
            "42/42 - 7s - loss: 0.7983 - accuracy: 0.5554 - val_loss: 1.0510 - val_accuracy: 0.1513 - 7s/epoch - 174ms/step\n",
            "Epoch 15/280\n",
            "42/42 - 7s - loss: 0.8189 - accuracy: 0.5309 - val_loss: 1.0527 - val_accuracy: 0.1513 - 7s/epoch - 164ms/step\n",
            "Epoch 16/280\n",
            "42/42 - 7s - loss: 0.8045 - accuracy: 0.5447 - val_loss: 1.0344 - val_accuracy: 0.1513 - 7s/epoch - 176ms/step\n",
            "Epoch 17/280\n",
            "42/42 - 7s - loss: 0.7969 - accuracy: 0.5604 - val_loss: 1.0136 - val_accuracy: 0.1513 - 7s/epoch - 173ms/step\n",
            "Epoch 18/280\n",
            "42/42 - 7s - loss: 0.8100 - accuracy: 0.5481 - val_loss: 1.0127 - val_accuracy: 0.1513 - 7s/epoch - 175ms/step\n",
            "Epoch 19/280\n",
            "42/42 - 6s - loss: 0.8217 - accuracy: 0.5294 - val_loss: 1.0733 - val_accuracy: 0.1513 - 6s/epoch - 152ms/step\n",
            "Epoch 20/280\n",
            "42/42 - 8s - loss: 0.8146 - accuracy: 0.5564 - val_loss: 1.0686 - val_accuracy: 0.1513 - 8s/epoch - 192ms/step\n",
            "Epoch 21/280\n",
            "42/42 - 6s - loss: 0.7906 - accuracy: 0.5721 - val_loss: 1.0480 - val_accuracy: 0.1513 - 6s/epoch - 152ms/step\n",
            "Epoch 22/280\n",
            "42/42 - 8s - loss: 0.8244 - accuracy: 0.5437 - val_loss: 1.0165 - val_accuracy: 0.1513 - 8s/epoch - 195ms/step\n",
            "Epoch 23/280\n",
            "42/42 - 7s - loss: 0.8169 - accuracy: 0.5491 - val_loss: 1.0299 - val_accuracy: 0.1513 - 7s/epoch - 171ms/step\n",
            "Epoch 24/280\n",
            "42/42 - 8s - loss: 0.7962 - accuracy: 0.5486 - val_loss: 1.0232 - val_accuracy: 0.1513 - 8s/epoch - 185ms/step\n",
            "Epoch 25/280\n",
            "42/42 - 7s - loss: 0.8088 - accuracy: 0.5505 - val_loss: 1.0199 - val_accuracy: 0.1513 - 7s/epoch - 175ms/step\n",
            "Epoch 26/280\n",
            "42/42 - 6s - loss: 0.7918 - accuracy: 0.5584 - val_loss: 1.0359 - val_accuracy: 0.1513 - 6s/epoch - 152ms/step\n",
            "Epoch 27/280\n",
            "42/42 - 8s - loss: 0.8050 - accuracy: 0.5393 - val_loss: 1.0325 - val_accuracy: 0.1513 - 8s/epoch - 180ms/step\n",
            "Epoch 28/280\n",
            "42/42 - 6s - loss: 0.7868 - accuracy: 0.5559 - val_loss: 1.0157 - val_accuracy: 0.1513 - 6s/epoch - 150ms/step\n",
            "Epoch 29/280\n",
            "42/42 - 7s - loss: 0.7752 - accuracy: 0.5613 - val_loss: 1.0165 - val_accuracy: 0.1513 - 7s/epoch - 174ms/step\n",
            "Epoch 30/280\n",
            "42/42 - 7s - loss: 0.7915 - accuracy: 0.5407 - val_loss: 1.0005 - val_accuracy: 0.1513 - 7s/epoch - 171ms/step\n",
            "Epoch 31/280\n",
            "42/42 - 8s - loss: 0.7835 - accuracy: 0.5682 - val_loss: 0.9822 - val_accuracy: 0.1513 - 8s/epoch - 192ms/step\n",
            "Epoch 32/280\n",
            "42/42 - 7s - loss: 0.7729 - accuracy: 0.5638 - val_loss: 1.0225 - val_accuracy: 0.1513 - 7s/epoch - 171ms/step\n",
            "Epoch 33/280\n",
            "42/42 - 8s - loss: 0.7789 - accuracy: 0.5638 - val_loss: 0.9795 - val_accuracy: 0.1513 - 8s/epoch - 192ms/step\n",
            "Epoch 34/280\n",
            "42/42 - 7s - loss: 0.7855 - accuracy: 0.5623 - val_loss: 0.9728 - val_accuracy: 0.1513 - 7s/epoch - 171ms/step\n",
            "Epoch 35/280\n",
            "42/42 - 7s - loss: 0.7743 - accuracy: 0.5707 - val_loss: 0.9620 - val_accuracy: 0.1513 - 7s/epoch - 177ms/step\n",
            "Epoch 36/280\n",
            "42/42 - 8s - loss: 0.7925 - accuracy: 0.5466 - val_loss: 1.0040 - val_accuracy: 0.1513 - 8s/epoch - 183ms/step\n",
            "Epoch 37/280\n",
            "42/42 - 6s - loss: 0.7818 - accuracy: 0.5653 - val_loss: 0.9864 - val_accuracy: 0.1513 - 6s/epoch - 152ms/step\n",
            "Epoch 38/280\n",
            "42/42 - 8s - loss: 0.7717 - accuracy: 0.5677 - val_loss: 0.9400 - val_accuracy: 0.1573 - 8s/epoch - 191ms/step\n",
            "Epoch 39/280\n",
            "42/42 - 7s - loss: 0.7988 - accuracy: 0.5368 - val_loss: 0.9510 - val_accuracy: 0.1589 - 7s/epoch - 172ms/step\n",
            "Epoch 40/280\n",
            "42/42 - 7s - loss: 0.7699 - accuracy: 0.5648 - val_loss: 0.9451 - val_accuracy: 0.1604 - 7s/epoch - 173ms/step\n",
            "Epoch 41/280\n",
            "42/42 - 6s - loss: 0.7835 - accuracy: 0.5554 - val_loss: 0.9737 - val_accuracy: 0.1573 - 6s/epoch - 152ms/step\n",
            "Epoch 42/280\n",
            "42/42 - 8s - loss: 0.7331 - accuracy: 0.5878 - val_loss: 0.9304 - val_accuracy: 0.1664 - 8s/epoch - 195ms/step\n",
            "Epoch 43/280\n",
            "42/42 - 7s - loss: 0.7861 - accuracy: 0.5520 - val_loss: 0.9610 - val_accuracy: 0.1634 - 7s/epoch - 171ms/step\n",
            "Epoch 44/280\n",
            "42/42 - 7s - loss: 0.7617 - accuracy: 0.5579 - val_loss: 0.9388 - val_accuracy: 0.1694 - 7s/epoch - 160ms/step\n",
            "Epoch 45/280\n",
            "42/42 - 8s - loss: 0.7599 - accuracy: 0.5697 - val_loss: 0.9377 - val_accuracy: 0.1740 - 8s/epoch - 181ms/step\n",
            "Epoch 46/280\n",
            "42/42 - 7s - loss: 0.7657 - accuracy: 0.5761 - val_loss: 0.9759 - val_accuracy: 0.1679 - 7s/epoch - 172ms/step\n",
            "Epoch 47/280\n",
            "42/42 - 7s - loss: 0.7714 - accuracy: 0.5658 - val_loss: 0.9717 - val_accuracy: 0.1740 - 7s/epoch - 176ms/step\n",
            "Epoch 48/280\n",
            "42/42 - 6s - loss: 0.7397 - accuracy: 0.5957 - val_loss: 0.9509 - val_accuracy: 0.1831 - 6s/epoch - 153ms/step\n",
            "Epoch 49/280\n",
            "42/42 - 7s - loss: 0.7422 - accuracy: 0.5913 - val_loss: 0.8965 - val_accuracy: 0.2300 - 7s/epoch - 175ms/step\n",
            "Epoch 50/280\n",
            "42/42 - 7s - loss: 0.7472 - accuracy: 0.5741 - val_loss: 0.9124 - val_accuracy: 0.2224 - 7s/epoch - 173ms/step\n",
            "Epoch 51/280\n",
            "42/42 - 7s - loss: 0.7571 - accuracy: 0.5731 - val_loss: 0.9146 - val_accuracy: 0.2239 - 7s/epoch - 175ms/step\n",
            "Epoch 52/280\n",
            "42/42 - 6s - loss: 0.7618 - accuracy: 0.5785 - val_loss: 0.9301 - val_accuracy: 0.2224 - 6s/epoch - 152ms/step\n",
            "Epoch 53/280\n",
            "42/42 - 7s - loss: 0.7546 - accuracy: 0.5795 - val_loss: 0.8905 - val_accuracy: 0.2481 - 7s/epoch - 175ms/step\n",
            "Epoch 54/280\n",
            "42/42 - 6s - loss: 0.7649 - accuracy: 0.5824 - val_loss: 0.9359 - val_accuracy: 0.2284 - 6s/epoch - 154ms/step\n",
            "Epoch 55/280\n",
            "42/42 - 8s - loss: 0.7510 - accuracy: 0.5756 - val_loss: 0.9094 - val_accuracy: 0.2466 - 8s/epoch - 190ms/step\n",
            "Epoch 56/280\n",
            "42/42 - 7s - loss: 0.7496 - accuracy: 0.5800 - val_loss: 0.9165 - val_accuracy: 0.2526 - 7s/epoch - 175ms/step\n",
            "Epoch 57/280\n",
            "42/42 - 6s - loss: 0.7393 - accuracy: 0.5918 - val_loss: 0.9128 - val_accuracy: 0.2602 - 6s/epoch - 154ms/step\n",
            "Epoch 58/280\n",
            "42/42 - 7s - loss: 0.7602 - accuracy: 0.5741 - val_loss: 0.9310 - val_accuracy: 0.2526 - 7s/epoch - 177ms/step\n",
            "Epoch 59/280\n",
            "42/42 - 7s - loss: 0.7545 - accuracy: 0.5893 - val_loss: 0.8916 - val_accuracy: 0.3056 - 7s/epoch - 172ms/step\n",
            "Epoch 60/280\n",
            "42/42 - 7s - loss: 0.7413 - accuracy: 0.5893 - val_loss: 0.9462 - val_accuracy: 0.2526 - 7s/epoch - 174ms/step\n",
            "Epoch 61/280\n",
            "42/42 - 6s - loss: 0.7190 - accuracy: 0.6016 - val_loss: 0.8975 - val_accuracy: 0.3101 - 6s/epoch - 153ms/step\n",
            "Epoch 62/280\n",
            "42/42 - 8s - loss: 0.7198 - accuracy: 0.6035 - val_loss: 0.9119 - val_accuracy: 0.3026 - 8s/epoch - 193ms/step\n",
            "Epoch 63/280\n",
            "42/42 - 7s - loss: 0.7459 - accuracy: 0.5986 - val_loss: 0.8982 - val_accuracy: 0.3238 - 7s/epoch - 171ms/step\n",
            "Epoch 64/280\n",
            "42/42 - 8s - loss: 0.7138 - accuracy: 0.6030 - val_loss: 0.8939 - val_accuracy: 0.3283 - 8s/epoch - 192ms/step\n",
            "Epoch 65/280\n",
            "42/42 - 7s - loss: 0.7450 - accuracy: 0.5918 - val_loss: 0.8819 - val_accuracy: 0.3480 - 7s/epoch - 171ms/step\n",
            "Epoch 66/280\n",
            "42/42 - 7s - loss: 0.7399 - accuracy: 0.5829 - val_loss: 0.8950 - val_accuracy: 0.3464 - 7s/epoch - 156ms/step\n",
            "Epoch 67/280\n",
            "42/42 - 7s - loss: 0.7275 - accuracy: 0.5967 - val_loss: 0.9225 - val_accuracy: 0.3177 - 7s/epoch - 175ms/step\n",
            "Epoch 68/280\n",
            "42/42 - 7s - loss: 0.6987 - accuracy: 0.6183 - val_loss: 0.8720 - val_accuracy: 0.3767 - 7s/epoch - 174ms/step\n",
            "Epoch 69/280\n",
            "42/42 - 8s - loss: 0.7189 - accuracy: 0.6016 - val_loss: 0.8631 - val_accuracy: 0.3843 - 8s/epoch - 188ms/step\n",
            "Epoch 70/280\n",
            "42/42 - 6s - loss: 0.7377 - accuracy: 0.5824 - val_loss: 0.8757 - val_accuracy: 0.3843 - 6s/epoch - 149ms/step\n",
            "Epoch 71/280\n",
            "42/42 - 7s - loss: 0.7306 - accuracy: 0.5937 - val_loss: 0.9074 - val_accuracy: 0.3464 - 7s/epoch - 173ms/step\n",
            "Epoch 72/280\n",
            "42/42 - 6s - loss: 0.7191 - accuracy: 0.6030 - val_loss: 0.8855 - val_accuracy: 0.3873 - 6s/epoch - 151ms/step\n",
            "Epoch 73/280\n",
            "42/42 - 8s - loss: 0.7133 - accuracy: 0.6202 - val_loss: 0.9019 - val_accuracy: 0.3752 - 8s/epoch - 193ms/step\n",
            "Epoch 74/280\n",
            "42/42 - 6s - loss: 0.6894 - accuracy: 0.6237 - val_loss: 0.8649 - val_accuracy: 0.4024 - 6s/epoch - 148ms/step\n",
            "Epoch 75/280\n",
            "42/42 - 8s - loss: 0.7117 - accuracy: 0.6173 - val_loss: 0.8858 - val_accuracy: 0.3888 - 8s/epoch - 193ms/step\n",
            "Epoch 76/280\n",
            "42/42 - 7s - loss: 0.7185 - accuracy: 0.6202 - val_loss: 0.8598 - val_accuracy: 0.4085 - 7s/epoch - 170ms/step\n",
            "Epoch 77/280\n",
            "42/42 - 8s - loss: 0.7007 - accuracy: 0.6246 - val_loss: 0.8758 - val_accuracy: 0.3979 - 8s/epoch - 181ms/step\n",
            "Epoch 78/280\n",
            "42/42 - 8s - loss: 0.6949 - accuracy: 0.6232 - val_loss: 0.8340 - val_accuracy: 0.4402 - 8s/epoch - 180ms/step\n",
            "Epoch 79/280\n",
            "42/42 - 7s - loss: 0.7026 - accuracy: 0.6153 - val_loss: 0.8659 - val_accuracy: 0.4100 - 7s/epoch - 171ms/step\n",
            "Epoch 80/280\n",
            "42/42 - 8s - loss: 0.7060 - accuracy: 0.6129 - val_loss: 0.8726 - val_accuracy: 0.4085 - 8s/epoch - 194ms/step\n",
            "Epoch 81/280\n",
            "42/42 - 7s - loss: 0.6764 - accuracy: 0.6428 - val_loss: 0.8466 - val_accuracy: 0.4418 - 7s/epoch - 172ms/step\n",
            "Epoch 82/280\n",
            "42/42 - 8s - loss: 0.6969 - accuracy: 0.6266 - val_loss: 0.8536 - val_accuracy: 0.4402 - 8s/epoch - 194ms/step\n",
            "Epoch 83/280\n",
            "42/42 - 7s - loss: 0.6962 - accuracy: 0.6271 - val_loss: 0.8686 - val_accuracy: 0.4221 - 7s/epoch - 171ms/step\n",
            "Epoch 84/280\n",
            "42/42 - 8s - loss: 0.6730 - accuracy: 0.6374 - val_loss: 0.8416 - val_accuracy: 0.4493 - 8s/epoch - 181ms/step\n",
            "Epoch 85/280\n",
            "42/42 - 8s - loss: 0.6684 - accuracy: 0.6418 - val_loss: 0.8807 - val_accuracy: 0.4206 - 8s/epoch - 180ms/step\n",
            "Epoch 86/280\n",
            "42/42 - 6s - loss: 0.6849 - accuracy: 0.6369 - val_loss: 0.8689 - val_accuracy: 0.4327 - 6s/epoch - 149ms/step\n",
            "Epoch 87/280\n",
            "42/42 - 8s - loss: 0.6644 - accuracy: 0.6359 - val_loss: 0.8643 - val_accuracy: 0.4387 - 8s/epoch - 186ms/step\n",
            "Epoch 88/280\n",
            "42/42 - 7s - loss: 0.6638 - accuracy: 0.6428 - val_loss: 0.8495 - val_accuracy: 0.4554 - 7s/epoch - 173ms/step\n",
            "Epoch 89/280\n",
            "42/42 - 8s - loss: 0.6639 - accuracy: 0.6443 - val_loss: 0.8748 - val_accuracy: 0.4418 - 8s/epoch - 193ms/step\n",
            "Epoch 90/280\n",
            "42/42 - 7s - loss: 0.6630 - accuracy: 0.6590 - val_loss: 0.8886 - val_accuracy: 0.4251 - 7s/epoch - 174ms/step\n",
            "Epoch 91/280\n",
            "42/42 - 7s - loss: 0.6636 - accuracy: 0.6457 - val_loss: 0.8464 - val_accuracy: 0.4690 - 7s/epoch - 166ms/step\n",
            "Epoch 92/280\n",
            "42/42 - 7s - loss: 0.6608 - accuracy: 0.6428 - val_loss: 0.8819 - val_accuracy: 0.4387 - 7s/epoch - 173ms/step\n",
            "Epoch 93/280\n",
            "42/42 - 7s - loss: 0.6563 - accuracy: 0.6452 - val_loss: 0.8373 - val_accuracy: 0.4735 - 7s/epoch - 177ms/step\n",
            "Epoch 94/280\n",
            "42/42 - 8s - loss: 0.6642 - accuracy: 0.6423 - val_loss: 0.8776 - val_accuracy: 0.4478 - 8s/epoch - 182ms/step\n",
            "Epoch 95/280\n",
            "42/42 - 7s - loss: 0.6675 - accuracy: 0.6477 - val_loss: 0.8763 - val_accuracy: 0.4463 - 7s/epoch - 172ms/step\n",
            "Epoch 96/280\n",
            "42/42 - 8s - loss: 0.6581 - accuracy: 0.6600 - val_loss: 0.8434 - val_accuracy: 0.4781 - 8s/epoch - 192ms/step\n",
            "Epoch 97/280\n",
            "42/42 - 6s - loss: 0.6443 - accuracy: 0.6521 - val_loss: 0.8645 - val_accuracy: 0.4584 - 6s/epoch - 151ms/step\n",
            "Epoch 98/280\n",
            "42/42 - 8s - loss: 0.6584 - accuracy: 0.6575 - val_loss: 0.8359 - val_accuracy: 0.4902 - 8s/epoch - 193ms/step\n",
            "Epoch 99/280\n",
            "42/42 - 7s - loss: 0.6404 - accuracy: 0.6580 - val_loss: 0.8335 - val_accuracy: 0.4932 - 7s/epoch - 172ms/step\n",
            "Epoch 100/280\n",
            "42/42 - 7s - loss: 0.6449 - accuracy: 0.6605 - val_loss: 0.8564 - val_accuracy: 0.4766 - 7s/epoch - 162ms/step\n",
            "Epoch 101/280\n",
            "42/42 - 7s - loss: 0.6322 - accuracy: 0.6688 - val_loss: 0.8049 - val_accuracy: 0.5174 - 7s/epoch - 173ms/step\n",
            "Epoch 102/280\n",
            "42/42 - 7s - loss: 0.6363 - accuracy: 0.6688 - val_loss: 0.8444 - val_accuracy: 0.4902 - 7s/epoch - 176ms/step\n",
            "Epoch 103/280\n",
            "42/42 - 8s - loss: 0.6512 - accuracy: 0.6467 - val_loss: 0.8569 - val_accuracy: 0.4811 - 8s/epoch - 187ms/step\n",
            "Epoch 104/280\n",
            "42/42 - 7s - loss: 0.6366 - accuracy: 0.6717 - val_loss: 0.8431 - val_accuracy: 0.4947 - 7s/epoch - 171ms/step\n",
            "Epoch 105/280\n",
            "42/42 - 8s - loss: 0.6350 - accuracy: 0.6683 - val_loss: 0.8716 - val_accuracy: 0.4705 - 8s/epoch - 193ms/step\n",
            "Epoch 106/280\n",
            "42/42 - 6s - loss: 0.6235 - accuracy: 0.6786 - val_loss: 0.8674 - val_accuracy: 0.4811 - 6s/epoch - 148ms/step\n",
            "Epoch 107/280\n",
            "42/42 - 7s - loss: 0.6310 - accuracy: 0.6683 - val_loss: 0.8684 - val_accuracy: 0.4796 - 7s/epoch - 171ms/step\n",
            "Epoch 108/280\n",
            "42/42 - 7s - loss: 0.6238 - accuracy: 0.6712 - val_loss: 0.8672 - val_accuracy: 0.4811 - 7s/epoch - 176ms/step\n",
            "Epoch 109/280\n",
            "42/42 - 8s - loss: 0.6342 - accuracy: 0.6708 - val_loss: 0.8537 - val_accuracy: 0.4917 - 8s/epoch - 185ms/step\n",
            "Epoch 110/280\n",
            "42/42 - 7s - loss: 0.6261 - accuracy: 0.6727 - val_loss: 0.8733 - val_accuracy: 0.4796 - 7s/epoch - 178ms/step\n",
            "Epoch 111/280\n",
            "42/42 - 8s - loss: 0.6160 - accuracy: 0.6757 - val_loss: 0.8598 - val_accuracy: 0.4887 - 8s/epoch - 179ms/step\n",
            "Epoch 112/280\n",
            "42/42 - 8s - loss: 0.6017 - accuracy: 0.6928 - val_loss: 0.8585 - val_accuracy: 0.4887 - 8s/epoch - 181ms/step\n",
            "Epoch 113/280\n",
            "42/42 - 7s - loss: 0.6210 - accuracy: 0.6727 - val_loss: 0.8673 - val_accuracy: 0.4856 - 7s/epoch - 155ms/step\n",
            "Epoch 114/280\n",
            "42/42 - 7s - loss: 0.6112 - accuracy: 0.6816 - val_loss: 0.8560 - val_accuracy: 0.4932 - 7s/epoch - 178ms/step\n",
            "Epoch 115/280\n",
            "42/42 - 7s - loss: 0.6174 - accuracy: 0.6781 - val_loss: 0.8456 - val_accuracy: 0.5023 - 7s/epoch - 172ms/step\n",
            "Epoch 116/280\n",
            "42/42 - 8s - loss: 0.5822 - accuracy: 0.6997 - val_loss: 0.8395 - val_accuracy: 0.5008 - 8s/epoch - 199ms/step\n",
            "Epoch 117/280\n",
            "42/42 - 7s - loss: 0.5853 - accuracy: 0.6938 - val_loss: 0.8339 - val_accuracy: 0.5098 - 7s/epoch - 172ms/step\n",
            "Epoch 118/280\n",
            "42/42 - 7s - loss: 0.6102 - accuracy: 0.6825 - val_loss: 0.8629 - val_accuracy: 0.4902 - 7s/epoch - 178ms/step\n",
            "Epoch 119/280\n",
            "42/42 - 8s - loss: 0.6198 - accuracy: 0.6806 - val_loss: 0.8331 - val_accuracy: 0.5098 - 8s/epoch - 184ms/step\n",
            "Epoch 120/280\n",
            "42/42 - 6s - loss: 0.5848 - accuracy: 0.6987 - val_loss: 0.8339 - val_accuracy: 0.5113 - 6s/epoch - 151ms/step\n",
            "Epoch 121/280\n",
            "42/42 - 8s - loss: 0.5889 - accuracy: 0.6987 - val_loss: 0.8330 - val_accuracy: 0.5098 - 8s/epoch - 193ms/step\n",
            "Epoch 122/280\n",
            "42/42 - 7s - loss: 0.5767 - accuracy: 0.7080 - val_loss: 0.8564 - val_accuracy: 0.4917 - 7s/epoch - 172ms/step\n",
            "Epoch 123/280\n",
            "42/42 - 7s - loss: 0.5821 - accuracy: 0.7110 - val_loss: 0.8414 - val_accuracy: 0.5098 - 7s/epoch - 169ms/step\n",
            "Epoch 124/280\n",
            "42/42 - 7s - loss: 0.5976 - accuracy: 0.6987 - val_loss: 0.8637 - val_accuracy: 0.4917 - 7s/epoch - 156ms/step\n",
            "Epoch 125/280\n",
            "42/42 - 8s - loss: 0.5813 - accuracy: 0.6997 - val_loss: 0.8607 - val_accuracy: 0.4962 - 8s/epoch - 183ms/step\n",
            "Epoch 126/280\n",
            "42/42 - 7s - loss: 0.5559 - accuracy: 0.7090 - val_loss: 0.8265 - val_accuracy: 0.5174 - 7s/epoch - 176ms/step\n",
            "Epoch 127/280\n",
            "42/42 - 8s - loss: 0.5835 - accuracy: 0.6953 - val_loss: 0.8351 - val_accuracy: 0.5113 - 8s/epoch - 183ms/step\n",
            "Epoch 128/280\n",
            "42/42 - 8s - loss: 0.5750 - accuracy: 0.7174 - val_loss: 0.8342 - val_accuracy: 0.5174 - 8s/epoch - 183ms/step\n",
            "Epoch 129/280\n",
            "42/42 - 7s - loss: 0.5704 - accuracy: 0.7179 - val_loss: 0.8390 - val_accuracy: 0.5098 - 7s/epoch - 173ms/step\n",
            "Epoch 130/280\n",
            "42/42 - 7s - loss: 0.5531 - accuracy: 0.7237 - val_loss: 0.8298 - val_accuracy: 0.5189 - 7s/epoch - 174ms/step\n",
            "Epoch 131/280\n",
            "42/42 - 6s - loss: 0.5702 - accuracy: 0.7252 - val_loss: 0.8338 - val_accuracy: 0.5174 - 6s/epoch - 150ms/step\n",
            "Epoch 132/280\n",
            "42/42 - 8s - loss: 0.5447 - accuracy: 0.7326 - val_loss: 0.8299 - val_accuracy: 0.5219 - 8s/epoch - 179ms/step\n",
            "Epoch 133/280\n",
            "42/42 - 7s - loss: 0.5597 - accuracy: 0.7169 - val_loss: 0.8395 - val_accuracy: 0.5174 - 7s/epoch - 157ms/step\n",
            "Epoch 134/280\n",
            "42/42 - 8s - loss: 0.5309 - accuracy: 0.7424 - val_loss: 0.8288 - val_accuracy: 0.5159 - 8s/epoch - 195ms/step\n",
            "Epoch 135/280\n",
            "42/42 - 7s - loss: 0.5507 - accuracy: 0.7184 - val_loss: 0.8548 - val_accuracy: 0.5008 - 7s/epoch - 173ms/step\n",
            "Epoch 136/280\n",
            "42/42 - 8s - loss: 0.5524 - accuracy: 0.7184 - val_loss: 0.8122 - val_accuracy: 0.5295 - 8s/epoch - 182ms/step\n",
            "Epoch 137/280\n",
            "42/42 - 8s - loss: 0.5414 - accuracy: 0.7272 - val_loss: 0.8593 - val_accuracy: 0.5023 - 8s/epoch - 182ms/step\n",
            "Epoch 138/280\n",
            "42/42 - 7s - loss: 0.5423 - accuracy: 0.7257 - val_loss: 0.8288 - val_accuracy: 0.5174 - 7s/epoch - 173ms/step\n",
            "Epoch 139/280\n",
            "42/42 - 8s - loss: 0.5450 - accuracy: 0.7233 - val_loss: 0.8258 - val_accuracy: 0.5159 - 8s/epoch - 193ms/step\n",
            "Epoch 140/280\n",
            "42/42 - 7s - loss: 0.5334 - accuracy: 0.7395 - val_loss: 0.8439 - val_accuracy: 0.5008 - 7s/epoch - 156ms/step\n",
            "Epoch 141/280\n",
            "42/42 - 7s - loss: 0.5286 - accuracy: 0.7395 - val_loss: 0.8279 - val_accuracy: 0.5129 - 7s/epoch - 176ms/step\n",
            "Epoch 142/280\n",
            "42/42 - 7s - loss: 0.5222 - accuracy: 0.7458 - val_loss: 0.8389 - val_accuracy: 0.5053 - 7s/epoch - 172ms/step\n",
            "Epoch 143/280\n",
            "42/42 - 8s - loss: 0.5241 - accuracy: 0.7507 - val_loss: 0.8248 - val_accuracy: 0.5174 - 8s/epoch - 186ms/step\n",
            "Epoch 144/280\n",
            "42/42 - 7s - loss: 0.5138 - accuracy: 0.7478 - val_loss: 0.8232 - val_accuracy: 0.5219 - 7s/epoch - 178ms/step\n",
            "Epoch 145/280\n",
            "42/42 - 6s - loss: 0.5009 - accuracy: 0.7502 - val_loss: 0.8076 - val_accuracy: 0.5340 - 6s/epoch - 150ms/step\n",
            "Epoch 146/280\n",
            "42/42 - 8s - loss: 0.5111 - accuracy: 0.7601 - val_loss: 0.8190 - val_accuracy: 0.5219 - 8s/epoch - 182ms/step\n",
            "Epoch 147/280\n",
            "42/42 - 7s - loss: 0.5020 - accuracy: 0.7586 - val_loss: 0.8218 - val_accuracy: 0.5219 - 7s/epoch - 173ms/step\n",
            "Epoch 148/280\n",
            "42/42 - 7s - loss: 0.4951 - accuracy: 0.7738 - val_loss: 0.8206 - val_accuracy: 0.5280 - 7s/epoch - 171ms/step\n",
            "Epoch 149/280\n",
            "42/42 - 6s - loss: 0.5140 - accuracy: 0.7532 - val_loss: 0.8122 - val_accuracy: 0.5204 - 6s/epoch - 150ms/step\n",
            "Epoch 150/280\n",
            "42/42 - 8s - loss: 0.5004 - accuracy: 0.7610 - val_loss: 0.8263 - val_accuracy: 0.5144 - 8s/epoch - 194ms/step\n",
            "Epoch 151/280\n",
            "42/42 - 7s - loss: 0.4887 - accuracy: 0.7650 - val_loss: 0.8124 - val_accuracy: 0.5280 - 7s/epoch - 173ms/step\n",
            "Epoch 152/280\n",
            "42/42 - 7s - loss: 0.4831 - accuracy: 0.7684 - val_loss: 0.8207 - val_accuracy: 0.5265 - 7s/epoch - 168ms/step\n",
            "Epoch 153/280\n",
            "42/42 - 7s - loss: 0.4749 - accuracy: 0.7709 - val_loss: 0.8253 - val_accuracy: 0.5083 - 7s/epoch - 172ms/step\n",
            "Epoch 154/280\n",
            "42/42 - 8s - loss: 0.4719 - accuracy: 0.7748 - val_loss: 0.8036 - val_accuracy: 0.5295 - 8s/epoch - 180ms/step\n",
            "Epoch 155/280\n",
            "42/42 - 7s - loss: 0.4609 - accuracy: 0.7807 - val_loss: 0.8323 - val_accuracy: 0.5098 - 7s/epoch - 172ms/step\n",
            "Epoch 156/280\n",
            "42/42 - 6s - loss: 0.4773 - accuracy: 0.7723 - val_loss: 0.8443 - val_accuracy: 0.4947 - 6s/epoch - 152ms/step\n",
            "Epoch 157/280\n",
            "42/42 - 8s - loss: 0.4741 - accuracy: 0.7758 - val_loss: 0.8393 - val_accuracy: 0.4932 - 8s/epoch - 185ms/step\n",
            "Epoch 158/280\n",
            "42/42 - 6s - loss: 0.4628 - accuracy: 0.7782 - val_loss: 0.8226 - val_accuracy: 0.5174 - 6s/epoch - 151ms/step\n",
            "Epoch 159/280\n",
            "42/42 - 8s - loss: 0.4554 - accuracy: 0.7870 - val_loss: 0.8412 - val_accuracy: 0.4977 - 8s/epoch - 193ms/step\n",
            "Epoch 160/280\n",
            "42/42 - 6s - loss: 0.4593 - accuracy: 0.7816 - val_loss: 0.8125 - val_accuracy: 0.5083 - 6s/epoch - 152ms/step\n",
            "Epoch 161/280\n",
            "42/42 - 8s - loss: 0.4534 - accuracy: 0.7758 - val_loss: 0.8002 - val_accuracy: 0.5234 - 8s/epoch - 194ms/step\n",
            "Epoch 162/280\n",
            "42/42 - 7s - loss: 0.4432 - accuracy: 0.7954 - val_loss: 0.8052 - val_accuracy: 0.5204 - 7s/epoch - 172ms/step\n",
            "Epoch 163/280\n",
            "42/42 - 8s - loss: 0.4505 - accuracy: 0.7905 - val_loss: 0.8301 - val_accuracy: 0.4917 - 8s/epoch - 184ms/step\n",
            "Epoch 164/280\n",
            "42/42 - 8s - loss: 0.4395 - accuracy: 0.8023 - val_loss: 0.8494 - val_accuracy: 0.4629 - 8s/epoch - 179ms/step\n",
            "Epoch 165/280\n",
            "42/42 - 7s - loss: 0.4249 - accuracy: 0.7998 - val_loss: 0.8714 - val_accuracy: 0.4508 - 7s/epoch - 171ms/step\n",
            "Epoch 166/280\n",
            "42/42 - 7s - loss: 0.4403 - accuracy: 0.8008 - val_loss: 0.8694 - val_accuracy: 0.4523 - 7s/epoch - 173ms/step\n",
            "Epoch 167/280\n",
            "42/42 - 6s - loss: 0.4437 - accuracy: 0.7929 - val_loss: 0.8413 - val_accuracy: 0.4705 - 6s/epoch - 150ms/step\n",
            "Epoch 168/280\n",
            "42/42 - 7s - loss: 0.4343 - accuracy: 0.7998 - val_loss: 0.7902 - val_accuracy: 0.5250 - 7s/epoch - 175ms/step\n",
            "Epoch 169/280\n",
            "42/42 - 6s - loss: 0.4173 - accuracy: 0.8057 - val_loss: 0.8341 - val_accuracy: 0.4796 - 6s/epoch - 151ms/step\n",
            "Epoch 170/280\n",
            "42/42 - 8s - loss: 0.4251 - accuracy: 0.8008 - val_loss: 0.8179 - val_accuracy: 0.4932 - 8s/epoch - 194ms/step\n",
            "Epoch 171/280\n",
            "42/42 - 6s - loss: 0.4214 - accuracy: 0.8165 - val_loss: 0.8704 - val_accuracy: 0.4478 - 6s/epoch - 151ms/step\n",
            "Epoch 172/280\n",
            "42/42 - 8s - loss: 0.4101 - accuracy: 0.8116 - val_loss: 0.8896 - val_accuracy: 0.4297 - 8s/epoch - 194ms/step\n",
            "Epoch 173/280\n",
            "42/42 - 7s - loss: 0.4302 - accuracy: 0.8018 - val_loss: 0.8646 - val_accuracy: 0.4508 - 7s/epoch - 172ms/step\n",
            "Epoch 174/280\n",
            "42/42 - 7s - loss: 0.4022 - accuracy: 0.8209 - val_loss: 0.8121 - val_accuracy: 0.4947 - 7s/epoch - 161ms/step\n",
            "Epoch 175/280\n",
            "42/42 - 7s - loss: 0.3950 - accuracy: 0.8243 - val_loss: 0.8004 - val_accuracy: 0.5053 - 7s/epoch - 174ms/step\n",
            "Epoch 176/280\n",
            "42/42 - 7s - loss: 0.4078 - accuracy: 0.8077 - val_loss: 0.8432 - val_accuracy: 0.4569 - 7s/epoch - 175ms/step\n",
            "Epoch 177/280\n",
            "42/42 - 8s - loss: 0.4062 - accuracy: 0.8189 - val_loss: 0.8541 - val_accuracy: 0.4584 - 8s/epoch - 188ms/step\n",
            "Epoch 178/280\n",
            "42/42 - 6s - loss: 0.3993 - accuracy: 0.8175 - val_loss: 0.8297 - val_accuracy: 0.4675 - 6s/epoch - 152ms/step\n",
            "Epoch 179/280\n",
            "42/42 - 8s - loss: 0.3871 - accuracy: 0.8209 - val_loss: 0.8617 - val_accuracy: 0.4327 - 8s/epoch - 194ms/step\n",
            "Epoch 180/280\n",
            "42/42 - 7s - loss: 0.3834 - accuracy: 0.8342 - val_loss: 0.8683 - val_accuracy: 0.4312 - 7s/epoch - 172ms/step\n",
            "Epoch 181/280\n",
            "42/42 - 8s - loss: 0.3946 - accuracy: 0.8204 - val_loss: 0.8326 - val_accuracy: 0.4720 - 8s/epoch - 196ms/step\n",
            "Epoch 182/280\n",
            "42/42 - 7s - loss: 0.3828 - accuracy: 0.8194 - val_loss: 0.8572 - val_accuracy: 0.4402 - 7s/epoch - 171ms/step\n",
            "Epoch 183/280\n",
            "42/42 - 7s - loss: 0.3832 - accuracy: 0.8248 - val_loss: 0.8660 - val_accuracy: 0.4009 - 7s/epoch - 177ms/step\n",
            "Epoch 184/280\n",
            "42/42 - 7s - loss: 0.3672 - accuracy: 0.8376 - val_loss: 0.8682 - val_accuracy: 0.3888 - 7s/epoch - 174ms/step\n",
            "Epoch 185/280\n",
            "42/42 - 6s - loss: 0.3636 - accuracy: 0.8454 - val_loss: 0.8748 - val_accuracy: 0.3843 - 6s/epoch - 152ms/step\n",
            "Epoch 186/280\n",
            "42/42 - 8s - loss: 0.3626 - accuracy: 0.8415 - val_loss: 0.8347 - val_accuracy: 0.4387 - 8s/epoch - 189ms/step\n",
            "Epoch 187/280\n",
            "42/42 - 7s - loss: 0.3734 - accuracy: 0.8337 - val_loss: 0.8412 - val_accuracy: 0.4372 - 7s/epoch - 171ms/step\n",
            "Epoch 188/280\n",
            "42/42 - 8s - loss: 0.3610 - accuracy: 0.8415 - val_loss: 0.8887 - val_accuracy: 0.3858 - 8s/epoch - 193ms/step\n",
            "Epoch 189/280\n",
            "42/42 - 7s - loss: 0.3656 - accuracy: 0.8317 - val_loss: 0.8290 - val_accuracy: 0.4660 - 7s/epoch - 173ms/step\n",
            "Epoch 190/280\n",
            "42/42 - 8s - loss: 0.3683 - accuracy: 0.8307 - val_loss: 0.8821 - val_accuracy: 0.3949 - 8s/epoch - 185ms/step\n",
            "Epoch 191/280\n",
            "42/42 - 8s - loss: 0.3497 - accuracy: 0.8420 - val_loss: 0.8560 - val_accuracy: 0.4206 - 8s/epoch - 179ms/step\n",
            "Epoch 192/280\n",
            "42/42 - 7s - loss: 0.3439 - accuracy: 0.8454 - val_loss: 0.8408 - val_accuracy: 0.4402 - 7s/epoch - 171ms/step\n",
            "Epoch 193/280\n",
            "42/42 - 7s - loss: 0.3395 - accuracy: 0.8508 - val_loss: 0.8510 - val_accuracy: 0.4327 - 7s/epoch - 173ms/step\n",
            "Epoch 194/280\n",
            "42/42 - 6s - loss: 0.3540 - accuracy: 0.8518 - val_loss: 0.8794 - val_accuracy: 0.3949 - 6s/epoch - 152ms/step\n",
            "Epoch 195/280\n",
            "42/42 - 7s - loss: 0.3555 - accuracy: 0.8430 - val_loss: 0.8305 - val_accuracy: 0.4584 - 7s/epoch - 174ms/step\n",
            "Epoch 196/280\n",
            "42/42 - 7s - loss: 0.3481 - accuracy: 0.8484 - val_loss: 0.8257 - val_accuracy: 0.4448 - 7s/epoch - 173ms/step\n",
            "Epoch 197/280\n",
            "42/42 - 7s - loss: 0.3401 - accuracy: 0.8533 - val_loss: 0.8217 - val_accuracy: 0.4554 - 7s/epoch - 173ms/step\n",
            "Epoch 198/280\n",
            "42/42 - 6s - loss: 0.3370 - accuracy: 0.8489 - val_loss: 0.8809 - val_accuracy: 0.3903 - 6s/epoch - 148ms/step\n",
            "Epoch 199/280\n",
            "42/42 - 7s - loss: 0.3281 - accuracy: 0.8494 - val_loss: 0.9157 - val_accuracy: 0.3525 - 7s/epoch - 174ms/step\n",
            "Epoch 200/280\n",
            "42/42 - 7s - loss: 0.3322 - accuracy: 0.8562 - val_loss: 0.8695 - val_accuracy: 0.4115 - 7s/epoch - 171ms/step\n",
            "Epoch 201/280\n",
            "42/42 - 7s - loss: 0.3541 - accuracy: 0.8342 - val_loss: 0.8307 - val_accuracy: 0.4387 - 7s/epoch - 166ms/step\n",
            "Epoch 202/280\n",
            "42/42 - 7s - loss: 0.3185 - accuracy: 0.8606 - val_loss: 0.8347 - val_accuracy: 0.4312 - 7s/epoch - 171ms/step\n",
            "Epoch 203/280\n",
            "42/42 - 7s - loss: 0.3135 - accuracy: 0.8582 - val_loss: 0.8774 - val_accuracy: 0.3797 - 7s/epoch - 159ms/step\n",
            "Epoch 204/280\n",
            "42/42 - 7s - loss: 0.3191 - accuracy: 0.8626 - val_loss: 0.9213 - val_accuracy: 0.3510 - 7s/epoch - 175ms/step\n",
            "Epoch 205/280\n",
            "42/42 - 7s - loss: 0.2997 - accuracy: 0.8685 - val_loss: 0.8520 - val_accuracy: 0.4342 - 7s/epoch - 175ms/step\n",
            "Epoch 206/280\n",
            "42/42 - 8s - loss: 0.3106 - accuracy: 0.8690 - val_loss: 0.9202 - val_accuracy: 0.3555 - 8s/epoch - 190ms/step\n",
            "Epoch 207/280\n",
            "42/42 - 6s - loss: 0.3143 - accuracy: 0.8744 - val_loss: 0.8616 - val_accuracy: 0.3979 - 6s/epoch - 151ms/step\n",
            "Epoch 208/280\n",
            "42/42 - 8s - loss: 0.3219 - accuracy: 0.8616 - val_loss: 0.8327 - val_accuracy: 0.4312 - 8s/epoch - 194ms/step\n",
            "Epoch 209/280\n",
            "42/42 - 6s - loss: 0.3268 - accuracy: 0.8587 - val_loss: 0.8344 - val_accuracy: 0.4418 - 6s/epoch - 154ms/step\n",
            "Epoch 210/280\n",
            "42/42 - 8s - loss: 0.3131 - accuracy: 0.8695 - val_loss: 0.8798 - val_accuracy: 0.3918 - 8s/epoch - 193ms/step\n",
            "Epoch 211/280\n",
            "42/42 - 7s - loss: 0.2959 - accuracy: 0.8734 - val_loss: 0.7962 - val_accuracy: 0.4902 - 7s/epoch - 173ms/step\n",
            "Epoch 212/280\n",
            "42/42 - 7s - loss: 0.2959 - accuracy: 0.8798 - val_loss: 0.8953 - val_accuracy: 0.3722 - 7s/epoch - 162ms/step\n",
            "Epoch 213/280\n",
            "42/42 - 7s - loss: 0.3050 - accuracy: 0.8665 - val_loss: 0.9076 - val_accuracy: 0.3676 - 7s/epoch - 171ms/step\n",
            "Epoch 214/280\n",
            "42/42 - 7s - loss: 0.2899 - accuracy: 0.8734 - val_loss: 0.8417 - val_accuracy: 0.4342 - 7s/epoch - 176ms/step\n",
            "Epoch 215/280\n",
            "42/42 - 8s - loss: 0.2924 - accuracy: 0.8739 - val_loss: 0.9013 - val_accuracy: 0.3707 - 8s/epoch - 189ms/step\n",
            "Epoch 216/280\n",
            "42/42 - 6s - loss: 0.2958 - accuracy: 0.8754 - val_loss: 0.9298 - val_accuracy: 0.3495 - 6s/epoch - 154ms/step\n",
            "Epoch 217/280\n",
            "42/42 - 7s - loss: 0.2954 - accuracy: 0.8759 - val_loss: 0.9292 - val_accuracy: 0.3767 - 7s/epoch - 171ms/step\n",
            "Epoch 218/280\n",
            "42/42 - 7s - loss: 0.2741 - accuracy: 0.8832 - val_loss: 0.8919 - val_accuracy: 0.3858 - 7s/epoch - 175ms/step\n",
            "Epoch 219/280\n",
            "42/42 - 7s - loss: 0.2842 - accuracy: 0.8759 - val_loss: 0.8989 - val_accuracy: 0.3661 - 7s/epoch - 174ms/step\n",
            "Epoch 220/280\n",
            "42/42 - 7s - loss: 0.2797 - accuracy: 0.8911 - val_loss: 0.9874 - val_accuracy: 0.3116 - 7s/epoch - 173ms/step\n",
            "Epoch 221/280\n",
            "42/42 - 7s - loss: 0.2784 - accuracy: 0.8773 - val_loss: 0.8915 - val_accuracy: 0.3873 - 7s/epoch - 166ms/step\n",
            "Epoch 222/280\n",
            "42/42 - 7s - loss: 0.2808 - accuracy: 0.8813 - val_loss: 0.9305 - val_accuracy: 0.3449 - 7s/epoch - 172ms/step\n",
            "Epoch 223/280\n",
            "42/42 - 8s - loss: 0.2795 - accuracy: 0.8837 - val_loss: 0.8219 - val_accuracy: 0.4569 - 8s/epoch - 180ms/step\n",
            "Epoch 224/280\n",
            "42/42 - 7s - loss: 0.2681 - accuracy: 0.8862 - val_loss: 0.8612 - val_accuracy: 0.4191 - 7s/epoch - 176ms/step\n",
            "Epoch 225/280\n",
            "42/42 - 6s - loss: 0.2822 - accuracy: 0.8734 - val_loss: 0.9118 - val_accuracy: 0.3782 - 6s/epoch - 151ms/step\n",
            "Epoch 226/280\n",
            "42/42 - 7s - loss: 0.2788 - accuracy: 0.8891 - val_loss: 0.8765 - val_accuracy: 0.4130 - 7s/epoch - 172ms/step\n",
            "Epoch 227/280\n",
            "42/42 - 6s - loss: 0.2686 - accuracy: 0.8808 - val_loss: 0.8651 - val_accuracy: 0.4221 - 6s/epoch - 153ms/step\n",
            "Epoch 228/280\n",
            "42/42 - 8s - loss: 0.2830 - accuracy: 0.8817 - val_loss: 0.8470 - val_accuracy: 0.4327 - 8s/epoch - 194ms/step\n",
            "Epoch 229/280\n",
            "42/42 - 7s - loss: 0.2590 - accuracy: 0.8847 - val_loss: 0.9378 - val_accuracy: 0.3646 - 7s/epoch - 172ms/step\n",
            "Epoch 230/280\n",
            "42/42 - 7s - loss: 0.2516 - accuracy: 0.8906 - val_loss: 0.9896 - val_accuracy: 0.3132 - 7s/epoch - 176ms/step\n",
            "Epoch 231/280\n",
            "42/42 - 7s - loss: 0.2482 - accuracy: 0.8974 - val_loss: 0.9081 - val_accuracy: 0.3616 - 7s/epoch - 173ms/step\n",
            "Epoch 232/280\n",
            "42/42 - 7s - loss: 0.2705 - accuracy: 0.8827 - val_loss: 0.8221 - val_accuracy: 0.4614 - 7s/epoch - 163ms/step\n",
            "Epoch 233/280\n",
            "42/42 - 7s - loss: 0.2503 - accuracy: 0.9038 - val_loss: 0.9229 - val_accuracy: 0.3631 - 7s/epoch - 174ms/step\n",
            "Epoch 234/280\n",
            "42/42 - 7s - loss: 0.2466 - accuracy: 0.8950 - val_loss: 0.9516 - val_accuracy: 0.3495 - 7s/epoch - 158ms/step\n",
            "Epoch 235/280\n",
            "42/42 - 7s - loss: 0.2507 - accuracy: 0.8871 - val_loss: 0.9532 - val_accuracy: 0.3449 - 7s/epoch - 178ms/step\n",
            "Epoch 236/280\n",
            "42/42 - 6s - loss: 0.2484 - accuracy: 0.9004 - val_loss: 0.8547 - val_accuracy: 0.4266 - 6s/epoch - 153ms/step\n",
            "Epoch 237/280\n",
            "42/42 - 8s - loss: 0.2635 - accuracy: 0.8921 - val_loss: 0.9253 - val_accuracy: 0.3661 - 8s/epoch - 183ms/step\n",
            "Epoch 238/280\n",
            "42/42 - 7s - loss: 0.2518 - accuracy: 0.8994 - val_loss: 0.9562 - val_accuracy: 0.3374 - 7s/epoch - 173ms/step\n",
            "Epoch 239/280\n",
            "42/42 - 8s - loss: 0.2374 - accuracy: 0.8970 - val_loss: 0.8649 - val_accuracy: 0.4236 - 8s/epoch - 194ms/step\n",
            "Epoch 240/280\n",
            "42/42 - 7s - loss: 0.2376 - accuracy: 0.9053 - val_loss: 0.8841 - val_accuracy: 0.4054 - 7s/epoch - 172ms/step\n",
            "Epoch 241/280\n",
            "42/42 - 8s - loss: 0.2296 - accuracy: 0.9043 - val_loss: 0.9765 - val_accuracy: 0.3374 - 8s/epoch - 188ms/step\n",
            "Epoch 242/280\n",
            "42/42 - 7s - loss: 0.2412 - accuracy: 0.9009 - val_loss: 1.0257 - val_accuracy: 0.2890 - 7s/epoch - 169ms/step\n",
            "Epoch 243/280\n",
            "42/42 - 7s - loss: 0.2345 - accuracy: 0.9004 - val_loss: 0.9612 - val_accuracy: 0.3419 - 7s/epoch - 158ms/step\n",
            "Epoch 244/280\n",
            "42/42 - 7s - loss: 0.2279 - accuracy: 0.9092 - val_loss: 0.9058 - val_accuracy: 0.3843 - 7s/epoch - 178ms/step\n",
            "Epoch 245/280\n",
            "42/42 - 6s - loss: 0.2315 - accuracy: 0.9058 - val_loss: 0.8854 - val_accuracy: 0.4160 - 6s/epoch - 152ms/step\n",
            "Epoch 246/280\n",
            "42/42 - 7s - loss: 0.2363 - accuracy: 0.9078 - val_loss: 0.9887 - val_accuracy: 0.3268 - 7s/epoch - 174ms/step\n",
            "Epoch 247/280\n",
            "42/42 - 6s - loss: 0.2266 - accuracy: 0.9024 - val_loss: 0.9268 - val_accuracy: 0.3767 - 6s/epoch - 153ms/step\n",
            "Epoch 248/280\n",
            "42/42 - 8s - loss: 0.2167 - accuracy: 0.9166 - val_loss: 0.8602 - val_accuracy: 0.4327 - 8s/epoch - 189ms/step\n",
            "Epoch 249/280\n",
            "42/42 - 6s - loss: 0.2139 - accuracy: 0.9181 - val_loss: 0.8687 - val_accuracy: 0.4221 - 6s/epoch - 153ms/step\n",
            "Epoch 250/280\n",
            "42/42 - 7s - loss: 0.2103 - accuracy: 0.9190 - val_loss: 0.9207 - val_accuracy: 0.3782 - 7s/epoch - 174ms/step\n",
            "Epoch 251/280\n",
            "42/42 - 7s - loss: 0.2228 - accuracy: 0.9156 - val_loss: 0.9709 - val_accuracy: 0.3389 - 7s/epoch - 173ms/step\n",
            "Epoch 252/280\n",
            "42/42 - 7s - loss: 0.2109 - accuracy: 0.9171 - val_loss: 0.9832 - val_accuracy: 0.3298 - 7s/epoch - 175ms/step\n",
            "Epoch 253/280\n",
            "42/42 - 7s - loss: 0.2321 - accuracy: 0.8994 - val_loss: 0.8633 - val_accuracy: 0.4448 - 7s/epoch - 174ms/step\n",
            "Epoch 254/280\n",
            "42/42 - 8s - loss: 0.2067 - accuracy: 0.9176 - val_loss: 0.9649 - val_accuracy: 0.3631 - 8s/epoch - 187ms/step\n",
            "Epoch 255/280\n",
            "42/42 - 7s - loss: 0.2038 - accuracy: 0.9176 - val_loss: 0.8110 - val_accuracy: 0.4660 - 7s/epoch - 176ms/step\n",
            "Epoch 256/280\n",
            "42/42 - 7s - loss: 0.2189 - accuracy: 0.9068 - val_loss: 0.8828 - val_accuracy: 0.4221 - 7s/epoch - 173ms/step\n",
            "Epoch 257/280\n",
            "42/42 - 8s - loss: 0.2091 - accuracy: 0.9151 - val_loss: 0.8015 - val_accuracy: 0.4720 - 8s/epoch - 191ms/step\n",
            "Epoch 258/280\n",
            "42/42 - 6s - loss: 0.2145 - accuracy: 0.9132 - val_loss: 0.8786 - val_accuracy: 0.4130 - 6s/epoch - 153ms/step\n",
            "Epoch 259/280\n",
            "42/42 - 7s - loss: 0.2073 - accuracy: 0.9166 - val_loss: 0.8640 - val_accuracy: 0.4297 - 7s/epoch - 175ms/step\n",
            "Epoch 260/280\n",
            "42/42 - 6s - loss: 0.2110 - accuracy: 0.9176 - val_loss: 0.7468 - val_accuracy: 0.5144 - 6s/epoch - 153ms/step\n",
            "Epoch 261/280\n",
            "42/42 - 7s - loss: 0.2137 - accuracy: 0.9136 - val_loss: 0.8524 - val_accuracy: 0.4372 - 7s/epoch - 176ms/step\n",
            "Epoch 262/280\n",
            "42/42 - 6s - loss: 0.1990 - accuracy: 0.9200 - val_loss: 0.9135 - val_accuracy: 0.3843 - 6s/epoch - 155ms/step\n",
            "Epoch 263/280\n",
            "42/42 - 7s - loss: 0.1836 - accuracy: 0.9279 - val_loss: 0.8562 - val_accuracy: 0.4342 - 7s/epoch - 173ms/step\n",
            "Epoch 264/280\n",
            "42/42 - 7s - loss: 0.1939 - accuracy: 0.9171 - val_loss: 0.9046 - val_accuracy: 0.4100 - 7s/epoch - 155ms/step\n",
            "Epoch 265/280\n",
            "42/42 - 7s - loss: 0.2000 - accuracy: 0.9235 - val_loss: 0.9242 - val_accuracy: 0.3843 - 7s/epoch - 173ms/step\n",
            "Epoch 266/280\n",
            "42/42 - 7s - loss: 0.2087 - accuracy: 0.9156 - val_loss: 0.8173 - val_accuracy: 0.4599 - 7s/epoch - 172ms/step\n",
            "Epoch 267/280\n",
            "42/42 - 8s - loss: 0.1908 - accuracy: 0.9205 - val_loss: 0.8840 - val_accuracy: 0.4191 - 8s/epoch - 184ms/step\n",
            "Epoch 268/280\n",
            "42/42 - 8s - loss: 0.1790 - accuracy: 0.9387 - val_loss: 0.8794 - val_accuracy: 0.4175 - 8s/epoch - 179ms/step\n",
            "Epoch 269/280\n",
            "42/42 - 6s - loss: 0.1890 - accuracy: 0.9249 - val_loss: 0.8659 - val_accuracy: 0.4387 - 6s/epoch - 152ms/step\n",
            "Epoch 270/280\n",
            "42/42 - 8s - loss: 0.1838 - accuracy: 0.9328 - val_loss: 0.8816 - val_accuracy: 0.4251 - 8s/epoch - 185ms/step\n",
            "Epoch 271/280\n",
            "42/42 - 6s - loss: 0.1961 - accuracy: 0.9200 - val_loss: 0.8813 - val_accuracy: 0.4206 - 6s/epoch - 151ms/step\n",
            "Epoch 272/280\n",
            "42/42 - 8s - loss: 0.1840 - accuracy: 0.9264 - val_loss: 0.7898 - val_accuracy: 0.4902 - 8s/epoch - 194ms/step\n",
            "Epoch 273/280\n",
            "42/42 - 7s - loss: 0.1770 - accuracy: 0.9323 - val_loss: 0.9385 - val_accuracy: 0.3933 - 7s/epoch - 172ms/step\n",
            "Epoch 274/280\n",
            "42/42 - 7s - loss: 0.1640 - accuracy: 0.9406 - val_loss: 0.8829 - val_accuracy: 0.4251 - 7s/epoch - 171ms/step\n",
            "Epoch 275/280\n",
            "42/42 - 6s - loss: 0.1691 - accuracy: 0.9264 - val_loss: 0.8164 - val_accuracy: 0.4675 - 6s/epoch - 152ms/step\n",
            "Epoch 276/280\n",
            "42/42 - 7s - loss: 0.1659 - accuracy: 0.9382 - val_loss: 0.8939 - val_accuracy: 0.4130 - 7s/epoch - 174ms/step\n",
            "Epoch 277/280\n",
            "42/42 - 7s - loss: 0.1819 - accuracy: 0.9279 - val_loss: 0.9573 - val_accuracy: 0.3722 - 7s/epoch - 173ms/step\n",
            "Epoch 278/280\n",
            "42/42 - 8s - loss: 0.1660 - accuracy: 0.9372 - val_loss: 0.8849 - val_accuracy: 0.4175 - 8s/epoch - 184ms/step\n",
            "Epoch 279/280\n",
            "42/42 - 8s - loss: 0.1753 - accuracy: 0.9352 - val_loss: 0.8925 - val_accuracy: 0.4145 - 8s/epoch - 181ms/step\n",
            "Epoch 280/280\n",
            "42/42 - 6s - loss: 0.1656 - accuracy: 0.9406 - val_loss: 0.8355 - val_accuracy: 0.4584 - 6s/epoch - 154ms/step\n",
            "Training end\n",
            "Testing start\n",
            "Testing end\n",
            "Model saved\n",
            "True Positive, False Positive, False negative, Second of Inter in Test, Sensitivity, FPR\n",
            "9,0,43,10500,0.17307692307692307,0.0\n",
            "SEIZURE OUT: 5\n",
            "Training start\n",
            "Epoch 1/280\n",
            "42/42 - 16s - loss: 1.1211 - accuracy: 0.5243 - val_loss: 1.7867 - val_accuracy: 0.3263 - 16s/epoch - 371ms/step\n",
            "Epoch 2/280\n",
            "42/42 - 25s - loss: 0.9109 - accuracy: 0.5291 - val_loss: 1.6817 - val_accuracy: 0.3263 - 25s/epoch - 587ms/step\n",
            "Epoch 3/280\n",
            "42/42 - 30s - loss: 0.8794 - accuracy: 0.5267 - val_loss: 1.5702 - val_accuracy: 0.3263 - 30s/epoch - 717ms/step\n",
            "Epoch 4/280\n",
            "42/42 - 15s - loss: 0.8733 - accuracy: 0.5089 - val_loss: 1.4469 - val_accuracy: 0.3263 - 15s/epoch - 353ms/step\n",
            "Epoch 5/280\n",
            "42/42 - 11s - loss: 0.8575 - accuracy: 0.5099 - val_loss: 1.3374 - val_accuracy: 0.3263 - 11s/epoch - 266ms/step\n",
            "Epoch 6/280\n",
            "42/42 - 11s - loss: 0.8806 - accuracy: 0.4954 - val_loss: 1.2103 - val_accuracy: 0.3263 - 11s/epoch - 256ms/step\n",
            "Epoch 7/280\n",
            "42/42 - 11s - loss: 0.8617 - accuracy: 0.5089 - val_loss: 1.0824 - val_accuracy: 0.3263 - 11s/epoch - 265ms/step\n",
            "Epoch 8/280\n",
            "42/42 - 9s - loss: 0.8356 - accuracy: 0.5103 - val_loss: 0.9800 - val_accuracy: 0.3263 - 9s/epoch - 218ms/step\n",
            "Epoch 9/280\n",
            "42/42 - 9s - loss: 0.8385 - accuracy: 0.5147 - val_loss: 0.9016 - val_accuracy: 0.3263 - 9s/epoch - 219ms/step\n",
            "Epoch 10/280\n",
            "42/42 - 9s - loss: 0.8434 - accuracy: 0.5267 - val_loss: 0.8292 - val_accuracy: 0.3293 - 9s/epoch - 224ms/step\n",
            "Epoch 11/280\n",
            "42/42 - 8s - loss: 0.8415 - accuracy: 0.5185 - val_loss: 0.7964 - val_accuracy: 0.3428 - 8s/epoch - 199ms/step\n",
            "Epoch 12/280\n",
            "42/42 - 8s - loss: 0.8386 - accuracy: 0.5166 - val_loss: 0.7646 - val_accuracy: 0.3533 - 8s/epoch - 196ms/step\n",
            "Epoch 13/280\n",
            "42/42 - 9s - loss: 0.8219 - accuracy: 0.5214 - val_loss: 0.7572 - val_accuracy: 0.3593 - 9s/epoch - 218ms/step\n",
            "Epoch 14/280\n",
            "42/42 - 8s - loss: 0.8399 - accuracy: 0.5123 - val_loss: 0.7669 - val_accuracy: 0.3593 - 8s/epoch - 197ms/step\n",
            "Epoch 15/280\n",
            "42/42 - 9s - loss: 0.8220 - accuracy: 0.5291 - val_loss: 0.7270 - val_accuracy: 0.3847 - 9s/epoch - 213ms/step\n",
            "Epoch 16/280\n",
            "42/42 - 9s - loss: 0.8369 - accuracy: 0.5127 - val_loss: 0.7286 - val_accuracy: 0.3862 - 9s/epoch - 219ms/step\n",
            "Epoch 17/280\n",
            "42/42 - 8s - loss: 0.8275 - accuracy: 0.5171 - val_loss: 0.7354 - val_accuracy: 0.3937 - 8s/epoch - 194ms/step\n",
            "Epoch 18/280\n",
            "42/42 - 9s - loss: 0.8208 - accuracy: 0.5411 - val_loss: 0.7242 - val_accuracy: 0.4057 - 9s/epoch - 212ms/step\n",
            "Epoch 19/280\n",
            "42/42 - 9s - loss: 0.8221 - accuracy: 0.5267 - val_loss: 0.7365 - val_accuracy: 0.4027 - 9s/epoch - 214ms/step\n",
            "Epoch 20/280\n",
            "42/42 - 8s - loss: 0.8225 - accuracy: 0.5166 - val_loss: 0.7312 - val_accuracy: 0.4117 - 8s/epoch - 198ms/step\n",
            "Epoch 21/280\n",
            "42/42 - 8s - loss: 0.8290 - accuracy: 0.5243 - val_loss: 0.7410 - val_accuracy: 0.3997 - 8s/epoch - 197ms/step\n",
            "Epoch 22/280\n",
            "42/42 - 9s - loss: 0.8109 - accuracy: 0.5344 - val_loss: 0.7156 - val_accuracy: 0.4431 - 9s/epoch - 205ms/step\n",
            "Epoch 23/280\n",
            "42/42 - 7s - loss: 0.7979 - accuracy: 0.5469 - val_loss: 0.7301 - val_accuracy: 0.4251 - 7s/epoch - 172ms/step\n",
            "Epoch 24/280\n",
            "42/42 - 9s - loss: 0.8100 - accuracy: 0.5325 - val_loss: 0.7297 - val_accuracy: 0.4356 - 9s/epoch - 215ms/step\n",
            "Epoch 25/280\n",
            "42/42 - 8s - loss: 0.8077 - accuracy: 0.5397 - val_loss: 0.7234 - val_accuracy: 0.4551 - 8s/epoch - 191ms/step\n",
            "Epoch 26/280\n",
            "42/42 - 8s - loss: 0.7913 - accuracy: 0.5426 - val_loss: 0.7037 - val_accuracy: 0.4805 - 8s/epoch - 198ms/step\n",
            "Epoch 27/280\n",
            "42/42 - 9s - loss: 0.7978 - accuracy: 0.5368 - val_loss: 0.7120 - val_accuracy: 0.4835 - 9s/epoch - 210ms/step\n",
            "Epoch 28/280\n",
            "42/42 - 8s - loss: 0.7936 - accuracy: 0.5498 - val_loss: 0.7334 - val_accuracy: 0.4506 - 8s/epoch - 184ms/step\n",
            "Epoch 29/280\n",
            "42/42 - 8s - loss: 0.7720 - accuracy: 0.5522 - val_loss: 0.7329 - val_accuracy: 0.4641 - 8s/epoch - 194ms/step\n",
            "Epoch 30/280\n",
            "42/42 - 8s - loss: 0.7800 - accuracy: 0.5498 - val_loss: 0.7166 - val_accuracy: 0.4835 - 8s/epoch - 200ms/step\n",
            "Epoch 31/280\n",
            "42/42 - 8s - loss: 0.7929 - accuracy: 0.5488 - val_loss: 0.7294 - val_accuracy: 0.4656 - 8s/epoch - 190ms/step\n",
            "Epoch 32/280\n",
            "42/42 - 8s - loss: 0.7850 - accuracy: 0.5426 - val_loss: 0.7038 - val_accuracy: 0.5225 - 8s/epoch - 201ms/step\n",
            "Epoch 33/280\n",
            "42/42 - 8s - loss: 0.7747 - accuracy: 0.5575 - val_loss: 0.7091 - val_accuracy: 0.5060 - 8s/epoch - 190ms/step\n",
            "Epoch 34/280\n",
            "42/42 - 8s - loss: 0.7536 - accuracy: 0.5517 - val_loss: 0.7102 - val_accuracy: 0.5135 - 8s/epoch - 184ms/step\n",
            "Epoch 35/280\n",
            "42/42 - 9s - loss: 0.7793 - accuracy: 0.5430 - val_loss: 0.7022 - val_accuracy: 0.5240 - 9s/epoch - 205ms/step\n",
            "Epoch 36/280\n",
            "42/42 - 8s - loss: 0.7528 - accuracy: 0.5753 - val_loss: 0.7244 - val_accuracy: 0.5060 - 8s/epoch - 191ms/step\n",
            "Epoch 37/280\n",
            "42/42 - 9s - loss: 0.7399 - accuracy: 0.5700 - val_loss: 0.7071 - val_accuracy: 0.5225 - 9s/epoch - 212ms/step\n",
            "Epoch 38/280\n",
            "42/42 - 8s - loss: 0.7557 - accuracy: 0.5777 - val_loss: 0.7180 - val_accuracy: 0.5225 - 8s/epoch - 198ms/step\n",
            "Epoch 39/280\n",
            "42/42 - 7s - loss: 0.7679 - accuracy: 0.5628 - val_loss: 0.7182 - val_accuracy: 0.5240 - 7s/epoch - 176ms/step\n",
            "Epoch 40/280\n",
            "42/42 - 9s - loss: 0.7465 - accuracy: 0.5863 - val_loss: 0.7364 - val_accuracy: 0.4835 - 9s/epoch - 215ms/step\n",
            "Epoch 41/280\n",
            "42/42 - 8s - loss: 0.7332 - accuracy: 0.5998 - val_loss: 0.7117 - val_accuracy: 0.5329 - 8s/epoch - 190ms/step\n",
            "Epoch 42/280\n",
            "42/42 - 9s - loss: 0.7489 - accuracy: 0.5902 - val_loss: 0.6975 - val_accuracy: 0.5479 - 9s/epoch - 203ms/step\n",
            "Epoch 43/280\n",
            "42/42 - 8s - loss: 0.7314 - accuracy: 0.5998 - val_loss: 0.7062 - val_accuracy: 0.5419 - 8s/epoch - 198ms/step\n",
            "Epoch 44/280\n",
            "42/42 - 8s - loss: 0.7386 - accuracy: 0.5892 - val_loss: 0.6978 - val_accuracy: 0.5524 - 8s/epoch - 193ms/step\n",
            "Epoch 45/280\n",
            "42/42 - 8s - loss: 0.7308 - accuracy: 0.6022 - val_loss: 0.7287 - val_accuracy: 0.5210 - 8s/epoch - 192ms/step\n",
            "Epoch 46/280\n",
            "42/42 - 8s - loss: 0.7411 - accuracy: 0.5868 - val_loss: 0.6658 - val_accuracy: 0.5793 - 8s/epoch - 202ms/step\n",
            "Epoch 47/280\n",
            "42/42 - 7s - loss: 0.7258 - accuracy: 0.5960 - val_loss: 0.7019 - val_accuracy: 0.5539 - 7s/epoch - 172ms/step\n",
            "Epoch 48/280\n",
            "42/42 - 9s - loss: 0.7239 - accuracy: 0.6118 - val_loss: 0.6649 - val_accuracy: 0.5868 - 9s/epoch - 203ms/step\n",
            "Epoch 49/280\n",
            "42/42 - 8s - loss: 0.7011 - accuracy: 0.6070 - val_loss: 0.7077 - val_accuracy: 0.5509 - 8s/epoch - 192ms/step\n",
            "Epoch 50/280\n",
            "42/42 - 9s - loss: 0.7210 - accuracy: 0.6051 - val_loss: 0.6919 - val_accuracy: 0.5704 - 9s/epoch - 205ms/step\n",
            "Epoch 51/280\n",
            "42/42 - 9s - loss: 0.7209 - accuracy: 0.6046 - val_loss: 0.7011 - val_accuracy: 0.5599 - 9s/epoch - 214ms/step\n",
            "Epoch 52/280\n",
            "42/42 - 7s - loss: 0.6991 - accuracy: 0.6186 - val_loss: 0.6681 - val_accuracy: 0.5913 - 7s/epoch - 173ms/step\n",
            "Epoch 53/280\n",
            "42/42 - 9s - loss: 0.7103 - accuracy: 0.6243 - val_loss: 0.6909 - val_accuracy: 0.5778 - 9s/epoch - 210ms/step\n",
            "Epoch 54/280\n",
            "42/42 - 8s - loss: 0.7139 - accuracy: 0.6277 - val_loss: 0.6869 - val_accuracy: 0.5808 - 8s/epoch - 200ms/step\n",
            "Epoch 55/280\n",
            "42/42 - 7s - loss: 0.6871 - accuracy: 0.6267 - val_loss: 0.6687 - val_accuracy: 0.5973 - 7s/epoch - 173ms/step\n",
            "Epoch 56/280\n",
            "42/42 - 8s - loss: 0.6913 - accuracy: 0.6219 - val_loss: 0.6800 - val_accuracy: 0.5913 - 8s/epoch - 200ms/step\n",
            "Epoch 57/280\n",
            "42/42 - 8s - loss: 0.6883 - accuracy: 0.6359 - val_loss: 0.6757 - val_accuracy: 0.5958 - 8s/epoch - 190ms/step\n",
            "Epoch 58/280\n",
            "42/42 - 8s - loss: 0.6932 - accuracy: 0.6306 - val_loss: 0.6776 - val_accuracy: 0.5988 - 8s/epoch - 192ms/step\n",
            "Epoch 59/280\n",
            "42/42 - 9s - loss: 0.6788 - accuracy: 0.6349 - val_loss: 0.6597 - val_accuracy: 0.6138 - 9s/epoch - 205ms/step\n",
            "Epoch 60/280\n",
            "42/42 - 8s - loss: 0.6793 - accuracy: 0.6364 - val_loss: 0.6537 - val_accuracy: 0.6138 - 8s/epoch - 193ms/step\n",
            "Epoch 61/280\n",
            "42/42 - 8s - loss: 0.6768 - accuracy: 0.6316 - val_loss: 0.6662 - val_accuracy: 0.6048 - 8s/epoch - 200ms/step\n",
            "Epoch 62/280\n",
            "42/42 - 8s - loss: 0.6953 - accuracy: 0.6311 - val_loss: 0.6800 - val_accuracy: 0.5943 - 8s/epoch - 202ms/step\n",
            "Epoch 63/280\n",
            "42/42 - 7s - loss: 0.6978 - accuracy: 0.6316 - val_loss: 0.6543 - val_accuracy: 0.6153 - 7s/epoch - 177ms/step\n",
            "Epoch 64/280\n",
            "42/42 - 9s - loss: 0.6591 - accuracy: 0.6595 - val_loss: 0.6730 - val_accuracy: 0.6063 - 9s/epoch - 212ms/step\n",
            "Epoch 65/280\n",
            "42/42 - 8s - loss: 0.6690 - accuracy: 0.6455 - val_loss: 0.6583 - val_accuracy: 0.6183 - 8s/epoch - 195ms/step\n",
            "Epoch 66/280\n",
            "42/42 - 8s - loss: 0.6708 - accuracy: 0.6436 - val_loss: 0.6561 - val_accuracy: 0.6183 - 8s/epoch - 202ms/step\n",
            "Epoch 67/280\n",
            "42/42 - 8s - loss: 0.6542 - accuracy: 0.6671 - val_loss: 0.6085 - val_accuracy: 0.6662 - 8s/epoch - 196ms/step\n",
            "Epoch 68/280\n",
            "42/42 - 8s - loss: 0.6774 - accuracy: 0.6441 - val_loss: 0.6351 - val_accuracy: 0.6317 - 8s/epoch - 195ms/step\n",
            "Epoch 69/280\n",
            "42/42 - 9s - loss: 0.6401 - accuracy: 0.6643 - val_loss: 0.6090 - val_accuracy: 0.6587 - 9s/epoch - 203ms/step\n",
            "Epoch 70/280\n",
            "42/42 - 9s - loss: 0.6372 - accuracy: 0.6744 - val_loss: 0.6342 - val_accuracy: 0.6317 - 9s/epoch - 206ms/step\n",
            "Epoch 71/280\n",
            "42/42 - 7s - loss: 0.6533 - accuracy: 0.6527 - val_loss: 0.6014 - val_accuracy: 0.6662 - 7s/epoch - 176ms/step\n",
            "Epoch 72/280\n",
            "42/42 - 9s - loss: 0.6446 - accuracy: 0.6652 - val_loss: 0.6010 - val_accuracy: 0.6647 - 9s/epoch - 215ms/step\n",
            "Epoch 73/280\n",
            "42/42 - 8s - loss: 0.6482 - accuracy: 0.6628 - val_loss: 0.6207 - val_accuracy: 0.6542 - 8s/epoch - 196ms/step\n",
            "Epoch 74/280\n",
            "42/42 - 8s - loss: 0.6224 - accuracy: 0.6821 - val_loss: 0.6283 - val_accuracy: 0.6407 - 8s/epoch - 188ms/step\n",
            "Epoch 75/280\n",
            "42/42 - 9s - loss: 0.6373 - accuracy: 0.6739 - val_loss: 0.6080 - val_accuracy: 0.6662 - 9s/epoch - 215ms/step\n",
            "Epoch 76/280\n",
            "42/42 - 8s - loss: 0.6236 - accuracy: 0.6700 - val_loss: 0.6031 - val_accuracy: 0.6707 - 8s/epoch - 196ms/step\n",
            "Epoch 77/280\n",
            "42/42 - 8s - loss: 0.6131 - accuracy: 0.6835 - val_loss: 0.5919 - val_accuracy: 0.6796 - 8s/epoch - 193ms/step\n",
            "Epoch 78/280\n",
            "42/42 - 9s - loss: 0.6252 - accuracy: 0.6893 - val_loss: 0.6115 - val_accuracy: 0.6557 - 9s/epoch - 210ms/step\n",
            "Epoch 79/280\n",
            "42/42 - 8s - loss: 0.6201 - accuracy: 0.6888 - val_loss: 0.5940 - val_accuracy: 0.6722 - 8s/epoch - 179ms/step\n",
            "Epoch 80/280\n",
            "42/42 - 9s - loss: 0.6166 - accuracy: 0.6801 - val_loss: 0.6130 - val_accuracy: 0.6557 - 9s/epoch - 214ms/step\n",
            "Epoch 81/280\n",
            "42/42 - 8s - loss: 0.6023 - accuracy: 0.6845 - val_loss: 0.5890 - val_accuracy: 0.6811 - 8s/epoch - 202ms/step\n",
            "Epoch 82/280\n",
            "42/42 - 8s - loss: 0.6063 - accuracy: 0.6821 - val_loss: 0.5773 - val_accuracy: 0.6901 - 8s/epoch - 182ms/step\n",
            "Epoch 83/280\n",
            "42/42 - 9s - loss: 0.5865 - accuracy: 0.6994 - val_loss: 0.5905 - val_accuracy: 0.6811 - 9s/epoch - 204ms/step\n",
            "Epoch 84/280\n",
            "42/42 - 8s - loss: 0.6096 - accuracy: 0.6970 - val_loss: 0.5819 - val_accuracy: 0.6841 - 8s/epoch - 198ms/step\n",
            "Epoch 85/280\n",
            "42/42 - 9s - loss: 0.5836 - accuracy: 0.7056 - val_loss: 0.5963 - val_accuracy: 0.6692 - 9s/epoch - 202ms/step\n",
            "Epoch 86/280\n",
            "42/42 - 9s - loss: 0.5884 - accuracy: 0.7076 - val_loss: 0.5862 - val_accuracy: 0.6841 - 9s/epoch - 206ms/step\n",
            "Epoch 87/280\n",
            "42/42 - 8s - loss: 0.5821 - accuracy: 0.7138 - val_loss: 0.5928 - val_accuracy: 0.6722 - 8s/epoch - 198ms/step\n",
            "Epoch 88/280\n",
            "42/42 - 9s - loss: 0.5986 - accuracy: 0.6960 - val_loss: 0.5707 - val_accuracy: 0.6886 - 9s/epoch - 208ms/step\n",
            "Epoch 89/280\n",
            "42/42 - 9s - loss: 0.5810 - accuracy: 0.7003 - val_loss: 0.5612 - val_accuracy: 0.6976 - 9s/epoch - 218ms/step\n",
            "Epoch 90/280\n",
            "42/42 - 8s - loss: 0.5850 - accuracy: 0.7032 - val_loss: 0.5647 - val_accuracy: 0.6961 - 8s/epoch - 196ms/step\n",
            "Epoch 91/280\n",
            "42/42 - 8s - loss: 0.5723 - accuracy: 0.7249 - val_loss: 0.5842 - val_accuracy: 0.6811 - 8s/epoch - 196ms/step\n",
            "Epoch 92/280\n",
            "42/42 - 9s - loss: 0.5612 - accuracy: 0.7282 - val_loss: 0.5710 - val_accuracy: 0.6901 - 9s/epoch - 214ms/step\n",
            "Epoch 93/280\n",
            "42/42 - 8s - loss: 0.5667 - accuracy: 0.7201 - val_loss: 0.5680 - val_accuracy: 0.6961 - 8s/epoch - 183ms/step\n",
            "Epoch 94/280\n",
            "42/42 - 9s - loss: 0.5684 - accuracy: 0.7191 - val_loss: 0.5598 - val_accuracy: 0.6946 - 9s/epoch - 217ms/step\n",
            "Epoch 95/280\n",
            "42/42 - 9s - loss: 0.5421 - accuracy: 0.7427 - val_loss: 0.5684 - val_accuracy: 0.6946 - 9s/epoch - 210ms/step\n",
            "Epoch 96/280\n",
            "42/42 - 8s - loss: 0.5482 - accuracy: 0.7186 - val_loss: 0.5698 - val_accuracy: 0.6931 - 8s/epoch - 197ms/step\n",
            "Epoch 97/280\n",
            "42/42 - 9s - loss: 0.5518 - accuracy: 0.7311 - val_loss: 0.5472 - val_accuracy: 0.7036 - 9s/epoch - 204ms/step\n",
            "Epoch 98/280\n",
            "42/42 - 11s - loss: 0.5350 - accuracy: 0.7340 - val_loss: 0.5440 - val_accuracy: 0.7111 - 11s/epoch - 265ms/step\n",
            "Epoch 99/280\n",
            "42/42 - 8s - loss: 0.5304 - accuracy: 0.7431 - val_loss: 0.5318 - val_accuracy: 0.7201 - 8s/epoch - 185ms/step\n",
            "Epoch 100/280\n",
            "42/42 - 9s - loss: 0.5366 - accuracy: 0.7335 - val_loss: 0.5375 - val_accuracy: 0.7141 - 9s/epoch - 215ms/step\n",
            "Epoch 101/280\n",
            "42/42 - 9s - loss: 0.5270 - accuracy: 0.7340 - val_loss: 0.5343 - val_accuracy: 0.7171 - 9s/epoch - 207ms/step\n",
            "Epoch 102/280\n",
            "42/42 - 8s - loss: 0.5097 - accuracy: 0.7609 - val_loss: 0.5402 - val_accuracy: 0.7111 - 8s/epoch - 198ms/step\n",
            "Epoch 103/280\n",
            "42/42 - 9s - loss: 0.5144 - accuracy: 0.7581 - val_loss: 0.5290 - val_accuracy: 0.7156 - 9s/epoch - 217ms/step\n",
            "Epoch 104/280\n",
            "42/42 - 9s - loss: 0.5183 - accuracy: 0.7436 - val_loss: 0.5299 - val_accuracy: 0.7171 - 9s/epoch - 214ms/step\n",
            "Epoch 105/280\n",
            "42/42 - 8s - loss: 0.5072 - accuracy: 0.7532 - val_loss: 0.5284 - val_accuracy: 0.7171 - 8s/epoch - 198ms/step\n",
            "Epoch 106/280\n",
            "42/42 - 8s - loss: 0.5059 - accuracy: 0.7523 - val_loss: 0.4948 - val_accuracy: 0.7545 - 8s/epoch - 198ms/step\n",
            "Epoch 107/280\n",
            "42/42 - 9s - loss: 0.5012 - accuracy: 0.7571 - val_loss: 0.4994 - val_accuracy: 0.7455 - 9s/epoch - 207ms/step\n",
            "Epoch 108/280\n",
            "42/42 - 8s - loss: 0.4958 - accuracy: 0.7686 - val_loss: 0.5093 - val_accuracy: 0.7320 - 8s/epoch - 201ms/step\n",
            "Epoch 109/280\n",
            "42/42 - 9s - loss: 0.4809 - accuracy: 0.7585 - val_loss: 0.4946 - val_accuracy: 0.7515 - 9s/epoch - 216ms/step\n",
            "Epoch 110/280\n",
            "42/42 - 9s - loss: 0.4745 - accuracy: 0.7629 - val_loss: 0.4992 - val_accuracy: 0.7425 - 9s/epoch - 207ms/step\n",
            "Epoch 111/280\n",
            "42/42 - 8s - loss: 0.4795 - accuracy: 0.7759 - val_loss: 0.4983 - val_accuracy: 0.7470 - 8s/epoch - 197ms/step\n",
            "Epoch 112/280\n",
            "42/42 - 9s - loss: 0.4756 - accuracy: 0.7730 - val_loss: 0.4854 - val_accuracy: 0.7710 - 9s/epoch - 208ms/step\n",
            "Epoch 113/280\n",
            "42/42 - 11s - loss: 0.4572 - accuracy: 0.7840 - val_loss: 0.5055 - val_accuracy: 0.7425 - 11s/epoch - 260ms/step\n",
            "Epoch 114/280\n",
            "42/42 - 8s - loss: 0.4620 - accuracy: 0.7811 - val_loss: 0.4825 - val_accuracy: 0.7799 - 8s/epoch - 197ms/step\n",
            "Epoch 115/280\n",
            "42/42 - 8s - loss: 0.4558 - accuracy: 0.7850 - val_loss: 0.4766 - val_accuracy: 0.7844 - 8s/epoch - 196ms/step\n",
            "Epoch 116/280\n",
            "42/42 - 9s - loss: 0.4453 - accuracy: 0.7932 - val_loss: 0.4658 - val_accuracy: 0.7934 - 9s/epoch - 217ms/step\n",
            "Epoch 117/280\n",
            "42/42 - 8s - loss: 0.4556 - accuracy: 0.7835 - val_loss: 0.4646 - val_accuracy: 0.7934 - 8s/epoch - 182ms/step\n",
            "Epoch 118/280\n",
            "42/42 - 9s - loss: 0.4392 - accuracy: 0.7999 - val_loss: 0.4655 - val_accuracy: 0.8009 - 9s/epoch - 220ms/step\n",
            "Epoch 119/280\n",
            "42/42 - 9s - loss: 0.4402 - accuracy: 0.7965 - val_loss: 0.4580 - val_accuracy: 0.8159 - 9s/epoch - 213ms/step\n",
            "Epoch 120/280\n",
            "42/42 - 8s - loss: 0.4268 - accuracy: 0.7970 - val_loss: 0.4556 - val_accuracy: 0.8054 - 8s/epoch - 193ms/step\n",
            "Epoch 121/280\n",
            "42/42 - 9s - loss: 0.4363 - accuracy: 0.7922 - val_loss: 0.4469 - val_accuracy: 0.8114 - 9s/epoch - 204ms/step\n",
            "Epoch 122/280\n",
            "42/42 - 9s - loss: 0.4274 - accuracy: 0.7994 - val_loss: 0.4492 - val_accuracy: 0.8129 - 9s/epoch - 208ms/step\n",
            "Epoch 123/280\n",
            "42/42 - 8s - loss: 0.4244 - accuracy: 0.8057 - val_loss: 0.4345 - val_accuracy: 0.8308 - 8s/epoch - 198ms/step\n",
            "Epoch 124/280\n",
            "42/42 - 9s - loss: 0.4081 - accuracy: 0.8249 - val_loss: 0.4368 - val_accuracy: 0.8219 - 9s/epoch - 208ms/step\n",
            "Epoch 125/280\n",
            "42/42 - 11s - loss: 0.4053 - accuracy: 0.8134 - val_loss: 0.4391 - val_accuracy: 0.8219 - 11s/epoch - 259ms/step\n",
            "Epoch 126/280\n",
            "42/42 - 8s - loss: 0.4147 - accuracy: 0.8086 - val_loss: 0.4314 - val_accuracy: 0.8308 - 8s/epoch - 198ms/step\n",
            "Epoch 127/280\n",
            "42/42 - 9s - loss: 0.3850 - accuracy: 0.8220 - val_loss: 0.4380 - val_accuracy: 0.8219 - 9s/epoch - 215ms/step\n",
            "Epoch 128/280\n",
            "42/42 - 9s - loss: 0.3773 - accuracy: 0.8341 - val_loss: 0.4295 - val_accuracy: 0.8278 - 9s/epoch - 218ms/step\n",
            "Epoch 129/280\n",
            "42/42 - 8s - loss: 0.3945 - accuracy: 0.8230 - val_loss: 0.4228 - val_accuracy: 0.8293 - 8s/epoch - 200ms/step\n",
            "Epoch 130/280\n",
            "42/42 - 9s - loss: 0.3630 - accuracy: 0.8389 - val_loss: 0.4281 - val_accuracy: 0.8353 - 9s/epoch - 212ms/step\n",
            "Epoch 131/280\n",
            "42/42 - 9s - loss: 0.3762 - accuracy: 0.8312 - val_loss: 0.4157 - val_accuracy: 0.8323 - 9s/epoch - 206ms/step\n",
            "Epoch 132/280\n",
            "42/42 - 8s - loss: 0.3684 - accuracy: 0.8345 - val_loss: 0.4195 - val_accuracy: 0.8428 - 8s/epoch - 199ms/step\n",
            "Epoch 133/280\n",
            "42/42 - 8s - loss: 0.3665 - accuracy: 0.8442 - val_loss: 0.4071 - val_accuracy: 0.8458 - 8s/epoch - 200ms/step\n",
            "Epoch 134/280\n",
            "42/42 - 9s - loss: 0.3565 - accuracy: 0.8461 - val_loss: 0.4028 - val_accuracy: 0.8533 - 9s/epoch - 208ms/step\n",
            "Epoch 135/280\n",
            "42/42 - 8s - loss: 0.3481 - accuracy: 0.8461 - val_loss: 0.4103 - val_accuracy: 0.8428 - 8s/epoch - 199ms/step\n",
            "Epoch 136/280\n",
            "42/42 - 9s - loss: 0.3511 - accuracy: 0.8456 - val_loss: 0.4126 - val_accuracy: 0.8383 - 9s/epoch - 225ms/step\n",
            "Epoch 137/280\n",
            "42/42 - 9s - loss: 0.3318 - accuracy: 0.8586 - val_loss: 0.4110 - val_accuracy: 0.8383 - 9s/epoch - 212ms/step\n",
            "Epoch 138/280\n",
            "42/42 - 8s - loss: 0.3509 - accuracy: 0.8538 - val_loss: 0.3936 - val_accuracy: 0.8563 - 8s/epoch - 196ms/step\n",
            "Epoch 139/280\n",
            "42/42 - 9s - loss: 0.3463 - accuracy: 0.8418 - val_loss: 0.4006 - val_accuracy: 0.8473 - 9s/epoch - 219ms/step\n",
            "Epoch 140/280\n",
            "42/42 - 9s - loss: 0.3150 - accuracy: 0.8749 - val_loss: 0.3999 - val_accuracy: 0.8473 - 9s/epoch - 218ms/step\n",
            "Epoch 141/280\n",
            "42/42 - 8s - loss: 0.3377 - accuracy: 0.8490 - val_loss: 0.4042 - val_accuracy: 0.8473 - 8s/epoch - 197ms/step\n",
            "Epoch 142/280\n",
            "42/42 - 9s - loss: 0.3134 - accuracy: 0.8629 - val_loss: 0.3967 - val_accuracy: 0.8518 - 9s/epoch - 203ms/step\n",
            "Epoch 143/280\n",
            "42/42 - 9s - loss: 0.3102 - accuracy: 0.8615 - val_loss: 0.3992 - val_accuracy: 0.8473 - 9s/epoch - 221ms/step\n",
            "Epoch 144/280\n",
            "42/42 - 8s - loss: 0.3163 - accuracy: 0.8634 - val_loss: 0.3828 - val_accuracy: 0.8668 - 8s/epoch - 199ms/step\n",
            "Epoch 145/280\n",
            "42/42 - 8s - loss: 0.3038 - accuracy: 0.8696 - val_loss: 0.3927 - val_accuracy: 0.8563 - 8s/epoch - 200ms/step\n",
            "Epoch 146/280\n",
            "42/42 - 9s - loss: 0.2988 - accuracy: 0.8735 - val_loss: 0.3812 - val_accuracy: 0.8593 - 9s/epoch - 215ms/step\n",
            "Epoch 147/280\n",
            "42/42 - 8s - loss: 0.2953 - accuracy: 0.8682 - val_loss: 0.3840 - val_accuracy: 0.8563 - 8s/epoch - 200ms/step\n",
            "Epoch 148/280\n",
            "42/42 - 9s - loss: 0.2860 - accuracy: 0.8884 - val_loss: 0.3770 - val_accuracy: 0.8623 - 9s/epoch - 221ms/step\n",
            "Epoch 149/280\n",
            "42/42 - 10s - loss: 0.2831 - accuracy: 0.8783 - val_loss: 0.3938 - val_accuracy: 0.8518 - 10s/epoch - 234ms/step\n",
            "Epoch 150/280\n",
            "42/42 - 8s - loss: 0.2806 - accuracy: 0.8855 - val_loss: 0.3964 - val_accuracy: 0.8458 - 8s/epoch - 202ms/step\n",
            "Epoch 151/280\n",
            "42/42 - 8s - loss: 0.2718 - accuracy: 0.8913 - val_loss: 0.3909 - val_accuracy: 0.8533 - 8s/epoch - 202ms/step\n",
            "Epoch 152/280\n",
            "42/42 - 10s - loss: 0.2745 - accuracy: 0.8894 - val_loss: 0.3853 - val_accuracy: 0.8503 - 10s/epoch - 232ms/step\n",
            "Epoch 153/280\n",
            "42/42 - 8s - loss: 0.2726 - accuracy: 0.8937 - val_loss: 0.3852 - val_accuracy: 0.8578 - 8s/epoch - 202ms/step\n",
            "Epoch 154/280\n",
            "42/42 - 8s - loss: 0.2725 - accuracy: 0.8913 - val_loss: 0.3813 - val_accuracy: 0.8608 - 8s/epoch - 200ms/step\n",
            "Epoch 155/280\n",
            "42/42 - 9s - loss: 0.2649 - accuracy: 0.8899 - val_loss: 0.3875 - val_accuracy: 0.8533 - 9s/epoch - 220ms/step\n",
            "Epoch 156/280\n",
            "42/42 - 8s - loss: 0.2571 - accuracy: 0.8951 - val_loss: 0.3783 - val_accuracy: 0.8593 - 8s/epoch - 195ms/step\n",
            "Epoch 157/280\n",
            "42/42 - 9s - loss: 0.2406 - accuracy: 0.8995 - val_loss: 0.3840 - val_accuracy: 0.8563 - 9s/epoch - 205ms/step\n",
            "Epoch 158/280\n",
            "42/42 - 9s - loss: 0.2451 - accuracy: 0.9009 - val_loss: 0.3781 - val_accuracy: 0.8563 - 9s/epoch - 218ms/step\n",
            "Epoch 159/280\n",
            "42/42 - 8s - loss: 0.2392 - accuracy: 0.9024 - val_loss: 0.3899 - val_accuracy: 0.8488 - 8s/epoch - 198ms/step\n",
            "Epoch 160/280\n",
            "42/42 - 9s - loss: 0.2364 - accuracy: 0.9076 - val_loss: 0.3768 - val_accuracy: 0.8623 - 9s/epoch - 203ms/step\n",
            "Epoch 161/280\n",
            "42/42 - 9s - loss: 0.2285 - accuracy: 0.9038 - val_loss: 0.3762 - val_accuracy: 0.8638 - 9s/epoch - 218ms/step\n",
            "Epoch 162/280\n",
            "42/42 - 8s - loss: 0.2165 - accuracy: 0.9177 - val_loss: 0.3731 - val_accuracy: 0.8578 - 8s/epoch - 200ms/step\n",
            "Epoch 163/280\n",
            "42/42 - 9s - loss: 0.2222 - accuracy: 0.9096 - val_loss: 0.3811 - val_accuracy: 0.8548 - 9s/epoch - 217ms/step\n",
            "Epoch 164/280\n",
            "42/42 - 9s - loss: 0.2214 - accuracy: 0.9125 - val_loss: 0.3861 - val_accuracy: 0.8548 - 9s/epoch - 209ms/step\n",
            "Epoch 165/280\n",
            "42/42 - 8s - loss: 0.2169 - accuracy: 0.9153 - val_loss: 0.3797 - val_accuracy: 0.8668 - 8s/epoch - 198ms/step\n",
            "Epoch 166/280\n",
            "42/42 - 9s - loss: 0.2162 - accuracy: 0.9216 - val_loss: 0.3922 - val_accuracy: 0.8443 - 9s/epoch - 220ms/step\n",
            "Epoch 167/280\n",
            "42/42 - 9s - loss: 0.2035 - accuracy: 0.9144 - val_loss: 0.3788 - val_accuracy: 0.8653 - 9s/epoch - 217ms/step\n",
            "Epoch 168/280\n",
            "42/42 - 9s - loss: 0.2230 - accuracy: 0.9125 - val_loss: 0.3835 - val_accuracy: 0.8653 - 9s/epoch - 203ms/step\n",
            "Epoch 169/280\n",
            "42/42 - 9s - loss: 0.2113 - accuracy: 0.9163 - val_loss: 0.3770 - val_accuracy: 0.8683 - 9s/epoch - 208ms/step\n",
            "Epoch 170/280\n",
            "42/42 - 9s - loss: 0.2136 - accuracy: 0.9182 - val_loss: 0.3852 - val_accuracy: 0.8608 - 9s/epoch - 211ms/step\n",
            "Epoch 171/280\n",
            "42/42 - 8s - loss: 0.1865 - accuracy: 0.9235 - val_loss: 0.3887 - val_accuracy: 0.8533 - 8s/epoch - 199ms/step\n",
            "Epoch 172/280\n",
            "42/42 - 9s - loss: 0.1869 - accuracy: 0.9360 - val_loss: 0.3828 - val_accuracy: 0.8623 - 9s/epoch - 207ms/step\n",
            "Epoch 173/280\n",
            "42/42 - 9s - loss: 0.1974 - accuracy: 0.9254 - val_loss: 0.3971 - val_accuracy: 0.8383 - 9s/epoch - 209ms/step\n",
            "Epoch 174/280\n",
            "42/42 - 8s - loss: 0.1754 - accuracy: 0.9370 - val_loss: 0.3803 - val_accuracy: 0.8533 - 8s/epoch - 199ms/step\n",
            "Epoch 175/280\n",
            "42/42 - 9s - loss: 0.1942 - accuracy: 0.9163 - val_loss: 0.3933 - val_accuracy: 0.8368 - 9s/epoch - 218ms/step\n",
            "Epoch 176/280\n",
            "42/42 - 9s - loss: 0.1726 - accuracy: 0.9389 - val_loss: 0.3960 - val_accuracy: 0.8338 - 9s/epoch - 217ms/step\n",
            "Epoch 177/280\n",
            "42/42 - 8s - loss: 0.1794 - accuracy: 0.9341 - val_loss: 0.3985 - val_accuracy: 0.8368 - 8s/epoch - 199ms/step\n",
            "Epoch 178/280\n",
            "42/42 - 9s - loss: 0.1781 - accuracy: 0.9259 - val_loss: 0.3997 - val_accuracy: 0.8413 - 9s/epoch - 216ms/step\n",
            "Epoch 179/280\n",
            "42/42 - 9s - loss: 0.1721 - accuracy: 0.9423 - val_loss: 0.3839 - val_accuracy: 0.8608 - 9s/epoch - 220ms/step\n",
            "Epoch 180/280\n",
            "42/42 - 8s - loss: 0.1712 - accuracy: 0.9351 - val_loss: 0.3918 - val_accuracy: 0.8458 - 8s/epoch - 198ms/step\n",
            "Epoch 181/280\n",
            "42/42 - 9s - loss: 0.1605 - accuracy: 0.9413 - val_loss: 0.3856 - val_accuracy: 0.8443 - 9s/epoch - 213ms/step\n",
            "Epoch 182/280\n",
            "42/42 - 9s - loss: 0.1626 - accuracy: 0.9418 - val_loss: 0.3882 - val_accuracy: 0.8458 - 9s/epoch - 212ms/step\n",
            "Epoch 183/280\n",
            "42/42 - 8s - loss: 0.1625 - accuracy: 0.9404 - val_loss: 0.3944 - val_accuracy: 0.8428 - 8s/epoch - 201ms/step\n",
            "Epoch 184/280\n",
            "42/42 - 9s - loss: 0.1626 - accuracy: 0.9418 - val_loss: 0.3822 - val_accuracy: 0.8593 - 9s/epoch - 218ms/step\n",
            "Epoch 185/280\n",
            "42/42 - 9s - loss: 0.1563 - accuracy: 0.9461 - val_loss: 0.3828 - val_accuracy: 0.8563 - 9s/epoch - 220ms/step\n",
            "Epoch 186/280\n",
            "42/42 - 8s - loss: 0.1701 - accuracy: 0.9336 - val_loss: 0.4147 - val_accuracy: 0.8293 - 8s/epoch - 198ms/step\n",
            "Epoch 187/280\n",
            "42/42 - 9s - loss: 0.1560 - accuracy: 0.9418 - val_loss: 0.3886 - val_accuracy: 0.8473 - 9s/epoch - 211ms/step\n",
            "Epoch 188/280\n",
            "42/42 - 9s - loss: 0.1568 - accuracy: 0.9442 - val_loss: 0.4018 - val_accuracy: 0.8368 - 9s/epoch - 210ms/step\n",
            "Epoch 189/280\n",
            "42/42 - 8s - loss: 0.1422 - accuracy: 0.9500 - val_loss: 0.4001 - val_accuracy: 0.8338 - 8s/epoch - 198ms/step\n",
            "Epoch 190/280\n",
            "42/42 - 9s - loss: 0.1620 - accuracy: 0.9408 - val_loss: 0.3901 - val_accuracy: 0.8458 - 9s/epoch - 203ms/step\n",
            "Epoch 191/280\n",
            "42/42 - 9s - loss: 0.1302 - accuracy: 0.9553 - val_loss: 0.4023 - val_accuracy: 0.8308 - 9s/epoch - 224ms/step\n",
            "Epoch 192/280\n",
            "42/42 - 8s - loss: 0.1410 - accuracy: 0.9471 - val_loss: 0.3907 - val_accuracy: 0.8473 - 8s/epoch - 201ms/step\n",
            "Epoch 193/280\n",
            "42/42 - 9s - loss: 0.1426 - accuracy: 0.9485 - val_loss: 0.3943 - val_accuracy: 0.8443 - 9s/epoch - 210ms/step\n",
            "Epoch 194/280\n",
            "42/42 - 9s - loss: 0.1207 - accuracy: 0.9615 - val_loss: 0.3886 - val_accuracy: 0.8488 - 9s/epoch - 223ms/step\n",
            "Epoch 195/280\n",
            "42/42 - 8s - loss: 0.1242 - accuracy: 0.9577 - val_loss: 0.3906 - val_accuracy: 0.8458 - 8s/epoch - 202ms/step\n",
            "Epoch 196/280\n",
            "42/42 - 8s - loss: 0.1434 - accuracy: 0.9538 - val_loss: 0.3936 - val_accuracy: 0.8458 - 8s/epoch - 199ms/step\n",
            "Epoch 197/280\n",
            "42/42 - 9s - loss: 0.1234 - accuracy: 0.9567 - val_loss: 0.3853 - val_accuracy: 0.8533 - 9s/epoch - 221ms/step\n",
            "Epoch 198/280\n",
            "42/42 - 8s - loss: 0.1348 - accuracy: 0.9529 - val_loss: 0.3971 - val_accuracy: 0.8503 - 8s/epoch - 199ms/step\n",
            "Epoch 199/280\n",
            "42/42 - 8s - loss: 0.1236 - accuracy: 0.9591 - val_loss: 0.3973 - val_accuracy: 0.8368 - 8s/epoch - 200ms/step\n",
            "Epoch 200/280\n",
            "42/42 - 9s - loss: 0.1267 - accuracy: 0.9538 - val_loss: 0.4031 - val_accuracy: 0.8383 - 9s/epoch - 223ms/step\n",
            "Epoch 201/280\n",
            "42/42 - 8s - loss: 0.1132 - accuracy: 0.9644 - val_loss: 0.3935 - val_accuracy: 0.8443 - 8s/epoch - 201ms/step\n",
            "Epoch 202/280\n",
            "42/42 - 9s - loss: 0.1208 - accuracy: 0.9562 - val_loss: 0.3829 - val_accuracy: 0.8488 - 9s/epoch - 215ms/step\n",
            "Epoch 203/280\n",
            "42/42 - 9s - loss: 0.1207 - accuracy: 0.9620 - val_loss: 0.3928 - val_accuracy: 0.8398 - 9s/epoch - 224ms/step\n",
            "Epoch 204/280\n",
            "42/42 - 9s - loss: 0.1141 - accuracy: 0.9610 - val_loss: 0.3856 - val_accuracy: 0.8578 - 9s/epoch - 209ms/step\n",
            "Epoch 205/280\n",
            "42/42 - 8s - loss: 0.1212 - accuracy: 0.9567 - val_loss: 0.3932 - val_accuracy: 0.8413 - 8s/epoch - 195ms/step\n",
            "Epoch 206/280\n",
            "42/42 - 9s - loss: 0.1160 - accuracy: 0.9562 - val_loss: 0.3925 - val_accuracy: 0.8413 - 9s/epoch - 226ms/step\n",
            "Epoch 207/280\n",
            "42/42 - 8s - loss: 0.1118 - accuracy: 0.9582 - val_loss: 0.3970 - val_accuracy: 0.8398 - 8s/epoch - 201ms/step\n",
            "Epoch 208/280\n",
            "42/42 - 9s - loss: 0.1176 - accuracy: 0.9567 - val_loss: 0.3817 - val_accuracy: 0.8503 - 9s/epoch - 212ms/step\n",
            "Epoch 209/280\n",
            "42/42 - 9s - loss: 0.1033 - accuracy: 0.9663 - val_loss: 0.4013 - val_accuracy: 0.8338 - 9s/epoch - 222ms/step\n",
            "Epoch 210/280\n",
            "42/42 - 9s - loss: 0.1057 - accuracy: 0.9639 - val_loss: 0.3775 - val_accuracy: 0.8518 - 9s/epoch - 205ms/step\n",
            "Epoch 211/280\n",
            "42/42 - 8s - loss: 0.1105 - accuracy: 0.9596 - val_loss: 0.3914 - val_accuracy: 0.8353 - 8s/epoch - 198ms/step\n",
            "Epoch 212/280\n",
            "42/42 - 9s - loss: 0.1121 - accuracy: 0.9606 - val_loss: 0.3879 - val_accuracy: 0.8413 - 9s/epoch - 213ms/step\n",
            "Epoch 213/280\n",
            "42/42 - 8s - loss: 0.1144 - accuracy: 0.9582 - val_loss: 0.3923 - val_accuracy: 0.8428 - 8s/epoch - 200ms/step\n",
            "Epoch 214/280\n",
            "42/42 - 8s - loss: 0.1067 - accuracy: 0.9658 - val_loss: 0.3889 - val_accuracy: 0.8398 - 8s/epoch - 200ms/step\n",
            "Epoch 215/280\n",
            "42/42 - 10s - loss: 0.0998 - accuracy: 0.9644 - val_loss: 0.3882 - val_accuracy: 0.8368 - 10s/epoch - 227ms/step\n",
            "Epoch 216/280\n",
            "42/42 - 9s - loss: 0.0977 - accuracy: 0.9673 - val_loss: 0.3934 - val_accuracy: 0.8338 - 9s/epoch - 207ms/step\n",
            "Epoch 217/280\n",
            "42/42 - 9s - loss: 0.0907 - accuracy: 0.9673 - val_loss: 0.3857 - val_accuracy: 0.8368 - 9s/epoch - 210ms/step\n",
            "Epoch 218/280\n",
            "42/42 - 9s - loss: 0.1092 - accuracy: 0.9577 - val_loss: 0.3928 - val_accuracy: 0.8353 - 9s/epoch - 222ms/step\n",
            "Epoch 219/280\n",
            "42/42 - 11s - loss: 0.0892 - accuracy: 0.9711 - val_loss: 0.3741 - val_accuracy: 0.8518 - 11s/epoch - 269ms/step\n",
            "Epoch 220/280\n",
            "42/42 - 8s - loss: 0.1057 - accuracy: 0.9567 - val_loss: 0.3828 - val_accuracy: 0.8398 - 8s/epoch - 190ms/step\n",
            "Epoch 221/280\n",
            "42/42 - 9s - loss: 0.1002 - accuracy: 0.9654 - val_loss: 0.3888 - val_accuracy: 0.8503 - 9s/epoch - 224ms/step\n",
            "Epoch 222/280\n",
            "42/42 - 9s - loss: 0.0868 - accuracy: 0.9697 - val_loss: 0.3758 - val_accuracy: 0.8488 - 9s/epoch - 219ms/step\n",
            "Epoch 223/280\n",
            "42/42 - 8s - loss: 0.1047 - accuracy: 0.9606 - val_loss: 0.3908 - val_accuracy: 0.8368 - 8s/epoch - 201ms/step\n",
            "Epoch 224/280\n",
            "42/42 - 9s - loss: 0.0746 - accuracy: 0.9788 - val_loss: 0.3806 - val_accuracy: 0.8383 - 9s/epoch - 210ms/step\n",
            "Epoch 225/280\n",
            "42/42 - 9s - loss: 0.0853 - accuracy: 0.9711 - val_loss: 0.3811 - val_accuracy: 0.8473 - 9s/epoch - 223ms/step\n",
            "Epoch 226/280\n",
            "42/42 - 8s - loss: 0.0813 - accuracy: 0.9731 - val_loss: 0.3714 - val_accuracy: 0.8503 - 8s/epoch - 201ms/step\n",
            "Epoch 227/280\n",
            "42/42 - 9s - loss: 0.0980 - accuracy: 0.9692 - val_loss: 0.3923 - val_accuracy: 0.8368 - 9s/epoch - 218ms/step\n",
            "Epoch 228/280\n",
            "42/42 - 9s - loss: 0.0858 - accuracy: 0.9716 - val_loss: 0.3776 - val_accuracy: 0.8533 - 9s/epoch - 212ms/step\n",
            "Epoch 229/280\n",
            "42/42 - 9s - loss: 0.0982 - accuracy: 0.9649 - val_loss: 0.3923 - val_accuracy: 0.8383 - 9s/epoch - 223ms/step\n",
            "Epoch 230/280\n",
            "42/42 - 9s - loss: 0.0845 - accuracy: 0.9702 - val_loss: 0.3910 - val_accuracy: 0.8308 - 9s/epoch - 221ms/step\n",
            "Epoch 231/280\n",
            "42/42 - 9s - loss: 0.0949 - accuracy: 0.9654 - val_loss: 0.3908 - val_accuracy: 0.8428 - 9s/epoch - 216ms/step\n",
            "Epoch 232/280\n",
            "42/42 - 11s - loss: 0.0826 - accuracy: 0.9716 - val_loss: 0.3532 - val_accuracy: 0.8608 - 11s/epoch - 270ms/step\n",
            "Epoch 233/280\n",
            "42/42 - 9s - loss: 0.0856 - accuracy: 0.9678 - val_loss: 0.3836 - val_accuracy: 0.8458 - 9s/epoch - 205ms/step\n",
            "Epoch 234/280\n",
            "42/42 - 9s - loss: 0.0752 - accuracy: 0.9784 - val_loss: 0.3554 - val_accuracy: 0.8563 - 9s/epoch - 210ms/step\n",
            "Epoch 235/280\n",
            "42/42 - 10s - loss: 0.0822 - accuracy: 0.9716 - val_loss: 0.3661 - val_accuracy: 0.8638 - 10s/epoch - 235ms/step\n",
            "Epoch 236/280\n",
            "42/42 - 9s - loss: 0.0765 - accuracy: 0.9760 - val_loss: 0.3688 - val_accuracy: 0.8518 - 9s/epoch - 207ms/step\n",
            "Epoch 237/280\n",
            "42/42 - 8s - loss: 0.0725 - accuracy: 0.9774 - val_loss: 0.3689 - val_accuracy: 0.8548 - 8s/epoch - 200ms/step\n",
            "Epoch 238/280\n",
            "42/42 - 9s - loss: 0.0830 - accuracy: 0.9750 - val_loss: 0.3809 - val_accuracy: 0.8443 - 9s/epoch - 224ms/step\n",
            "Epoch 239/280\n",
            "42/42 - 9s - loss: 0.0702 - accuracy: 0.9841 - val_loss: 0.3557 - val_accuracy: 0.8578 - 9s/epoch - 209ms/step\n",
            "Epoch 240/280\n",
            "42/42 - 8s - loss: 0.0658 - accuracy: 0.9774 - val_loss: 0.3556 - val_accuracy: 0.8548 - 8s/epoch - 196ms/step\n",
            "Epoch 241/280\n",
            "42/42 - 9s - loss: 0.0817 - accuracy: 0.9707 - val_loss: 0.3640 - val_accuracy: 0.8578 - 9s/epoch - 220ms/step\n",
            "Epoch 242/280\n",
            "42/42 - 8s - loss: 0.0598 - accuracy: 0.9817 - val_loss: 0.3561 - val_accuracy: 0.8593 - 8s/epoch - 199ms/step\n",
            "Epoch 243/280\n",
            "42/42 - 8s - loss: 0.0755 - accuracy: 0.9711 - val_loss: 0.3786 - val_accuracy: 0.8473 - 8s/epoch - 199ms/step\n",
            "Epoch 244/280\n",
            "42/42 - 9s - loss: 0.0561 - accuracy: 0.9846 - val_loss: 0.3680 - val_accuracy: 0.8488 - 9s/epoch - 212ms/step\n",
            "Epoch 245/280\n",
            "42/42 - 8s - loss: 0.0754 - accuracy: 0.9707 - val_loss: 0.3621 - val_accuracy: 0.8548 - 8s/epoch - 199ms/step\n",
            "Epoch 246/280\n",
            "42/42 - 8s - loss: 0.0642 - accuracy: 0.9793 - val_loss: 0.3656 - val_accuracy: 0.8548 - 8s/epoch - 197ms/step\n",
            "Epoch 247/280\n",
            "42/42 - 9s - loss: 0.0758 - accuracy: 0.9740 - val_loss: 0.3639 - val_accuracy: 0.8593 - 9s/epoch - 211ms/step\n",
            "Epoch 248/280\n",
            "42/42 - 8s - loss: 0.0657 - accuracy: 0.9793 - val_loss: 0.3642 - val_accuracy: 0.8593 - 8s/epoch - 200ms/step\n",
            "Epoch 249/280\n",
            "42/42 - 8s - loss: 0.0621 - accuracy: 0.9788 - val_loss: 0.3450 - val_accuracy: 0.8653 - 8s/epoch - 200ms/step\n",
            "Epoch 250/280\n",
            "42/42 - 9s - loss: 0.0608 - accuracy: 0.9808 - val_loss: 0.3493 - val_accuracy: 0.8653 - 9s/epoch - 209ms/step\n",
            "Epoch 251/280\n",
            "42/42 - 8s - loss: 0.0611 - accuracy: 0.9779 - val_loss: 0.3455 - val_accuracy: 0.8683 - 8s/epoch - 186ms/step\n",
            "Epoch 252/280\n",
            "42/42 - 9s - loss: 0.0587 - accuracy: 0.9812 - val_loss: 0.3426 - val_accuracy: 0.8698 - 9s/epoch - 222ms/step\n",
            "Epoch 253/280\n",
            "42/42 - 9s - loss: 0.0690 - accuracy: 0.9764 - val_loss: 0.3609 - val_accuracy: 0.8653 - 9s/epoch - 210ms/step\n",
            "Epoch 254/280\n",
            "42/42 - 8s - loss: 0.0569 - accuracy: 0.9832 - val_loss: 0.3501 - val_accuracy: 0.8518 - 8s/epoch - 185ms/step\n",
            "Epoch 255/280\n",
            "42/42 - 9s - loss: 0.0760 - accuracy: 0.9735 - val_loss: 0.3607 - val_accuracy: 0.8563 - 9s/epoch - 222ms/step\n",
            "Epoch 256/280\n",
            "42/42 - 11s - loss: 0.0516 - accuracy: 0.9865 - val_loss: 0.3468 - val_accuracy: 0.8698 - 11s/epoch - 268ms/step\n",
            "Epoch 257/280\n",
            "42/42 - 8s - loss: 0.0692 - accuracy: 0.9760 - val_loss: 0.3880 - val_accuracy: 0.8293 - 8s/epoch - 198ms/step\n",
            "Epoch 258/280\n",
            "42/42 - 9s - loss: 0.0570 - accuracy: 0.9793 - val_loss: 0.3578 - val_accuracy: 0.8638 - 9s/epoch - 211ms/step\n",
            "Epoch 259/280\n",
            "42/42 - 9s - loss: 0.0587 - accuracy: 0.9822 - val_loss: 0.3557 - val_accuracy: 0.8578 - 9s/epoch - 205ms/step\n",
            "Epoch 260/280\n",
            "42/42 - 8s - loss: 0.0610 - accuracy: 0.9803 - val_loss: 0.3688 - val_accuracy: 0.8518 - 8s/epoch - 199ms/step\n",
            "Epoch 261/280\n",
            "42/42 - 9s - loss: 0.0560 - accuracy: 0.9861 - val_loss: 0.3718 - val_accuracy: 0.8533 - 9s/epoch - 219ms/step\n",
            "Epoch 262/280\n",
            "42/42 - 9s - loss: 0.0450 - accuracy: 0.9870 - val_loss: 0.3462 - val_accuracy: 0.8668 - 9s/epoch - 221ms/step\n",
            "Epoch 263/280\n",
            "42/42 - 8s - loss: 0.0680 - accuracy: 0.9755 - val_loss: 0.3774 - val_accuracy: 0.8383 - 8s/epoch - 201ms/step\n",
            "Epoch 264/280\n",
            "42/42 - 9s - loss: 0.0476 - accuracy: 0.9894 - val_loss: 0.3577 - val_accuracy: 0.8473 - 9s/epoch - 214ms/step\n",
            "Epoch 265/280\n",
            "42/42 - 9s - loss: 0.0809 - accuracy: 0.9683 - val_loss: 0.3809 - val_accuracy: 0.8278 - 9s/epoch - 210ms/step\n",
            "Epoch 266/280\n",
            "42/42 - 8s - loss: 0.0530 - accuracy: 0.9846 - val_loss: 0.3639 - val_accuracy: 0.8488 - 8s/epoch - 197ms/step\n",
            "Epoch 267/280\n",
            "42/42 - 9s - loss: 0.0898 - accuracy: 0.9639 - val_loss: 0.4253 - val_accuracy: 0.8084 - 9s/epoch - 213ms/step\n",
            "Epoch 268/280\n",
            "42/42 - 9s - loss: 0.0560 - accuracy: 0.9803 - val_loss: 0.3367 - val_accuracy: 0.8653 - 9s/epoch - 218ms/step\n",
            "Epoch 269/280\n",
            "42/42 - 8s - loss: 0.0643 - accuracy: 0.9788 - val_loss: 0.3456 - val_accuracy: 0.8608 - 8s/epoch - 196ms/step\n",
            "Epoch 270/280\n",
            "42/42 - 8s - loss: 0.0484 - accuracy: 0.9875 - val_loss: 0.3645 - val_accuracy: 0.8443 - 8s/epoch - 200ms/step\n",
            "Epoch 271/280\n",
            "42/42 - 9s - loss: 0.0630 - accuracy: 0.9817 - val_loss: 0.3867 - val_accuracy: 0.8443 - 9s/epoch - 208ms/step\n",
            "Epoch 272/280\n",
            "42/42 - 8s - loss: 0.0469 - accuracy: 0.9875 - val_loss: 0.3546 - val_accuracy: 0.8488 - 8s/epoch - 202ms/step\n",
            "Epoch 273/280\n",
            "42/42 - 9s - loss: 0.0747 - accuracy: 0.9697 - val_loss: 0.3816 - val_accuracy: 0.8353 - 9s/epoch - 216ms/step\n",
            "Epoch 274/280\n",
            "42/42 - 9s - loss: 0.0431 - accuracy: 0.9880 - val_loss: 0.3608 - val_accuracy: 0.8488 - 9s/epoch - 218ms/step\n",
            "Epoch 275/280\n",
            "42/42 - 9s - loss: 0.0821 - accuracy: 0.9658 - val_loss: 0.4618 - val_accuracy: 0.7934 - 9s/epoch - 205ms/step\n",
            "Epoch 276/280\n",
            "42/42 - 9s - loss: 0.0485 - accuracy: 0.9875 - val_loss: 0.3333 - val_accuracy: 0.8713 - 9s/epoch - 217ms/step\n",
            "Epoch 277/280\n",
            "42/42 - 9s - loss: 0.0878 - accuracy: 0.9668 - val_loss: 0.3679 - val_accuracy: 0.8398 - 9s/epoch - 218ms/step\n",
            "Epoch 278/280\n",
            "42/42 - 8s - loss: 0.0488 - accuracy: 0.9856 - val_loss: 0.3442 - val_accuracy: 0.8638 - 8s/epoch - 201ms/step\n",
            "Epoch 279/280\n",
            "42/42 - 9s - loss: 0.1298 - accuracy: 0.9461 - val_loss: 0.4223 - val_accuracy: 0.7919 - 9s/epoch - 213ms/step\n",
            "Epoch 280/280\n",
            "42/42 - 9s - loss: 0.0509 - accuracy: 0.9851 - val_loss: 0.3701 - val_accuracy: 0.8503 - 9s/epoch - 209ms/step\n",
            "Training end\n",
            "Testing start\n",
            "Testing end\n",
            "Model saved\n",
            "True Positive, False Positive, False negative, Second of Inter in Test, Sensitivity, FPR\n",
            "18,0,32,10500,0.36,0.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "PathSpectogramFolder='/content/drive/MyDrive/spectrograms'\n",
        "OutputPath='/content/results.txt'\n",
        "OutputPathModels='/content/drive/MyDrive/chbmit-1.0.0.physionet.org'\n",
        "interictalSpectograms=[]\n",
        "preictalSpectograms=[]  #This array contains syntetic data, it's created to have a balance dataset and it's used for training\n",
        "preictalRealSpectograms=[]  #This array containt the real preictal data, it's used for testing\n",
        "#use patients list selected in the begining\n",
        "patients = [\"23\"]\n",
        "nSeizure=0\n",
        "\n",
        "def loadParametersFromFile(filePath):\n",
        "    global PathSpectogramFolder\n",
        "    global OutputPath\n",
        "    global OutputPathModels\n",
        "    if(os.path.isfile(filePath)):\n",
        "        with open(filePath, \"r\") as f:\n",
        "                line=f.readline()\n",
        "                if(line.split(\":\")[0]==\"PathSpectogramFolder\"):\n",
        "                    PathSpectogramFolder=line.split(\":\")[1].strip()\n",
        "                line=f.readline()\n",
        "                if(line.split(\":\")[0]==\"OutputPath\"):\n",
        "                    OutputPath=line.split(\":\")[1].strip()\n",
        "                line=f.readline()\n",
        "                if(line.split(\":\")[0]==\"OutputPathModels\"):\n",
        "                    OutputPathModels=line.split(\":\")[1].strip()\n",
        "\n",
        "def loadSpectogramData(indexPat):\n",
        "    global interictalSpectograms\n",
        "    global preictalSpectograms\n",
        "    global preictalRealSpectograms\n",
        "    global nSeizure\n",
        "    nFileForSeizure=0\n",
        "    \n",
        "    interictalSpectograms=[]\n",
        "    preictalSpectograms=[]\n",
        "    preictalRealSpectograms=[]\n",
        "    \n",
        "    f = open(PathSpectogramFolder+'/paz'+patients[indexPat]+'/legendAllData.txt', 'r')\n",
        "    line=f.readline()\n",
        "    while(not \"SEIZURE\" in line):\n",
        "        line=f.readline()\n",
        "    nSeizure=int(line.split(\":\")[1].strip())\n",
        "    line=f.readline()\n",
        "    line=f.readline()\n",
        "    nSpectograms=int(line.strip())\n",
        "    nFileForSeizure=math.ceil(math.ceil(nSpectograms/50)/nSeizure)\n",
        "    line=f.readline()\n",
        "    \n",
        "    \n",
        "    cont=-1\n",
        "    indFilePathRead=0\n",
        "    while(\"npy\" in line and indFilePathRead<nSeizure*nFileForSeizure):\n",
        "        if(indFilePathRead%nFileForSeizure==0):\n",
        "            interictalSpectograms.append([])\n",
        "            cont=cont+1\n",
        "            interictalSpectograms[cont].append(line.split(' ')[2].rstrip())\n",
        "            indFilePathRead=indFilePathRead+1\n",
        "        else:\n",
        "            if(len(line.split(' '))>=3):\n",
        "                interictalSpectograms[cont].append(line.split(' ')[2].rstrip())\n",
        "            indFilePathRead=indFilePathRead+1\n",
        "            \n",
        "        line=f.readline()\n",
        "    line=f.readline()\n",
        "    line=f.readline()\n",
        "    line=f.readline()\n",
        "\n",
        "   \n",
        "    cont=-1\n",
        "    indFilePathRead=0   \n",
        "     \n",
        "    while(line.strip()!=\"\"):\n",
        "        if(\"SEIZURE\" in line):\n",
        "            line=f.readline()\n",
        "            if(len(line.split(' '))>=3):\n",
        "                preictalSpectograms.append([])\n",
        "                cont=cont+1\n",
        "                preictalSpectograms[cont].append(line.split(' ')[2].rstrip())\n",
        "                indFilePathRead=indFilePathRead+1\n",
        "        else:\n",
        "            if(len(line.split(' '))>=3):\n",
        "                preictalSpectograms[cont].append(line.split(' ')[2].rstrip())\n",
        "            indFilePathRead=indFilePathRead+1\n",
        "            \n",
        "        line=f.readline()\n",
        "        \n",
        "    line=f.readline()\n",
        "    line=f.readline()\n",
        "    line=f.readline()\n",
        "\n",
        "    \n",
        "    cont=-1\n",
        "    while(line):\n",
        "        if(\"SEIZURE\" in line):\n",
        "            line=f.readline()\n",
        "            preictalRealSpectograms.append([])\n",
        "            cont=cont+1\n",
        "            preictalRealSpectograms[cont].append(line.split(' ')[2].rstrip())\n",
        "        else:\n",
        "            preictalRealSpectograms[cont].append(line.split(' ')[2].rstrip())\n",
        "            \n",
        "        line=f.readline()\n",
        "    f.close()\n",
        "\n",
        "# Generator model\n",
        "def build_generator(latent_dim):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128 * 7 * 7, input_dim=latent_dim))\n",
        "    model.add(Reshape((7, 7, 128)))\n",
        "    model.add(Conv3D(16, (22, 5, 5), strides=(1, 2, 2), padding='valid',activation='relu',data_format= \"channels_first\", input_shape=input_shape))\n",
        "    model.add(Conv3D(32, (1, 3, 3), strides=(1, 1,1), padding='valid',data_format= \"channels_first\",  activation='relu'))   \n",
        "    model.add(Conv3D(64, (1,3, 3), strides=(1, 1,1), padding='valid',data_format= \"channels_first\",  activation='relu'))\n",
        "    return model\n",
        "\n",
        "# Discriminator model\n",
        "def build_discriminator(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(Conv3D(16, (22, 5, 5), strides=(1, 2, 2), padding='valid',activation='relu',data_format= \"channels_first\", input_shape=input_shape))\n",
        "    model.add(keras.layers.MaxPooling3D(pool_size=(1, 2, 2),data_format= \"channels_first\",  padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv3D(32, (1, 3, 3), strides=(1, 1,1), padding='valid',data_format= \"channels_first\",  activation='relu'))\n",
        "    model.add(keras.layers.MaxPooling3D(pool_size=(1,2, 2),data_format= \"channels_first\", ))\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    model.add(Conv3D(64, (1,3, 3), strides=(1, 1,1), padding='valid',data_format= \"channels_first\",  activation='relu'))\n",
        "    model.add(keras.layers.MaxPooling3D(pool_size=(1,2, 2),data_format= \"channels_first\", ))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(256, activation='sigmoid'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "    \n",
        "\n",
        "# LSTM model\n",
        "def build_lstm(sequence_length, latent_dim):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(64, input_shape=(sequence_length, latent_dim)))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    return model\n",
        "\n",
        "def build():\n",
        "    input_shape = (1,2,59,114)\n",
        "    latent_dim = 100\n",
        "    sequence_length = 50\n",
        "    generator = build_generator(latent_dim)\n",
        "    discriminator = build_discriminator(input_shape)\n",
        "    lstm = build_lstm(sequence_length, latent_dim)\n",
        "  \n",
        "def createModel():\n",
        "    input_shape=(1, 22, 59, 114)\n",
        "    model = Sequential()\n",
        "    #C1\n",
        "    model.add(Conv3D(16, (22, 5, 5), strides=(1, 2, 2), padding='valid',activation='relu',data_format= \"channels_first\", input_shape=input_shape))\n",
        "    model.add(keras.layers.MaxPooling3D(pool_size=(1, 2, 2),data_format= \"channels_first\",  padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    #C2\n",
        "    model.add(Conv3D(32, (1, 3, 3), strides=(1, 1,1), padding='valid',data_format= \"channels_first\",  activation='relu'))\n",
        "    model.add(keras.layers.MaxPooling3D(pool_size=(1,2, 2),data_format= \"channels_first\", ))\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    #C3\n",
        "    model.add(Conv3D(64, (1,3, 3), strides=(1, 1,1), padding='valid',data_format= \"channels_first\",  activation='relu'))\n",
        "    model.add(keras.layers.MaxPooling3D(pool_size=(1,2, 2),data_format= \"channels_first\", ))\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(256, activation='sigmoid'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "    \n",
        "    opt_adam = keras.optimizers.Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt_adam, metrics=['accuracy'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "def getFilesPathWithoutSeizure(indexSeizure, indexPat):\n",
        "    filesPath=[]\n",
        "    for i in range(0, nSeizure):\n",
        "        if(i!=indexSeizure):\n",
        "            filesPath.extend(interictalSpectograms[i])\n",
        "            filesPath.extend(preictalSpectograms[i])\n",
        "    shuffle(filesPath)\n",
        "    return filesPath\n",
        "\n",
        "\n",
        "def generate_arrays_for_training(indexPat, paths, start=0, end=100):\n",
        "    while True:\n",
        "        from_=int(len(paths)/100*start)\n",
        "        to_=int(len(paths)/100*end)\n",
        "        for i in range(from_, int(to_)):\n",
        "            f=paths[i]\n",
        "            x = np.load(PathSpectogramFolder+f)\n",
        "            x=np.array([x])\n",
        "            x=x.swapaxes(0,1)\n",
        "            if('P' in f):\n",
        "                y = np.repeat([[0,1]],x.shape[0], axis=0)\n",
        "            else:\n",
        "                y =np.repeat([[1,0]],x.shape[0], axis=0)\n",
        "            yield(x,y)\n",
        "            \n",
        "def generate_arrays_for_predict(indexPat, paths, start=0, end=100):\n",
        "    while True:\n",
        "        from_=int(len(paths)/100*start)\n",
        "        to_=int(len(paths)/100*end)\n",
        "        for i in range(from_, int(to_)):\n",
        "            f=paths[i]\n",
        "            x = np.load(PathSpectogramFolder+f)\n",
        "            x=np.array([x])\n",
        "            x=x.swapaxes(0,1)\n",
        "            yield(x)\n",
        "\n",
        "class EarlyStoppingByLossVal(keras.callbacks.Callback):\n",
        "    def __init__(self, monitor='val_loss', value=0.00001, verbose=0, lower=True):\n",
        "        super(keras.callbacks.Callback, self).__init__()\n",
        "        self.monitor = monitor\n",
        "        self.value = value\n",
        "        self.verbose = verbose\n",
        "        self.lower=lower\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        current = logs.get(self.monitor)\n",
        "        if self.lower:\n",
        "            if current < self.value:\n",
        "                if self.verbose > 0:\n",
        "                    print(\"Epoch %05d: early stopping THR\" % epoch)\n",
        "                self.model.stop_training = True\n",
        "     #critical secton   \n",
        "\n",
        "def main():\n",
        "    print(\"START\")\n",
        "    if not os.path.exists(OutputPathModels):\n",
        "        os.makedirs(OutputPathModels)\n",
        "    loadParametersFromFile(\"PARAMETERS_CNN.txt\")\n",
        "    \n",
        "    callback=EarlyStoppingByLossVal(monitor='val_acc', value=0.975, verbose=1, lower=False)\n",
        "    print(\"Parameters loaded\")\n",
        "    \n",
        "    for indexPat in range(0, len(patients)):\n",
        "        print('Patient '+patients[indexPat])\n",
        "        if not os.path.exists(OutputPathModels+\"ModelPat\"+patients[indexPat]+\"/\"):\n",
        "            os.makedirs(OutputPathModels+\"ModelPat\"+patients[indexPat]+\"/\")\n",
        "        loadSpectogramData(indexPat) \n",
        "        print('Spectograms data loaded')\n",
        "        \n",
        "        result='Patient '+patients[indexPat]+'\\n'     \n",
        "        result='Out Seizure, True Positive, False Positive, False negative, Second of Inter in Test, Sensitivity, FPR \\n'\n",
        "        for i in range(0, nSeizure):\n",
        "            print('SEIZURE OUT: '+str(i+1))\n",
        "            \n",
        "            print('Training start')  \n",
        "            model = createModel()\n",
        "            filesPath=getFilesPathWithoutSeizure(i, indexPat)\n",
        "            \n",
        "            model.fit_generator(generate_arrays_for_training(indexPat, filesPath, end=75), #end=75),#It take the first 75%\n",
        "                                validation_data=generate_arrays_for_training(indexPat, filesPath, start=75),#start=75), #It take the last 25%\n",
        "                                #steps_per_epoch=10000, epochs=10)\n",
        "                                steps_per_epoch=int((len(filesPath)-int(len(filesPath)/100*25))),#*25), \n",
        "                                validation_steps=int((len(filesPath)-int(len(filesPath)/100*75))),#*75),\n",
        "                                verbose=2,\n",
        "                                epochs=280, max_queue_size=2, shuffle=True, callbacks=[callback])# 100 epochs è meglio #aggiungere criterio di stop in base accuratezza\n",
        "            print('Training end')\n",
        "            \n",
        "            print('Testing start')\n",
        "            filesPath=interictalSpectograms[i]\n",
        "            interPrediction=model.predict_generator(generate_arrays_for_predict(indexPat, filesPath), max_queue_size=4, steps=len(filesPath))\n",
        "            filesPath=preictalRealSpectograms[i]\n",
        "            preictPrediction=model.predict_generator(generate_arrays_for_predict(indexPat, filesPath), max_queue_size=4, steps=len(filesPath))\n",
        "            print('Testing end')\n",
        "            \n",
        "\n",
        "            # Creates a HDF5 file \n",
        "            model.save(OutputPathModels+\"ModelPat\"+patients[indexPat]+\"/\"+'ModelOutSeizure'+str(i+1)+'.h5')\n",
        "            print(\"Model saved\")\n",
        "            \n",
        "            if not os.path.exists(OutputPathModels+\"OutputTest\"+\"/\"):\n",
        "                os.makedirs(OutputPathModels+\"OutputTest\"+\"/\")\n",
        "            np.savetxt(OutputPathModels+\"OutputTest\"+\"/\"+\"Int_\"+patients[indexPat]+\"_\"+str(i+1)+\".csv\", interPrediction, delimiter=\",\")\n",
        "            np.savetxt(OutputPathModels+\"OutputTest\"+\"/\"+\"Pre_\"+patients[indexPat]+\"_\"+str(i+1)+\".csv\", preictPrediction, delimiter=\",\")\n",
        "            \n",
        "            secondsInterictalInTest=len(interictalSpectograms[i])*50*30#50 spectograms for file, 30 seconds for each spectogram\n",
        "            acc=0#accumulator\n",
        "            fp=0\n",
        "            tp=0\n",
        "            fn=0\n",
        "            lastTenResult=list()\n",
        "            \n",
        "            for el in interPrediction:\n",
        "                if(el[1]>0.5):\n",
        "                    acc=acc+1\n",
        "                    lastTenResult.append(1)\n",
        "                else:\n",
        "                    lastTenResult.append(0)\n",
        "                if(len(lastTenResult)>10):\n",
        "                    acc=acc-lastTenResult.pop(0)\n",
        "                if(acc>=8):\n",
        "                  fp=fp+1\n",
        "                  lastTenResult=list()\n",
        "                  acc=0\n",
        "            \n",
        "            lastTenResult=list()\n",
        "            for el in preictPrediction:\n",
        "                if(el[1]>0.5):\n",
        "                    acc=acc+1\n",
        "                    lastTenResult.append(1)\n",
        "                else:\n",
        "                    lastTenResult.append(0)\n",
        "                if(len(lastTenResult)>10):\n",
        "                    acc=acc-lastTenResult.pop(0)\n",
        "                if(acc>=8):\n",
        "                  tp=tp+1 \n",
        "                else:\n",
        "                    if(len(lastTenResult)==10):\n",
        "                       fn=fn+1 \n",
        "                       \n",
        "            sensitivity=tp/(tp+fn)\n",
        "            FPR=fp/(secondsInterictalInTest/(60*60))\n",
        "            \n",
        "            result=result+str(i+1)+','+str(tp)+','+str(fp)+','+str(fn)+','+str(secondsInterictalInTest)+','\n",
        "            result=result+str(sensitivity)+','+str(FPR)+'\\n'\n",
        "            print('True Positive, False Positive, False negative, Second of Inter in Test, Sensitivity, FPR')\n",
        "            print(str(tp)+','+str(fp)+','+str(fn)+','+str(secondsInterictalInTest)+','+str(sensitivity)+','+str(FPR))\n",
        "        with open(OutputPath, \"a+\") as myfile:\n",
        "            myfile.write(result)\n",
        "    \n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKfMaG2Bm-4a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogl1YOTcmdwm"
      },
      "outputs": [],
      "source": [
        "\n",
        "OutputPathModels=['/content/chbmit-1.0.0.physionet.org',\n",
        "                  '/content/chbmit-1.0.0.physionet.org'] \n",
        "def dataProc():\n",
        "    pat=[\"01\"]\n",
        "    nSeizure=[2]\n",
        "    secondsInterictalInTest=[7500,31500, 10500, 46500, 21000,10500]\n",
        "    threshold=[0.6,0.8, 0.4, 0.001, 0.3,0.3]\n",
        "    for j in range(0,len(pat)):\n",
        "        sensResults=[]\n",
        "        FPRResults=[]\n",
        "        for k in range(0,2):\n",
        "            for i in range(0, nSeizure[j]):            \n",
        "                interPrediction=np.loadtxt(OutputPathModels[k]+\"OutputTest\"+\"/\"+\"Int_\"+pat[j]+\"_\"+str(i+1)+\".csv\",delimiter=',')\n",
        "                preictPrediction=np.loadtxt(OutputPathModels[k]+\"OutputTest\"+\"/\"+\"Pre_\"+pat[j]+\"_\"+str(i+1)+\".csv\",delimiter=',')\n",
        "                \n",
        "                acc=0#accumulator\n",
        "                fp=0\n",
        "                tp=0\n",
        "                fn=0\n",
        "                lastTenResult=list()\n",
        "                \n",
        "                for el in interPrediction:\n",
        "                    if(el[1]>threshold[j]):\n",
        "                        acc=acc+1\n",
        "                        lastTenResult.append(1)\n",
        "                    else:\n",
        "                        lastTenResult.append(0)\n",
        "                    if(len(lastTenResult)>10):\n",
        "                        acc=acc-lastTenResult.pop(0)\n",
        "                    if(acc>=8):\n",
        "                      fp=fp+1\n",
        "                      lastTenResult=list()\n",
        "                      acc=0\n",
        "                \n",
        "                lastTenResult=list()\n",
        "                for el in preictPrediction:\n",
        "                    if(el[1]>threshold[j]):\n",
        "                        acc=acc+1\n",
        "                        lastTenResult.append(1)\n",
        "                    else:\n",
        "                        lastTenResult.append(0)\n",
        "                    if(len(lastTenResult)>10):\n",
        "                        acc=acc-lastTenResult.pop(0)\n",
        "                    if(acc>=8):\n",
        "                      tp=tp+1 \n",
        "                    else:\n",
        "                        if(len(lastTenResult)==10):\n",
        "                           fn=fn+1 \n",
        "                           \n",
        "                sensitivity=tp/(tp+fn)*100\n",
        "                FPR=fp/(secondsInterictalInTest[j]/(60*60))\n",
        "                sensResults.append(sensitivity)\n",
        "                FPRResults.append(FPR)\n",
        "                \n",
        "        sdSENS=statistics.stdev(sensResults)\n",
        "        avSENS=statistics.mean(sensResults)\n",
        "        \n",
        "        sdFPR=statistics.stdev(FPRResults)\n",
        "        avFPR=statistics.mean(FPRResults)\n",
        "        print(pat[j]+\"   AVG_Sens= \"+str(avSENS)+\" +- \"+str(sdSENS)+\"   AVG_FPR= \"+str(avFPR)+\" +- \"+str(sdFPR))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQf_CVOdrXEK"
      },
      "outputs": [],
      "source": [
        "dataProc()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}